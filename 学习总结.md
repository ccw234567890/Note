# PyTorch深度学习核心路径总结

> [!abstract]
> 本笔记系统地梳理了从神经网络基础到前沿生成模型的完整学习路径。它不仅涵盖了各类模型的实现细节，更着重阐述了技术演进背后的核心思想，展现了现代深度学习的思考脉络与工程实践。

---

### Ⅰ. 基础构建与核心工作流

> [!info]
> 万丈高楼平地起，我们首先掌握了使用PyTorch进行开发的基本功。
> - **模型搭建**: 学习了通过继承 `nn.Module` 和利用 `nn.Sequential` 来创建自定义网络。
> - **自动管理**: 理解了PyTorch如何自动追踪参数 (`.parameters()`) 并与优化器 (`optimizer`) 无缝集成。
> - **核心实践技能**:
>   - 设备迁移 (`.to(device)`)
>   - 状态保存与加载 (`state_dict`)
>   - 模式切换 (`.train()` / `.eval()`)
>   - 数据增强 (`transforms`)

### Ⅱ. 卷积神经网络 (CNN)：攻克空间数据

> [!example]
> 针对图像等空间数据，我们深入探讨了CNN的革命性设计。
> - **核心思想**: 通过 **局部感受野** 和 **权重共享** 两大创新，极大地减少了参数量并保留了空间信息。
> - **架构控制**: 掌握了通过**卷积核 (Kernel)**、**步长 (Stride)** 和**填充 (Padding)** 来精确控制网络结构与输出尺寸。

### Ⅲ. 循环神经网络 (RNN/LSTM)：解读序列密码

> [!help]
> 对于文本、语音等序列数据，我们转向了RNN及其强大的变体LSTM。
> - **RNN**: 学习了其通过**隐藏状态**实现记忆，并通过**权重共享**处理变长序列的基本原理。
> - **核心挑战**: 深入分析了RNN在处理长序列时，因梯度累乘导致的**梯度消失/爆炸**问题。
> - **LSTM**: 作为解决方案，我们详细解析了LSTM如何通过**“三门”结构（遗忘、输入、输出）** 和独立的**“细胞状态”**，创建了一条梯度的“高速公路”，从而有效建模长期依赖。

### Ⅳ. 生成对抗网络 (GAN)：从博弈到创造

> [!tip]
> 在无监督学习领域，我们重点剖析了GAN及其演进过程，见证了AI如何学会“创造”。
> > [!check] **标准GAN**
> > - **核心机制**: 理解了**生成器 (Generator)** 与 **判别器 (Discriminator)** 之间的“猫鼠游戏”般的**对抗博弈**。
> > - **理论瓶颈**: 剖析了其损失函数与**JS散度**的关联，并指出了当两个分布不重叠时，JS散度失效并导致**训练不稳定**的根本原因。

> > [!success] **WGAN & WGAN-GP**
> > - **革命性改进**: 学习了更先进的**Wasserstein GAN (WGAN)**，它用更优越的**Wasserstein距离**（推土机距离）替代了脆弱的JS散度。
> > - **稳定训练**: 掌握了**梯度惩罚 (Gradient Penalty)** 这一关键技术，它通过直接约束判别器的梯度，从根本上解决了训练不稳定的问题，极大地提升了生成模型的性能和可靠性。

### Ⅴ. 总结：从“如何实现”到“为何如此”

> [!summary]
> 整个学习路径贯穿了一条清晰的主线：不断发现问题，并用更巧妙的结构和数学原理去解决问题。从CNN对FCN的超越，到LSTM对RNN的改进，再到WGAN对GAN的革新，我们不仅学习了模型的使用方法，更深刻理解了驱动深度学习技术发展的内在逻辑。