# 第六章：大数定律 (The Law of Large Numbers)

> [!info] 课程进度与导读
> * **当前进度**：第6章内容不算太多，核心是**不等式估算**和**收敛概念**。
> * **后续安排**：第7章（下周讲完）、第8-9章（各一周半）。
> * **重要性**：本章是第7章（中心极限定理）的基础。如果搞不清楚本章的样本均值和方差的关系，后面会非常困难。
> * **学习建议**：课后必须复习，尤其是新的概念和公式推导，一定要亲手算一遍。

---

## 1. 直觉引入：硬币抛掷 (Coin Toss Intuition)

### 1.1 频率 vs 概率
假设我们抛掷一枚均匀硬币（Fair Coin），正面（Head）概率 $p=1/2$。

* **抛掷 10 次 ($n=10$)**：
    * 虽然期望是 5 次正面，但实际上经常不会刚好得到 5 次。
    * 计算得到刚好 5 次正面的概率：
      $$P(X=5) = \binom{10}{5} (0.5)^5 (0.5)^5 \approx 0.246$$
    * **结论**：只有约 25% 的概率刚好是一半正面。

* **抛掷 100 次 ($n=100$)**：
    * 刚好得到 50 次正面的概率更低：
      $$P(X=50) \approx 0.0796$$
    * **现象**：随着次数 $n$ 增加，**刚好**等于期望值的概率在下降（因为可能的结果总数变多了，概率被分散了）。

### 1.2 频率的集中趋势 (Concentration of Measure)
虽然“刚好等于均值”的概率变小了，但是**频率落在均值附近**的概率却变大了。

* **案例对比**：我们希望正面出现的比例在 $0.4 \sim 0.6$ 之间（即 $40\% \sim 60\%$）。
    * **当 $n=10$ 时**：
      $$P(4 \le X \le 6) \approx 0.65$$
    * **当 $n=100$ 时**：
      $$P(40 \le X \le 60) \approx 0.964$$
* **结论（大数定律的雏形）**：试验次数 $n$ 越多，观测到的频率（Proportion）就越聚拢在真实概率（Expectation）附近。

---

## 2. 基础定义 (Definitions)

在进入定理前，需要明确三个关于随机变量序列的概念：

> [!abstract] 定义 1：随机变量序列 (Sequence of Random Variables)
> 连续进行多次试验，记 $X_n$ 为第 $n$ 次试验的结果。
> $$X_1, X_2, \dots, X_n$$
> * **例子**：抛硬币，$X_i=1$ (Head), $X_i=0$ (Tail)。每一个 $X_i$ 都是独立的伯努利分布（Bernoulli Distribution），$P=1/2$。

> [!abstract] 定义 2：前 n 次的和 (Sum of First n Trials)
> 令 $Y_n$ 为前 $n$ 次结果的总和：
> $$Y_n = \sum_{i=1}^{n} X_i$$
> * **分布性质**：如果 $X_i$ 是独立的伯努利分布，那么 $Y_n$ 服从**二项分布 (Binomial Distribution)** $B(n, p)$。

> [!abstract] 定义 3：频率 / 样本均值 (Sample Proportion / Mean)
> 令 $Z_n$（或记为 $\bar{X}_n$）为前 $n$ 次结果的平均值（或频率）：
> $$Z_n = \frac{Y_n}{n} = \frac{1}{n} \sum_{i=1}^{n} X_i$$
> * **取值范围**：$0 \le Z_n \le 1$。
> * **本质**：这就是我们后面要讲的 **样本均值 (Sample Mean)**。

---

## 3. 两个核心不等式 (Important Inequalities)

这两个不等式允许我们在**不知道具体分布函数**（PDF/PMF）的情况下，仅通过**均值**和**方差**来估算概率的上界。

### 3.1 马尔可夫不等式 (Markov's Inequality)

> [!example] 定理 6.2.1：马尔可夫不等式
> 设 $X$ 是一个**非负**随机变量（即 $P(X<0)=0$）。对于任意常数 $t > 0$：
> $$P(X \ge t) \le \frac{E[X]}{t}$$

* **直观理解**：如果均值 $E[X]$ 很小，那么 $X$ 取极大值 $t$ 的概率一定很小。
* **条件**：必须满足 $X \ge 0$。如果 $X$ 可能为负数，此定理不适用。

> [!note]- **证明过程 (Proof)**
> 假设 $X$ 是连续型随机变量，PDF 为 $f(x)$（离散型用求和代替积分同理）：
>
> $$E[X] = \int_{-\infty}^{\infty} x f(x) dx = \int_{0}^{\infty} x f(x) dx \quad (\text{因为 } X \ge 0)$$
>
> 将积分区间分为两部分：$[0, t)$ 和 $[t, \infty)$：
> $$E[X] = \int_{0}^{t} x f(x) dx + \int_{t}^{\infty} x f(x) dx$$
>
> 因为 $x \ge 0$，第一部分积分 $\int_{0}^{t} x f(x) dx \ge 0$，我们将其舍去（放缩）：
> $$E[X] \ge \int_{t}^{\infty} x f(x) dx$$
>
> 在区间 $[t, \infty)$ 上，由于 $x \ge t$，所以可以将 $x$ 换成 $t$ 继续放缩：
> $$\int_{t}^{\infty} x f(x) dx \ge \int_{t}^{\infty} t f(x) dx = t \int_{t}^{\infty} f(x) dx$$
>
> 而 $\int_{t}^{\infty} f(x) dx$ 正是概率 $P(X \ge t)$。所以：
> $$E[X] \ge t \cdot P(X \ge t)$$
> 移项得证：$P(X \ge t) \le \frac{E[X]}{t}$。

### 3.2 切比雪夫不等式 (Chebyshev's Inequality)

> [!example] 定理 6.2.2：切比雪夫不等式
> 设 $X$ 是任意随机变量，均值 $\mu$ 和方差 $\sigma^2$ 存在。对于任意 $t > 0$：
> $$P(|X - \mu| \ge t) \le \frac{\text{Var}(X)}{t^2}$$

* **直观理解**：随机变量 $X$ 偏离其均值 $\mu$ 的距离超过 $t$ 的概率，被其方差控制。方差越小，偏离大概率越小。
* **特点**：这是马尔可夫不等式的一个特例应用。

> [!note]- **证明过程 (Proof)**
> 定义新变量 $Y = (X - \mu)^2$。
> 1. 显然平方项 $Y \ge 0$，满足马尔可夫不等式的条件。
> 2. $Y$ 的期望 $E[Y] = E[(X - \mu)^2] = \text{Var}(X)$。
> 3. 我们要估计的事件是 $|X - \mu| \ge t$，这等价于 $(X - \mu)^2 \ge t^2$，也就是 $Y \ge t^2$。
>
> 对 $Y$ 应用马尔可夫不等式：
> $$P(Y \ge t^2) \le \frac{E[Y]}{t^2}$$
> 代回 $X$ 的形式：
> $$P(|X - \mu| \ge t) \le \frac{\text{Var}(X)}{t^2}$$
> 得证。

* **局限性**：这两个不等式给出的只是一个**上界 (Upper Bound)**，而且往往是一个很宽泛（Loose）的估计。
    * *例子*：真实概率可能是 0.01，但不等式算出来告诉你 $\le 0.8$。虽然不够精确，但在理论推导（如大数定律证明）中非常有用。

---

## 4. 样本均值 (Sample Mean) 与 大数定律

这是本章的核心：如何从单次实验推广到多次实验的平均值。

### 4.1 样本均值与方差的关系

假设 $X_1, X_2, \dots, X_n$ 是独立同分布 (i.i.d.) 的样本，总体均值为 $\mu$，总体方差为 $\sigma^2$。
定义 **样本均值 (Sample Mean)**：
$$\bar{X}_n = \frac{1}{n} \sum_{i=1}^{n} X_i$$

> [!failure] ⚠️ 关键易错点 (Critical Point)
> 请务必区分 **单次样本** 和 **样本均值** 的方差！
>
> 1. **样本均值的期望**：
>    $$E[\bar{X}_n] = \mu$$
>    *(解释：平均值的期望 = 总体的期望)*
>
> 2. **样本均值的方差**：
>    $$\text{Var}(\bar{X}_n) = \frac{\sigma^2}{n}$$
>    *(推导：$\text{Var}(\frac{1}{n}\sum X_i) = \frac{1}{n^2}\sum \text{Var}(X_i) = \frac{1}{n^2} \cdot n\sigma^2 = \frac{\sigma^2}{n}$)*
>
> **重点**：在使用切比雪夫不等式分析 $\bar{X}_n$ 时，分子的方差项必须用 $\frac{\sigma^2}{n}$，而不是 $\sigma^2$！

### 4.2 切比雪夫不等式在样本均值上的应用
对于样本均值 $\bar{X}_n$，切比雪夫不等式变为：
$$P(|\bar{X}_n - \mu| \ge t) \le \frac{\text{Var}(\bar{X}_n)}{t^2} = \frac{\sigma^2}{n t^2}$$

---

## 5. 典型例题详解 (Examples)

### 例题 1：确定样本量 (Sample Size Determination)
**题目**：
从一个分布中取样，均值 $\mu$ 未知，但已知标准差 $\sigma \le 2$。我们要确定样本量 $n$，使得样本均值 $\bar{X}_n$ 与真实均值 $\mu$ 的偏差小于 1 的概率至少为 0.99。

**解析**：
1. **翻译题目条件**：
    * 已知：$\sigma \le 2 \Rightarrow \text{Var}(X) = \sigma^2 \le 4$。
    * 目标：$P(|\bar{X}_n - \mu| < 1) \ge 0.99$。

2. **转换为切比雪夫形式**：
    切比雪夫不等式给出的是“大于等于”的概率上界。利用对立事件：
    目标等价于：$P(|\bar{X}_n - \mu| \ge 1) \le 1 - 0.99 = 0.01$。

3. **列出不等式**：
    $$P(|\bar{X}_n - \mu| \ge 1) \le \frac{\text{Var}(\bar{X}_n)}{1^2} = \frac{\sigma^2/n}{1}$$

4. **代入计算**：
    我们知道 $\sigma^2 \le 4$，所以：
    $$\frac{4}{n} \le 0.01$$
    $$n \ge \frac{4}{0.01} = 400$$

**结论**：至少需要采样 400 次。

### 例题 2：抛硬币次数 (Coin Toss Proportion)
**题目**：
抛掷均匀硬币，$X_i$ 为伯努利分布（1为正面，0为反面）。计算需要抛掷多少次，才能使“正面出现的比例”落在 $0.4 \sim 0.6$ 之间的概率至少为 0.7？

**解析**：
1. **参数识别**：
    * $X_i \sim \text{Bernoulli}(0.5)$。
    * 均值 $\mu = p = 0.5$。
    * 单次方差 $\sigma^2 = p(1-p) = 0.5 \times 0.5 = 0.25$。
    * 目标区间：$[0.4, 0.6]$，即与均值 $0.5$ 的距离 $t = 0.1$。

2. **构建目标**：
    我们希望 $P(0.4 \le \bar{X}_n \le 0.6) \ge 0.7$。
    即 $P(|\bar{X}_n - 0.5| < 0.1) \ge 0.7$。
    转为对立事件（切比雪夫形式）：
    $$P(|\bar{X}_n - 0.5| \ge 0.1) \le 1 - 0.7 = 0.3$$

3. **应用公式**：
    $$P(|\bar{X}_n - \mu| \ge t) \le \frac{\sigma^2}{n t^2}$$
    代入数值：
    $$\frac{0.25}{n \cdot (0.1)^2} \le 0.3$$
    $$\frac{0.25}{0.01 n} \le 0.3$$
    $$\frac{25}{n} \le 0.3$$

4. **求解**：
    $$n \ge \frac{25}{0.3} \approx 83.33$$
    取整数 $n \ge 84$。

### 例题 3：直方图与区间概率 (Histograms & Intervals)
> [!example] 将任意分布转化为伯努利分布
> **背景**：这个例子解释了为什么我们可以用“频率”来估计“概率”（即直方图的原理）。
>
> **设定**：
> 设 $X_1, X_2, \dots$ 是独立同分布 (i.i.d.) 的随机变量序列。我们想知道 $X$ 落在区间 $[c_1, c_2)$ 的概率。
>
> **转换方法**：
> 定义一个新的指示变量 (Indicator Variable) $Y_i$：
> * 如果 $c_1 \le X_i < c_2$，则 $Y_i = 1$。
> * 否则，$Y_i = 0$。
>
> 这样，$Y_i$ 就变成了一个**伯努利随机变量**。
> * $P(Y_i=1) = P(c_1 \le X_i < c_2) = p$。
>
> **结论**：
> 根据伯努利大数定律，样本均值 $\bar{Y}_n$（即落在该区间内的样本比例）将依概率收敛于该区间的真实概率：
> $$\bar{Y}_n = \frac{\text{落在区间内的次数}}{总次数} \xrightarrow{p} P(c_1 \le X_i < c_2)$$

### 例题 4：平均等待时间 (Average Waiting Time)
> [!example] 均匀分布的应用
> **题目描述**：
> 假设一家店正在服务顾客，第 $i$ 位顾客的等待时间 $X_i$ 服从区间 $[0, 1]$ 上的**均匀分布 (Uniform Distribution)**。假设所有 $X_i$ 都是独立的。
>
> **分析**：
> 1. **识别参数**：
>    * 对于均匀分布 $U[0, 1]$，其均值 $\mu = \frac{0+1}{2} = 0.5$。
>    * 这意味着理论上的平均等待时间是 0.5 小时（或单位时间）。
>
> 2. **应用大数定律**：
>    * 我们考察 $n$ 个顾客的**样本均值** $\bar{X}_n = \frac{1}{n}\sum X_i$。
>    * 根据大数定律（Theorem 6.2.4），当 $n$ 足够大时，样本均值 $\bar{X}_n$ 会依概率收敛于总体均值 $\mu$。
>
> **结论**：
> $$\bar{X}_n \xrightarrow{p} 0.5$$
> 也就是说，虽然每个人的等待时间是随机的，但如果统计足够多的人，他们的**平均**等待时间几乎一定是 0.5。

---

## 6. 依概率收敛 (Convergence in Probability)

这是一个比较抽象的概念，**不要求证明**，但要理解其物理含义。

> [!abstract] 定义：依概率收敛
> 序列 $Z_1, Z_2, \dots, Z_n$ **依概率收敛** 到常数 $b$，如果对于任意微小的正数 $\epsilon > 0$：
> $$\lim_{n \to \infty} P(|Z_n - b| < \epsilon) = 1$$
> 或者等价地写作（对立面）：
> $$\lim_{n \to \infty} P(|Z_n - b| \ge \epsilon) = 0$$
> 记作：$Z_n \xrightarrow{p} b$。

* **物理意义**：当 $n \to \infty$ 时，随机变量 $Z_n$ 的分布会无限地“聚拢”在数值 $b$ 的周围。虽然它可能稍微偏离 $b$，但偏离的概率会趋向于 0。
* **连续映射定理**：如果 $Z_n \xrightarrow{p} b$，且函数 $g(\cdot)$ 在 $b$ 点连续，那么 $g(Z_n) \xrightarrow{p} g(b)$。

### 伯努利大数定律 (Bernoulli's Law of Large Numbers)
这是大数定律最简单的形式：
如果 $X_1, \dots, X_n$ 是参数为 $p$ 的伯努利试验样本。
那么样本均值（即成功的比例）依概率收敛于 $p$。
$$\bar{X}_n \xrightarrow{p} p$$

---

> [!summary] 本周总结与下节预告
> 1. **切比雪夫不等式**：给了我们在未知分布下，利用均值和方差进行估算的方法。
> 2. **样本均值方差**：$\text{Var}(\bar{X}_n) = \sigma^2/n$，这是导致大数定律成立的根本原因（$n$ 在分母，当 $n \to \infty$ 时方差趋于0，分布收缩成一个点）。
> 3. **下节课预告**：我们将学习 **中心极限定理 (Central Limit Theorem)**。这是概率论中最重要、最基石的定理（地位等同于微积分基本定理），它将解释为什么正态分布如此常见。

