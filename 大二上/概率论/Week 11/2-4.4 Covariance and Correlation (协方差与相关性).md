# æ¦‚ç‡è®º Lecture 4.4: åæ–¹å·® (Covariance) & ç›¸å…³ç³»æ•° (Correlation)

> [!abstract] è¯¾ç¨‹å‰è¨€ä¸å¤ä¹  (Review & Motivation)
> * **å›é¡¾ (Review):** ä¸ŠèŠ‚è¯¾æˆ‘ä»¬å­¦ä¹ äº†ä¸‰ä¸ªæ ¸å¿ƒæ¦‚å¿µï¼š**Elements (Raw Moments, åŸç‚¹çŸ©)**ã€**Central Moments (ä¸­å¿ƒçŸ©)** ä»¥åŠæœ€é‡è¦çš„ **Moment Generating Function (MGF, åŠ¨å·®ç”Ÿæˆå‡½æ•°)**ã€‚
>     * MGF ä¸ä»…èƒ½ç”Ÿæˆ First Moment (ä¸€é˜¶çŸ©/å‡å€¼)ï¼Œè¿˜èƒ½ç”Ÿæˆ Second Momentï¼Œä»è€Œè®©æˆ‘ä»¬è®¡ç®—æ–¹å·® $Var(X) = E[X^2] - (E[X])^2$ã€‚
> * **æœ¬èŠ‚ç›®æ ‡ (Goal):** ä»Šå¤©æˆ‘ä»¬è¦è¿›å…¥ 4.4 ç« èŠ‚ï¼Œè®¨è®º **åæ–¹å·® (Covariance)** å’Œ **ç›¸å…³ç³»æ•° (Correlation)**ã€‚è¿™æ˜¯ä¸ºäº†é‡åŒ–**ä¸¤ä¸ª**éšæœºå˜é‡ä¹‹é—´çš„å…³ç³»ã€‚
> * **ç›´è§‚ä¾‹å­ (Motivation):** æƒ³è±¡é«˜ä¸­å‚åŠ æ ‡å‡†è€ƒè¯•ã€‚
>     * å¦‚æœä¸€ä¸ªå­¦ç”Ÿ **æ•°å­¦ (Math)** è€ƒå¾—å¥½ï¼Œé€šå¸¸æ„å‘³ç€ä»–æ¯”è¾ƒèªæ˜æˆ–åŠªåŠ›ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é¢„æœŸä»–çš„ **è‹±è¯­ (Verbal)** æˆç»©è™½ç„¶ä¸ä¸€å®šé¡¶å°–ï¼Œä½†è‡³å°‘åº”è¯¥æ¯”å¹³å‡æ°´å¹³å¥½ã€‚
>     * è¿™ç§â€œä¸€ä¸ªé«˜ï¼Œå¦ä¸€ä¸ªä¹Ÿå€¾å‘äºé«˜â€çš„å…³ç³»ï¼Œå°±æ˜¯æˆ‘ä»¬æƒ³é€šè¿‡ Joint Distribution (è”åˆåˆ†å¸ƒ) æ•æ‰çš„ç‰¹å¾ã€‚
> * **é¢„è­¦:** æœ¬èŠ‚è¯¾åŒ…å«å¤§é‡è®¡ç®—å’Œè¯æ˜ï¼ˆå¦‚æŸ¯è¥¿-æ–½ç“¦èŒ¨ä¸ç­‰å¼ï¼‰ï¼Œè€Œä¸”ä¸‹å‘¨è¯¾ç¨‹éš¾åº¦ä¼šç»§ç»­åŠ å¤§ï¼Œè¯·åŠ¡å¿…è·Ÿä¸Šè¿›åº¦ï¼Œä¸è¦ç¼ºè¯¾ï¼

---

## 1. åæ–¹å·® (Covariance)

### 1.1 å®šä¹‰ (Definition)

> [!NOTE] ğŸ“ Definition 4.6.1
> è®¾ $X$ å’Œ $Y$ æ˜¯ä¸¤ä¸ªå…·æœ‰æœ‰é™å‡å€¼çš„éšæœºå˜é‡ï¼Œè®° $\mu_X = E[X]$, $\mu_Y = E[Y]$ã€‚
> $X$ å’Œ $Y$ çš„**åæ–¹å·®**å®šä¹‰ä¸ºï¼š
> $$Cov(X, Y) = E[(X - \mu_X)(Y - \mu_Y)]$$
>
> **ç›´è§‚ç†è§£:**
> * å®ƒæ˜¯ $(X-\mu_X)$ å’Œ $(Y-\mu_Y)$ ä¹˜ç§¯çš„æœŸæœ›ã€‚
> * æœ¬è´¨ä¸Šå’Œæ–¹å·®å®šä¹‰ $Var(X) = E[(X-\mu_X)^2]$ æ˜¯ä¸€æ ·çš„ï¼Œåªæ˜¯æŠŠå…¶ä¸­ä¸€é¡¹æ¢æˆäº†å¦ä¸€ä¸ªå˜é‡ã€‚
> * å¦‚æœ $X > \mu_X$ ä¸” $Y > \mu_Y$ (åŒå‘åç¦»)ï¼Œä¹˜ç§¯ä¸ºæ­£ï¼›å¦‚æœä¸€æ­£ä¸€è´Ÿï¼Œä¹˜ç§¯ä¸ºè´Ÿã€‚
> 
> **ä¹¦å†™å»ºè®®:** è€å¸ˆå»ºè®®åœ¨ä¹¦å†™æœŸæœ›æ—¶ï¼Œå¤–å±‚ä½¿ç”¨**æ–¹æ‹¬å·** `[]`ï¼Œå†…éƒ¨é¡¹ä½¿ç”¨**åœ†æ‹¬å·** `()`ï¼Œä¾‹å¦‚ $E[(X - \mu_X)(Y - \mu_Y)]$ï¼Œè¿™æ ·ä¹¦å†™æ›´è§„èŒƒã€‚

### 1.2 è®¡ç®—å…¬å¼ (Shortcut Formula)

ç›´æ¥ç”¨å®šä¹‰è®¡ç®—éœ€è¦ç§¯åˆ†ä¸¤é¡¹ä¹‹å·®ï¼Œéå¸¸ç¹çã€‚æˆ‘ä»¬é€šå¸¸ä½¿ç”¨å±•å¼€åçš„å…¬å¼ï¼ˆè¿™æ˜¯è§£é¢˜çš„å…³é”®ï¼‰ï¼š

> [!tip] â­ Theorem 4.6.1: è®¡ç®—å…¬å¼
> $$Cov(X, Y) = E[XY] - E[X]E[Y]$$

**è¯æ˜ (Proof):**
åˆ©ç”¨æœŸæœ›çš„çº¿æ€§æ€§è´¨å±•å¼€ï¼š
$$
\begin{aligned}
Cov(X, Y) &= E[(X - \mu_X)(Y - \mu_Y)] \\
&= E[XY - X\mu_Y - Y\mu_X + \mu_X\mu_Y] \quad \text{(å±•å¼€æ‹¬å·)} \\
&= E[XY] - \mu_Y E[X] - \mu_X E[Y] + \mu_X\mu_Y \quad (\text{æ³¨æ„: } \mu \text{ æ˜¯å¸¸æ•°ï¼Œæå‡ºå»}) \\
&= E[XY] - \mu_Y \mu_X - \mu_X \mu_Y + \mu_X\mu_Y \\
&= E[XY] - \mu_X \mu_Y \\
&= E[XY] - E[X]E[Y] \quad \text{Q.E.D.}
\end{aligned}
$$

---

## 2. å®æˆ˜è®¡ç®—è¯¦è§£ (Detailed Calculation)

è¿™é“é¢˜æ˜¯è¯¾å ‚ä¸Šè€å¸ˆèŠ±äº†å¾ˆå¤šæ—¶é—´è®²è§£çš„é‡ç‚¹ï¼Œæ¶µç›–äº†è¾¹ç¼˜åˆ†å¸ƒã€æœŸæœ›ç§¯åˆ†å’Œåæ–¹å·®è®¡ç®—çš„å…¨è¿‡ç¨‹ã€‚

> [!example] ğŸ“– Example 4.6.2 & 4.6.3
> **é¢˜ç›®:** è®¾è”åˆæ¦‚ç‡å¯†åº¦å‡½æ•°ä¸ºï¼š
> $$f(x,y) = \begin{cases} 2xy + \frac{1}{2}, & 0 < x < 1, 0 < y < 1 \\ 0, & \text{å…¶ä»–} \end{cases}$$
> **ä»»åŠ¡:** è®¡ç®— $Cov(X, Y)$ å’Œ ç›¸å…³ç³»æ•° $\rho_{XY}$ã€‚

### Step 1: æ±‚è¾¹ç¼˜åˆ†å¸ƒ (Marginal Distributions)
æˆ‘ä»¬éœ€è¦å…ˆæŠŠ $f(x,y)$ å¯¹ $y$ ç§¯åˆ†å¾—åˆ° $f_X(x)$ï¼š
$$
\begin{aligned}
f_X(x) &= \int_0^1 f(x,y) dy = \int_0^1 (2xy + \frac{1}{2}) dy \\
&= \left[ xy^2 + \frac{1}{2}y \right]_{y=0}^{y=1} \\
&= (x \cdot 1^2 + 0.5 \cdot 1) - 0 \\
&= x + \frac{1}{2} \quad (\text{å¯¹äº } 0 < x < 1)
\end{aligned}
$$
åŒç†ï¼ˆå› ä¸ºå‡½æ•°å…³äº $x,y$ å¯¹ç§°ï¼‰ï¼Œ$f_Y(y) = y + \frac{1}{2}$ã€‚

### Step 2: è®¡ç®—æœŸæœ› (Means)
$$
\begin{aligned}
\mu_X = E[X] &= \int_0^1 x \cdot f_X(x) dx = \int_0^1 x(x + \frac{1}{2}) dx \\
&= \int_0^1 (x^2 + \frac{1}{2}x) dx \\
&= \left[ \frac{x^3}{3} + \frac{x^2}{4} \right]_0^1 = \frac{1}{3} + \frac{1}{4} = \frac{7}{12}
\end{aligned}
$$
åŒç†ï¼Œ$\mu_Y = \frac{7}{12}$ã€‚

### Step 3: è®¡ç®—æ··åˆçŸ© $E[XY]$ (å…³é”®ç§¯åˆ†æ­¥éª¤)
è¿™æ˜¯æœ€å®¹æ˜“å‡ºé”™çš„åœ°æ–¹ï¼Œéœ€è¦å¯¹è”åˆå¯†åº¦ç§¯åˆ†ï¼š
$$E[XY] = \int_0^1 \int_0^1 xy \cdot f(x,y) dx dy = \int_0^1 \int_0^1 xy(2xy + \frac{1}{2}) dx dy$$

å±•å¼€è¢«ç§¯å‡½æ•°ï¼š$2x^2y^2 + \frac{1}{2}xy$ã€‚
1. **å…ˆå¯¹ $x$ ç§¯åˆ†:**
$$
\int_0^1 (2x^2y^2 + \frac{1}{2}xy) dx = \left[ \frac{2}{3}x^3y^2 + \frac{1}{4}x^2y \right]_{x=0}^{x=1} = \frac{2}{3}y^2 + \frac{1}{4}y
$$
2. **å†å¯¹ $y$ ç§¯åˆ†:**
$$
E[XY] = \int_0^1 (\frac{2}{3}y^2 + \frac{1}{4}y) dy = \left[ \frac{2}{9}y^3 + \frac{1}{8}y^2 \right]_0^1 = \frac{2}{9} + \frac{1}{8} = \frac{16+9}{72} = \frac{25}{72}
$$

### Step 4: è®¡ç®—åæ–¹å·® (Covariance)
åˆ©ç”¨å…¬å¼ $Cov = E[XY] - E[X]E[Y]$ï¼š
$$Cov(X, Y) = \frac{25}{72} - \left(\frac{7}{12}\right)\left(\frac{7}{12}\right) = \frac{50}{144} - \frac{49}{144} = \frac{1}{144}$$

### Step 5: è®¡ç®—ç›¸å…³ç³»æ•° (Correlation) (Example 4.6.3)
æˆ‘ä»¬éœ€è¦å…ˆè®¡ç®—æ–¹å·® $\sigma_X^2$ã€‚
$$E[X^2] = \int_0^1 x^2 f_X(x) dx = \int_0^1 x^2(x+0.5) dx = \int_0^1 (x^3 + 0.5x^2) dx = \frac{1}{4} + \frac{1}{6} = \frac{5}{12}$$
$$\sigma_X^2 = E[X^2] - (\mu_X)^2 = \frac{5}{12} - \left(\frac{7}{12}\right)^2 = \frac{60}{144} - \frac{49}{144} = \frac{11}{144}$$
å› ä¸ºå¯¹ç§°ï¼Œ$\sigma_Y^2 = \frac{11}{144}$ã€‚

æœ€ç»ˆç›¸å…³ç³»æ•°ï¼š
$$\rho = \frac{Cov(X,Y)}{\sigma_X \sigma_Y} = \frac{1/144}{\sqrt{11/144}\sqrt{11/144}} = \frac{1/144}{11/144} = \frac{1}{11}$$

---

## 3. æŸ¯è¥¿-æ–½ç“¦èŒ¨ä¸ç­‰å¼ (Cauchy-Schwarz Inequality)

è¿™ä¸ªå®šç†æ˜¯è¯æ˜ç›¸å…³ç³»æ•°èŒƒå›´çš„åŸºç¡€ã€‚è€å¸ˆå¼ºè°ƒï¼šè™½ç„¶è€ƒè¯•å¯èƒ½ä¸ç›´æ¥è€ƒè¯æ˜ï¼Œä½†å¿…é¡»ç†è§£å…¶ä¸­çš„æ„é€ é€»è¾‘ï¼Œè¿™åœ¨æ•°å­¦åˆ†æä¸­ä¹Ÿéå¸¸é‡è¦ã€‚

> [!important] ğŸš© Theorem 4.6.2
> å¦‚æœ $E[U^2]$ å’Œ $E[V^2]$ å­˜åœ¨ï¼Œåˆ™ï¼š
> $$(E[UV])^2 \le E[U^2]E[V^2]$$
> **ç­‰å·æˆç«‹æ¡ä»¶:** å½“ä¸”ä»…å½“å­˜åœ¨å¸¸æ•° $a, b$ (ä¸å…¨ä¸º0) ä½¿å¾— $P(aU + bV = 0) = 1$ã€‚

**è¯æ˜æ€è·¯ (Proof Sketch):** è€å¸ˆåˆ†äº†ä¸‰ç§æƒ…å†µè®¨è®ºï¼Œä»¥ç¡®ä¿ä¸¥è°¨ã€‚

1.  **Case 1: $E[U^2] = 0$**
    * æ„å‘³ç€ $\int u^2 f(u) du = 0$ã€‚å› ä¸º $u^2 \ge 0$ ä¸” $f(u) \ge 0$ï¼Œå”¯ä¸€çš„å¯èƒ½æ˜¯ $P(U=0)=1$ï¼ˆ$U$ å‡ ä¹å¤„å¤„ä¸º0ï¼‰ã€‚
    * å¦‚æœ $U=0$ï¼Œé‚£ä¹ˆ $UV=0$ï¼Œæ‰€ä»¥ $E[UV]=0$ã€‚
    * ä¸ç­‰å¼å˜ä¸º $0 \le 0$ï¼Œæˆç«‹ã€‚
2.  **Case 2: å³è¾¹ä¸ºæ— ç©·å¤§**
    * å¦‚æœ $E[U^2] = \infty$ æˆ– $E[V^2] = \infty$ï¼Œä¸ç­‰å¼å³è¾¹æ— ç©·å¤§ï¼Œæ˜¾ç„¶æˆç«‹ã€‚
3.  **Case 3: æœ‰é™å€¼ (Finite Case) - æ ¸å¿ƒæ„é€ **
    * æ„é€ ä¸€ä¸ªéè´Ÿçš„äºŒæ¬¡å‹æœŸæœ›ï¼š
    $$0 \le E[(aU + bV)^2] = a^2 E[U^2] + b^2 E[V^2] + 2ab E[UV]$$
    * **å·§å¦™å–å€¼ (Substitution):**
        * ä»¤ $a = \sqrt{E[V^2]}$
        * ä»¤ $b = -\text{sgn}(E[UV]) \sqrt{E[U^2]}$ (æˆ–è€…ç®€å•ç†è§£ä¸ºå–é€‚å½“ç¬¦å·ä½¿å¾—ä¸­é—´é¡¹ä¸ºè´Ÿ)
    * ä»£å…¥åæ¶ˆå…ƒï¼Œå³å¯å¯¼å‡º $(E[UV])^2 \le E[U^2]E[V^2]$ã€‚

> **ç»“è®ºåº”ç”¨:** ä»¤ $U=X-\mu_X, V=Y-\mu_Y$ï¼Œä»£å…¥ä¸Šè¿°ä¸ç­‰å¼ï¼Œå³å¯è¯æ˜ $[Cov(X,Y)]^2 \le \sigma_X^2 \sigma_Y^2$ï¼Œä»è€Œæ¨å‡º $-1 \le \rho \le 1$ã€‚

---

## 4. ç›¸å…³ç³»æ•° (Correlation Coefficient)

å› ä¸ºåæ–¹å·®çš„å¤§å°å—å•ä½å½±å“ï¼ˆrescalingï¼‰ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ ‡å‡†åŒ–çš„åº¦é‡ã€‚

> [!NOTE] ğŸ“ å®šä¹‰
> $$\rho_{XY} = \frac{Cov(X, Y)}{\sigma_X \sigma_Y}$$
> * **èŒƒå›´:** $-1 \le \rho \le 1$
> * **æœ¯è¯­:**
>     * $\rho > 0$: **Positively correlated** (æ­£ç›¸å…³)
>     * $\rho < 0$: **Negatively correlated** (è´Ÿç›¸å…³)
>     * $\rho = 0$: **Uncorrelated** (ä¸ç›¸å…³)

### 4.1 ç‹¬ç«‹ vs ä¸ç›¸å…³ (æ˜“é”™ç‚¹!)

> [!success] âœ… å®šç† (Theorem 4.6.4)
> å¦‚æœ $X, Y$ **ç‹¬ç«‹ (Independent)** $\implies$ å®ƒä»¬ **ä¸ç›¸å…³ (Uncorrelated, $\rho=0$)**ã€‚
> **Proof:** ç‹¬ç«‹åˆ™ $f(x,y) = f_X(x)f_Y(y)$ï¼Œç§¯åˆ†å¯åˆ†ç¦» $\implies E[XY] = E[X]E[Y]$ï¼Œå¯¼è‡´ $Cov=0$ã€‚

> [!warning] âŒ é€†å‘½é¢˜ä¸æˆç«‹ï¼
> **ä¸ç›¸å…³ (Uncorrelated) $\nRightarrow$ ç‹¬ç«‹ (Independent)ã€‚**
> å³ä½¿ $\rho=0$ï¼Œå®ƒä»¬ä»å¯èƒ½æœ‰éçº¿æ€§çš„ä¾èµ–å…³ç³» (Dependent)ã€‚

**åä¾‹ 1 (ç¦»æ•£):**
* $X \in \{-1, 0, 1\}$ ç­‰æ¦‚ç‡ï¼Œ$Y = X^2$ã€‚
* æ˜¾ç„¶ $Y$ ä¾èµ– $X$ï¼Œä½†è®¡ç®—å¯å¾— $Cov(X,Y) = E[X^3] - E[X]E[X^2] = 0 - 0 = 0$ã€‚

**åä¾‹ 2 (è¿ç»­ - æåæ ‡ç§¯åˆ†æŠ€å·§):**
* $(X, Y)$ å‡åŒ€åˆ†å¸ƒåœ¨å•ä½åœ† $x^2+y^2 \le 1$ ä¸Šã€‚$f(x,y) = 1/\pi$ã€‚
* è®¡ç®— $E[XY]$ æ—¶ä½¿ç”¨ **æåæ ‡ (Polar Coordinates)**:
    * $x = r\cos\theta, y = r\sin\theta$ã€‚
    * **å…³é”®ç‚¹:** $dx dy$ å¿…é¡»å˜æˆ **$r dr d\theta$**ã€‚
    * è€å¸ˆå¼ºè°ƒï¼šè¿™é‡Œçš„ **$r$** æ˜¯ **Jacobian (å½¢å˜ç³»æ•°)**ï¼Œä»£è¡¨åæ ‡å˜æ¢æ—¶çš„é¢ç§¯æ‹‰ä¼¸ï¼Œåƒä¸‡ä¸èƒ½æ¼æ‰ï¼
    * $E[XY] = \frac{1}{\pi} \int_0^{2\pi} \int_0^1 (r\cos\theta)(r\sin\theta) \cdot r dr d\theta$
    * ç§¯åˆ†éƒ¨åˆ†å« $\int \sin\theta \cos\theta d\theta = \int \frac{1}{2}\sin(2\theta) = 0$ã€‚
    * ç»“è®º: $\rho=0$ï¼Œä½† $X,Y$ æ˜¾ç„¶ä¸ç‹¬ç«‹ï¼ˆå› ä¸º $X^2+Y^2 \le 1$ äº’ç›¸é™åˆ¶ï¼‰ã€‚

---

## 5. çº¿æ€§å˜æ¢ä¸æ–¹å·®æ±‚å’Œ (Linear Properties)

### 5.1 çº¿æ€§å˜æ¢ (Theorem 4.6.5)
å¦‚æœ $Y = aX + b$ ($a \ne 0$)ï¼š
* è‹¥ $a > 0 \implies \rho = 1$
* è‹¥ $a < 0 \implies \rho = -1$
* **è¯æ˜ç»†èŠ‚:** $Cov(X, aX+b) = a \sigma_X^2$ï¼Œè€Œ $\sigma_Y = |a|\sigma_X$ (**æ³¨æ„ç»å¯¹å€¼**)ï¼Œç›¸é™¤å¾— $a/|a|$ã€‚

### 5.2 æ–¹å·®çš„æ±‚å’Œ (Variance of Sums)

è¿™æ˜¯è§£å†³ **Homework Problem 8** çš„å…³é”®å…¬å¼ï¼

> [!tip] ğŸ’¡ ä¸¤ä¸ªå˜é‡ (Theorem 4.6.6)
> $$Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y)$$
> * è¯æ˜æ€è·¯ï¼šå±•å¼€ $E[((X-\mu_X) + (Y-\mu_Y))^2]$ã€‚
> * è‹¥ $X, Y$ ä¸ç›¸å…³ ($Cov=0$)ï¼Œåˆ™ç›´æ¥ç›¸åŠ ã€‚

> [!tip] ğŸ’¡ å¤šä¸ªå˜é‡ (Theorem 4.6.7) - ä½œä¸šæç¤º
> $$Var\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n Var(X_i) + 2 \sum_{1 \le i < j \le n} Cov(X_i, X_j)$$
> * **è§£é‡Š:** æ€»æ–¹å·® = å„è‡ªæ–¹å·®ä¹‹å’Œ + æ‰€æœ‰ä¸¤ä¸¤ç»„åˆçš„åæ–¹å·®çš„2å€ã€‚
> * **Action:** è€å¸ˆç‰¹åˆ«æåˆ°ï¼Œå®šç† 4.6.6 å’Œ 4.6.7 ä¸ **Homework ç¬¬8é¢˜** æ¯æ¯ç›¸å…³ã€‚è¯·æ ¹æ®è¿™ä¸ªå…¬å¼å»æ¨å¯¼ä½œä¸šé¢˜ã€‚

---

> [!check] è¯¾åè¡ŒåŠ¨æŒ‡å— (Next Steps)
> 1.  **å¤ä¹  (Review):** é®ä½ç¬”è®°ï¼Œé‡æ–°æ¨å¯¼ Example 4.6.2 çš„ç§¯åˆ†è¿‡ç¨‹ï¼Œç¡®ä¿ä½ èƒ½ç®—å‡º $1/144$ã€‚
> 2.  **ç†è§£ (Understand):** å¤è¿°æŸ¯è¥¿-æ–½ç“¦èŒ¨ä¸ç­‰å¼çš„æ„é€ æ³•è¯æ˜ã€‚
> 3.  **ä½œä¸š (Homework):** ç«‹å³ç€æ‰‹åš Homework ç¬¬8é¢˜ï¼Œåˆ©ç”¨ Theorem 4.6.7ã€‚
> 4.  **é¢„ä¹  (Preview):** ä¸‹å‘¨å†…å®¹éš¾åº¦ä¼šåŠ å¤§ï¼Œä¸è¦ç¼ºè¯¾ã€‚

