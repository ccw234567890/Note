# 统计推断：贝叶斯估计与最大似然估计

> [!abstract] 章节概览
> 本章节基于课堂板书整理，涵盖了参数估计的两大流派：
> 1.  **贝叶斯估计 (Bayes Estimation)**：
>     - 核心思想：参数 $\theta$ 是随机变量，具有先验分布。
>     - 关键计算：后验分布 $\xi(\theta|x) \propto f(x|\theta)\xi(\theta)$。
>     - 决策准则：最小化后验期望损失（平方损失对应后验均值）。
> 2.  **最大似然估计 (MLE)**：
>     - 核心思想：寻找使样本出现概率最大的参数值。
>     - 常见模型：泊松分布、均匀分布、伯努利分布。

---

## 1. 贝叶斯估计 (Bayes Estimation)

### 1.1 核心公式与流程 (Page 2)

**基本设定**：
*   $X_1, \dots, X_n$ 来自总体 $P(x|\theta)$。
*   $\theta$ 具有先验分布 $\xi(\theta)$ (Prior)。
*   似然函数 (Likelihood)：$f_n(\mathbf{x}|\theta) = \prod f(x_i|\theta)$。

**贝叶斯公式 (Bayes Theorem)**：
$$ \xi(\theta|\mathbf{x}) = \frac{f_n(\mathbf{x}|\theta)\xi(\theta)}{g_n(\mathbf{x})} $$
其中 $g_n(\mathbf{x})$ 是边缘分布（归一化常数）：
$$ g_n(\mathbf{x}) = \int f_n(\mathbf{x}|\theta)\xi(\theta) d\theta $$

**贝叶斯估计的五个步骤 (Bayes Test Steps)**：
1.  **确定 $\theta$ 的先验**：$\xi(\theta)$。
2.  **写出似然函数**：$f_n(\mathbf{x}|\theta)$。
3.  **确定损失函数 (Loss)**：$L(\theta, a)$。
4.  **计算期望损失**：$E[L(\theta, a) | \mathbf{x}]$ （即对后验分布求期望）。
5.  **最小化 (Minimize)**：寻找 $a$ 使得期望损失最小。
    $$ \min_a E[L(\theta, a) | \mathbf{x}] \implies \delta^*(x) $$

---

### 1.2 贝叶斯估计实例：投硬币 (Page 2 & 3)

**题目设定**：
*   $X \sim Bernoulli(p)$ (正面为1，反面为0)。
*   参数 $p$ 未知，先验分布为 $U(0,1)$。
    $$ \xi(p) = 1, \quad 0 < p < 1 $$
*   损失函数：平方损失 $L(p, a) = (p-a)^2$。

#### <font color="#2980b9">情境一：投掷 1 次，出现正面 ($X_1=1$)</font>
*   **似然**：$f(1|p) = p$。
*   **边缘分布**：$g(1) = \int_0^1 p \cdot 1 dp = [\frac{1}{2}p^2]_0^1 = \frac{1}{2}$。
*   **后验分布**：
    $$ \xi(p|x_1) = \frac{p \cdot 1}{1/2} = 2p $$
*   **贝叶斯估计** (后验均值)：
    $$ E[p|x_1] = \int_0^1 p \cdot (2p) dp = \int_0^1 2p^2 dp = \frac{2}{3} $$

#### <font color="#2980b9">情境二：投掷 2 次，正、正 ($X_1=1, X_2=1$)</font>
*   **似然**：$f(x|p) = p \cdot p = p^2$。
*   **边缘分布**：$\int_0^1 p^2 dp = \frac{1}{3}$。
*   **后验分布**：
    $$ \xi(p|x_1, x_2) = \frac{p^2}{1/3} = 3p^2 $$
*   **估计值**：$E = \int p \cdot 3p^2 = 3/4$。

#### <font color="#2980b9">情境三：投掷 3 次，正、正、反 ($X_1=1, X_2=1, X_3=0$)</font>
*   **似然**：$f(x|p) = p \cdot p \cdot (1-p) = p^2 - p^3$。
*   **边缘分布**：
    $$ \int_0^1 (p^2 - p^3) dp = [\frac{p^3}{3} - \frac{p^4}{4}]_0^1 = \frac{1}{3} - \frac{1}{4} = \frac{1}{12} $$
*   **后验分布**：
    $$ \xi(p|x) = \frac{p^2(1-p)}{1/12} = 12p^2(1-p) $$

---

### 1.3 推广：$n$ 次投掷与贝叶斯估计量的推导 (Page 3)

**一般情况**：
设 $n$ 次实验中有 $y$ 次正面 ($y = \sum x_i$)。
*   **后验分布**：
    $$ \xi(p|\mathbf{x}) = \frac{p^y(1-p)^{n-y}}{\int_0^1 p^y(1-p)^{n-y} dp} = \frac{p^y(1-p)^{n-y}}{B(y+1, n-y+1)} $$
    其中 $B(m,k) = \frac{(m-1)!(k-1)!}{(m+k-1)!}$。

#### <font color="#c0392b">补充推导：为什么平方损失对应后验均值？</font>
(对应 Page 3 中间部分的积分推导)

目标是最小化期望损失：
$$ Q(a) = E[(p-a)^2 | \mathbf{x}] = \int_0^1 (p-a)^2 \xi(p|\mathbf{x}) dp $$

为了求最小值，对 $a$ 求导并令其为 0：
$$ \frac{d}{da} \int_0^1 (p-a)^2 \xi(p|\mathbf{x}) dp = \int_0^1 \frac{\partial}{\partial a}(p-a)^2 \xi(p|\mathbf{x}) dp = 0 $$
$$ \int_0^1 -2(p-a) \xi(p|\mathbf{x}) dp = 0 $$
$$ \int_0^1 p \xi(p|\mathbf{x}) dp - a \underbrace{\int_0^1 \xi(p|\mathbf{x}) dp}_{=1 (\text{概率密度积分为1})} = 0 $$
$$ E[p|\mathbf{x}] - a = 0 \implies a = E[p|\mathbf{x}] $$

**结论**：在平方损失下，贝叶斯估计量就是**后验均值**。
对于本题：
$$ \hat{p}_{Bayes} = \frac{y+1}{n+2} $$

---

## 2. 最大似然估计 (MLE)

### 2.1 泊松分布 (Poisson Distribution) (Page 3)

**题目**：$X_i \sim P(\theta)$，概率质量函数 $P(X=k) = \frac{\theta^k e^{-\theta}}{k!}$。求 $\theta$ 的 MLE。

**解**：
1.  **似然函数**：
    $$ f_n(\mathbf{x}|\theta) = \prod_{i=1}^n \frac{\theta^{x_i}e^{-\theta}}{x_i!} = \frac{\theta^{\sum x_i} e^{-n\theta}}{\prod x_i!} $$
    令 $y = \sum x_i$。
2.  **对数似然**：
    $$ \ln f_n = y \ln \theta - n\theta - \ln(\prod x_i!) $$
3.  **求导**：
    $$ \frac{\partial \ln f_n}{\partial \theta} = \frac{y}{\theta} - n $$
4.  **讨论求解**：
    *   **情形 (a)**: 若样本中至少有一个非零值 ($y > 0$)，令导数为 0：
        $$ \frac{y}{\theta} - n = 0 \implies \hat{\theta} = \frac{y}{n} = \bar{x}_n $$
    *   **情形 (b)**: 若所有样本均为 0 ($y=0$)，似然函数为 $e^{-n\theta}$（单调递减）。
        在 $\theta \ge 0$ 的约束下，最大值在端点处取得：
        $$ \hat{\theta} = 0 $$
    *   **综上**：$\hat{\theta}_{MLE} = \bar{x}_n$。

---

### 2.2 均匀分布 (Uniform Distribution) (Page 4)

**题目**：$X_i \sim U[\theta_1, \theta_2]$，密度函数 $f(x) = \frac{1}{\theta_2 - \theta_1}, \theta_1 \le x \le \theta_2$。

**解**：
1.  **似然函数**：
    $$ f_n(\mathbf{x}|\theta) = \begin{cases} \frac{1}{(\theta_2 - \theta_1)^n} & \text{当 } \theta_1 \le x_{\min} \text{ 且 } x_{\max} \le \theta_2 \\ 0 & \text{其他} \end{cases} $$
    *(图示：区间 $[\theta_1, \theta_2]$ 必须包含所有样本点 $x_1, \dots, x_n$)*
2.  **最大化分析**：
    要使 $f_n$ 最大，即要使分母 $(\theta_2 - \theta_1)$ 最小。
    即我们要寻找一个**最短的区间**，该区间能覆盖所有的样本点。
    *   $\theta_1$ 应尽可能大 $\rightarrow \hat{\theta}_1 = x_{\min} = \min(X_i)$
    *   $\theta_2$ 应尽可能小 $\rightarrow \hat{\theta}_2 = x_{\max} = \max(X_i)$

---

### 2.3 伯努利分布 (Bernoulli) (Page 4)

**题目**：$X \sim B(1, p)$，求 $p$ 的 MLE。

**解**：
1.  **似然函数**：$f_n = p^y(1-p)^{n-y}$，其中 $y = \sum x_i$。
2.  **对数似然**：$\ln f_n = y \ln p + (n-y) \ln (1-p)$。
3.  **求导**：
    $$ \frac{y}{p} - \frac{n-y}{1-p} = 0 $$
    $$ y(1-p) = p(n-y) \implies y - yp = np - py \implies y = np $$
4.  **结果**：$\hat{p} = \frac{y}{n} = \bar{x}_n$。