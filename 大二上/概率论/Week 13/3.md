# 📖 Chapter 7: Statistical Inference & Bayes Estimation (Complete Note)

> [!abstract] 章节核心
> 本章详细记录了统计推断的定义、贝叶斯与频率派的对立视图，重点在于**贝叶斯估计 (Bayes Estimation)** 的完整推导。
> * **核心公式:** $Posterior \propto Likelihood \times Prior$
> * **关键推导:** 正态-正态共轭分布的配方法、损失函数的最小化证明。
> * **数值案例:** 包含了笔记中出现的荧光灯寿命计算、硬币序列更新计算等。

---

## 7.1 Statistical Inference (统计推断基础)

### 1. Statistical Model (统计模型)
> [!info] Definition 7.1.1: Statistical Model
> 一个统计模型必须包含以下三个要素：
> 1.  **Identification of Random Variables (识别随机变量):**
>     * **Observable (可观测的):** 也就是样本数据 $X_1, X_2, ..., X_n$。
>     * **Hypothetically observable:** 理论上可观测。
> 2.  **Specification of Distributions (分布设定):**
>     * 为随机变量指定具体的概率分布形式（如 $Exp(\lambda), Bernoulli(p)$）。
> 3.  **Identification of Parameters (参数识别):**
>     * 识别分布中的未知常量。

* **Definition 7.1.3 Parameter / Parameter Space:**
    * **Parameter ($\theta$):** 决定随机变量联合分布特征的量（Characteristic）。
    * **Parameter Space ($\Omega$):** 所有可能参数值的集合。
        * *Note:* 参数可以是标量，也可以是向量 $(\theta_1, ..., \theta_k)$。

#### 📝 Examples form Notes (笔记中的经典例子)
* **Example 7.1.1: Electronic Components (电子元件寿命)**
    * **RV:** $X_i$ (component life-times in years).
    * **Model:** Exponential distribution ($X_i \sim Exp(\lambda)$).
    * **Parameter:** $\lambda$ (failure rate, 失效率). 假设 $\lambda=2$。
* **Example 7.1.2: Clinical Trial (临床试验)**
    * **RV:** $X_i$ (第 $i$ 个病人是否康复)。$X_i=1$ (Recover), $X_i=0$ (Not recover).
    * **Model:** Bernoulli distribution.
    * **Parameter:** $p$ (Recover rate, 康复率).
    * **Parameter Space:** $\Omega = [0, 1]$.

### 2. Statistic (统计量)
> [!def] Definition 7.1.4: Statistic
> 假设 $X_1, ..., X_n$ 是可观测的随机变量。令 $r$ 为 $n$ 个变量的任意实值函数。
> 随机变量 $T = r(X_1, ..., X_n)$ 被称为一个**统计量 (Statistic)**。
> * **核心注意:** 统计量**不能**包含任何未知的参数。

* **Example 7.1.10 (Failure Times of Ball Bearings):**
    * 如果 $X_i$ 是轴承的失效时间，我们定义 $Y_i = \ln(X_i)$。
    * 这里 $Y_i$ 也是一个统计量。
    * 假设 $Y_i \sim N(\mu, \sigma^2)$，我们想对 $\mu$ 和 $\sigma^2$ 进行推断。

---

## 🆚 Bayesian vs. Classical Statistics (两大派别详解)

这是理解本章公式推导前提的关键哲学差异。

### 1. Bayesian Viewpoint (贝叶斯派)
1.  **核心观点:** 参数 $\theta$ 是**随机变量 (Random Variables)**。
2.  **分布:** 它们拥有分布，称为**先验分布 (Prior Distribution)**。
3.  **推断:** 我们可以直接对参数做概率陈述。
    * *Quote:* "There is 80% probability that $\theta > 0.5$."

### 2. Classical / Frequentist Viewpoint (经典/频率派)
1.  **核心观点:** 参数 $\theta$ 是**固定、确定性的量 (Fixed, deterministic quantities)**。
2.  **状态:** 它们只是恰好**未知 (Unknown)** 而已。
3.  **限制:** 我们**不能 (Cannot)** 给参数本身分配概率。
    * $\theta$ 要么是 0.5，要么不是，没有“概率”一说。
    * *Quote:* "The probability of observing this data is 0.03 (given $\theta=0.5$)."

---

## 7.2 Bayes Estimation (贝叶斯估计详细推导)

### 1. Definitions (先验与后验)
* **Prior Distribution (Definition 7.2.1):**
    在观测数据之前，分配给参数 $\theta$ 的分布 $\xi(\theta)$。
    * *Ex 7.2.3 (次品率):* 对 $\theta$ 一无所知，假设 $\theta \sim Uniform(0,1)$。
* **Posterior Distribution (Definition 7.2.x):**
    给定样本 $X_1, ..., X_n$ 后，$\theta$ 的条件分布，记为 $\xi(\theta | \mathbf{x})$。

### 2. Theorem 7.2.1: The Bayes Rule (贝叶斯公式)
给定样本联合分布 $f_n(\mathbf{x}|\theta)$ 和先验 $\xi(\theta)$，后验分布为：

$$\xi(\theta | \mathbf{x}) = \frac{f_n(\mathbf{x} | \theta) \xi(\theta)}{g_n(\mathbf{x})}$$

* **分母 $g_n(\mathbf{x})$ (Marginal PDF):**
    $$g_n(\mathbf{x}) = \int_{\Omega} f_n(\mathbf{x}|\theta)\xi(\theta) d\theta$$
    *(对于给定数据 $\mathbf{x}$，分母是一个常数，用于归一化)*

> [!tip] 核心口诀
> **Posterior $\propto$ Likelihood $\times$ Prior**
> **后验 $\propto$ 似然函数 $\times$ 先验**

---

### 3. Detailed Example Derivations (核心推导)

#### 🟢 Case 1: The Classical Estimation (频率派的做法)
*(笔记 Page 4 专门对比了这种做法)*
* 根据大数定律 (Law of Large Numbers)，样本均值收敛于真实均值：
    $$\lim_{n \to \infty} P\left( \left| \frac{n}{\sum_{i=1}^n X_i} - \theta \right| < \epsilon \right) = 1$$
* 样本均值 $\bar{X}_n = \frac{1}{n}\sum X_i$ 是总体均值 $1/\theta$ 的估计。
* 因此，**$\frac{1}{\bar{X}_n}$ 是 $\theta$ 的估计量**。

#### 🔵 Case 2: Bayesian Estimation (Gamma-Exponential Model)
*(笔记 Example 7.2.4: Fluorescent Lamps)*
* **Prior:** $\mu \sim$ Gamma (笔记中具体数值例子)。
    * $\mu_{prior} = 20000$, $\sigma_{prior} = 100$ (推断值)。
    * 分布形式 $\xi(\theta) \propto \theta^{\alpha-1} e^{-\beta \theta}$。
* **Posterior:** Gamma 分布是指数分布的共轭先验，后验依然是 Gamma 分布。

#### 🟣 Case 3: Beta-Bernoulli Model (Detailed Proof)
*(笔记 Example 7.2.7 & 7.4.3)*

1.  **Likelihood Function:**
    对于 Bernoulli 试验，似然函数是：
    $$f_n(\mathbf{x}|\theta) = \prod_{i=1}^n \theta^{x_i}(1-\theta)^{1-x_i} = \theta^{\sum x_i} (1-\theta)^{n-\sum x_i}$$
    令 $Y = \sum_{i=1}^n X_i$ (成功的总次数)，则：
    $$f_n(\mathbf{x}|\theta) = \theta^Y (1-\theta)^{n-Y}$$

2.  **Prior Distribution:**
    $$\xi(\theta) \sim Beta(\alpha, \beta) \propto \theta^{\alpha-1} (1-\theta)^{\beta-1}$$

3.  **Marginal Distribution $g_n(\mathbf{x})$ (分母积分细节):**
    笔记详细写出了利用 Beta 函数 $B(a,b)$ 进行积分的过程：
    $$
    \begin{aligned}
    g_n(\mathbf{x}) &= \int_0^1 \theta^Y (1-\theta)^{n-Y} \cdot \theta^{\alpha-1} (1-\theta)^{\beta-1} d\theta \\
    &= \int_0^1 \theta^{Y+\alpha-1} (1-\theta)^{n-Y+\beta-1} d\theta \\
    &= B(Y+\alpha, n-Y+\beta) \quad \text{(Beta Function Definition)} \\
    &= \frac{\Gamma(Y+\alpha)\Gamma(n-Y+\beta)}{\Gamma(n+\alpha+\beta)}
    \end{aligned}
    $$

4.  **Posterior Distribution:**
    $$\xi(\theta|\mathbf{x}) = \frac{\theta^{Y+\alpha-1}(1-\theta)^{n-Y+\beta-1}}{B(Y+\alpha, n-Y+\beta)}$$
    **结论:** $\theta | \mathbf{x} \sim Beta(\alpha + Y, \beta + n - Y)$。

---

#### 🔴 Case 4: Normal-Normal Model (The "Completing Square" Proof)
*(笔记 Page 5-7 最复杂的推导)*

**设定:**
* $X_1, ..., X_n \sim N(\theta, \sigma^2)$ ($\sigma^2$ 已知)。
* Prior $\theta \sim N(\mu_0, v_0^2)$。

**Step 1: Likelihood Expansion (代数恒等式证明)**
笔记 Page 6 详细推导了指数内部的展开：
$$
\begin{aligned}
\sum_{i=1}^n (X_i - \theta)^2 &= \sum_{i=1}^n [(X_i - \bar{X}_n) + (\bar{X}_n - \theta)]^2 \\
&= \sum (X_i - \bar{X}_n)^2 + \sum (\bar{X}_n - \theta)^2 + 2(\bar{X}_n - \theta)\underbrace{\sum (X_i - \bar{X}_n)}_{0} \\
&= \text{Const} + n(\bar{X}_n - \theta)^2
\end{aligned}
$$
所以，似然函数关于 $\theta$ 的核心部分是：
$$f_n(\mathbf{x}|\theta) \propto \exp\left[ -\frac{n}{2\sigma^2}(\theta - \bar{X}_n)^2 \right]$$

**Step 2: Combining Prior and Likelihood**
$$
\begin{aligned}
\xi(\theta|\mathbf{x}) &\propto \exp\left[ -\frac{1}{2v_0^2}(\theta - \mu_0)^2 \right] \cdot \exp\left[ -\frac{n}{2\sigma^2}(\theta - \bar{X}_n)^2 \right] \\
&\propto \exp\left[ -\frac{1}{2} \underbrace{\left( \frac{(\theta - \mu_0)^2}{v_0^2} + \frac{n(\theta - \bar{X}_n)^2}{\sigma^2} \right)}_{Q(\theta)} \right]
\end{aligned}
$$

**Step 3: Completing the Square (配方法)**
展开 $Q(\theta)$ 并整理系数：
$$Q(\theta) = \left( \frac{1}{v_0^2} + \frac{n}{\sigma^2} \right)\theta^2 - 2\left( \frac{\mu_0}{v_0^2} + \frac{n\bar{X}_n}{\sigma^2} \right)\theta + C$$
对比正态分布 $N(\mu_1, v_1^2)$ 的指数项 $\frac{1}{v_1^2}\theta^2 - \frac{2\mu_1}{v_1^2}\theta$，我们得到：

* **后验方差 ($v_1^2$):**
    $$\frac{1}{v_1^2} = \frac{1}{v_0^2} + \frac{n}{\sigma^2} \implies v_1^2 = \frac{\sigma^2 v_0^2}{\sigma^2 + n v_0^2}$$
* **后验均值 ($\mu_1$):**
    $$\frac{\mu_1}{v_1^2} = \frac{\mu_0}{v_0^2} + \frac{n\bar{X}_n}{\sigma^2} \implies \mu_1 = \frac{\sigma^2 \mu_0 + n v_0^2 \bar{X}_n}{\sigma^2 + n v_0^2}$$

> [!example] Page 7 Exercise (数值练习)
> **条件:** $\sigma^2=100, \mu_0=0, v_0^2=60, n=20, \bar{X}_n=0.125$.
> **计算:**
> * $Mean (\mu_1) = \frac{100(0) + 20(60)(0.125)}{100 + 20(60)} = \frac{150}{1300} \approx 0.1154$
> * $Var (v_1^2) = \frac{100 \times 60}{100 + 1200} = \frac{6000}{1300} \approx 4.615$

---

### 4. Sequential Updating (序列更新实例)
*(笔记 Page 7 底部关于 $P(E)=0.5$ 的详细积分过程)*

假设先验为 Uniform ($p \in [0,1]$)，即 $\xi(p)=1$。
1.  **观测 1 (Obs 1):** 似然 $p$.
    * Denominator: $\int_0^1 p dp = [\frac{1}{2}p^2]_0^1 = 1/2$.
    * Posterior: $p / (1/2) = 2p$.
2.  **观测 2 (Obs 2):** 似然 $p$. 新先验 $2p$.
    * Numerator: $p \cdot 2p = 2p^2$.
    * Denominator: $\int_0^1 2p^2 dp = [\frac{2}{3}p^3]_0^1 = 2/3$.
    * Posterior: $2p^2 / (2/3) = 3p^2$.
3.  **观测 3 (Obs 3):** 似然 $1-p$. 新先验 $3p^2$.
    * Numerator: $(1-p) \cdot 3p^2 = 3p^2 - 3p^3$.
    * Denominator: $\int_0^1 (3p^2 - 3p^3) dp = [p^3 - \frac{3}{4}p^4]_0^1 = 1 - 0.75 = 0.25 = 1/4$.
    * *(注: 笔记中此处采用了直接合并计算的方式，结果一致)*
    * Posterior: $\propto p^2(1-p)$. 归一化系数为 $12$. 即 $12p^2(1-p)$.

---

## 7.4 Bayes Estimators & Loss Functions (损失函数与估计量)

有了后验分布，我们选哪个具体的数作为估计值？这取决于**损失函数 (Loss Function)**。

### 1. Squared Error Loss (平方误差损失)
$$L(\theta, a) = (\theta - a)^2$$
目标：最小化 $E[(\theta - a)^2 | \mathbf{x}]$。

> [!tip] Proof: Variance Decomposition (方差分解证明)
> 笔记 Page 8 底部展示了该证明：
> 令 $\mu = E[\theta|\mathbf{x}]$ (后验均值)。
> $$
> \begin{aligned}
> E[(\theta - a)^2 | \mathbf{x}] &= E[(\theta - \mu + \mu - a)^2 | \mathbf{x}] \\
> &= E[(\theta - \mu)^2] + (\mu - a)^2 + 2(\mu - a)\underbrace{E[\theta - \mu]}_{0} \\
> &= \text{Var}(\theta|\mathbf{x}) + (\mu - a)^2
> \end{aligned}
> $$
> 显而易见，当且仅当 $a = \mu$ 时，损失最小。
> **结论:** **Bayes Estimator = Posterior Mean (后验均值)**.

### 2. Absolute Error Loss (绝对误差损失)
$$L(\theta, a) = |\theta - a|$$
目标：最小化 $g(a) = \int |\theta - a| \xi(\theta|\mathbf{x}) d\theta$。

> [!tip] Proof: Leibniz Integral Rule (莱布尼茨法则证明)
> 笔记 Page 10 详细推导了求导过程：
> $$g(a) = \int_{-\infty}^a (a-\theta)\xi(\theta|\mathbf{x}) d\theta + \int_a^{\infty} (\theta-a)\xi(\theta|\mathbf{x}) d\theta$$
> 对 $a$ 求导：
> $$\frac{dg}{da} = \int_{-\infty}^a 1 \cdot \xi(\theta|\mathbf{x}) d\theta - \int_a^{\infty} 1 \cdot \xi(\theta|\mathbf{x}) d\theta$$
> 令导数为 0：
> $$\int_{-\infty}^a \xi(\theta|\mathbf{x}) d\theta = \int_a^{\infty} \xi(\theta|\mathbf{x}) d\theta = \frac{1}{2}$$
> **结论:** **Bayes Estimator = Posterior Median (后验中位数)**.



### 3. Numerical Comparison: Mean vs. Median (详细推导)

> [!example] 笔记 Page 10 案例还原
> **场景:** 假设经过计算，参数 $\theta$ 的后验分布为 **Beta(12, 10)**。
> * **Note Source:** "posterior distribution is Beat 12... mean=0.55 ... median=0.545" 
> * **目标:** 展示在不同损失函数下，贝叶斯估计值的差异。

#### 1. 平方误差损失 (Squared Error Loss) $\to$ 后验均值 (Mean)
根据 Corollary 7.4.1，平方损失下的最优估计量是**后验均值**。

* **公式:** 对于 Beta 分布 $\theta \sim Beta(\alpha, \beta)$，其均值为：
    $$E[\theta | \mathbf{x}] = \frac{\alpha}{\alpha + \beta}$$
* **推导:**
    代入参数 $\alpha = 12, \beta = 10$：
    $$
    \begin{aligned}
    \delta^*_{mean}(\mathbf{x}) &= \frac{12}{12 + 10} \\
    &= \frac{12}{22} \\
    &\approx 0.54545...
    \end{aligned}
    $$
* **结果:** 笔记中将其四舍五入记为 **0.55** 。

#### 2. 绝对误差损失 (Absolute Error Loss) $\to$ 后验中位数 (Median)
根据 Corollary 7.4.2，绝对误差损失下的最优估计量是**后验中位数**。

* **定义:** 中位数 $m$ 是满足以下积分方程的值：
    $$\int_{0}^{m} \xi(\theta | \mathbf{x}) d\theta = 0.5$$
    即累积分布函数 $F(m) = 0.5$。
* **推导 (近似分析):**
    对于 Beta(12, 10) 这种 $\alpha, \beta$ 较大的分布，我们可以使用近似公式来理解为何它与均值不同。
    * **众数 (Mode):** $\frac{\alpha-1}{\alpha+\beta-2} = \frac{11}{20} = 0.55$。
    * **均值 (Mean):** $\approx 0.5454$。
    * **中位数 (Median):** 对于 Beta 分布，当 $\alpha > \beta > 1$ 时（分布左偏，尾巴向左），通常满足：
        $$\text{Mean} < \text{Median} < \text{Mode}$$
        *(注：这里 $\alpha=12 > \beta=10$，峰值偏右，长尾在左侧。实际上 Beta(12,10) 的精确中位数约为 0.548 左右。笔记中的 0.545 可能是一个近似计算值或笔误，但它想要展示的核心逻辑是 **Mean $\neq$ Median**。)*
* **结果:** 笔记给出的特定数值是 **0.545** 。

#### 3. 结论 (Conclusion)
* **Mean ($\approx 0.55$):** 对应**平方损失**，对极端误差更敏感。
* **Median ($\approx 0.545$):** 对应**绝对损失**，对异常值更鲁棒。
* **Insight:** 即使面对同一个后验分布，如果我们选择不同的“损失函数”（即我们对犯错代价的看法不同），我们给出的最优估计值 $\delta^*(\mathbf{x})$ 也会不同。

