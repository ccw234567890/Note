# 概率论笔记：方差、协方差与数字特征的局限性

> [!NOTE] 核心纲要
> 1.  **方差 (Variance) 的定义**：理解方差的计算公式 `E(X²) - [E(X)]²` 及其推导。
> 2.  **方差的性质**：掌握方差的线性性质 `Var(aX+b)` 和**<font color="#E74C3C">和的方差</font>** `Var(X+Y)`（重点：独立性）。
> 3.  **常见分布的方差**：推导伯努利、二项、指数和正态分布的方差。
> 4.  **方差的局限性**：当期望或方差不存在时（如柯西分布），引入 **IQR (四分位距)** 作为替代。
> 5.  **数字特征的陷阱**：理解均值和方差的局限性（安斯库姆四重奏），并引入**矩 (Moments)** 的概念。

---

## 1. 数据的陷阱：相关性 vs. 因果性 (回顾)

在深入研究数字特征之前，必须重申一个核心警示：**<font color="#E74C3C">相关性不等于因果性 (Correlation does not imply causation)</font>**。

* **相关性** 只是数据显示的趋势，而**因果性**是事物之间真实的逻辑关系。
* 我们很容易用真实的数据讲述一个完全错误的故事，来佐证一个已经预设好的结论。

> [!EXAMPLE] 数据的误导
> * **巧克力与诺贝尔奖：** 数据显示，一个国家的人均巧克力消耗量 (X) 与该国诺贝尔奖获得者数量 (Y) 呈**正相关**。
>     * **<font color="#E74C3C">错误结论：</font>** “多吃巧克力能让你得诺贝尔奖。”
>     * **<font color="#F39C12">真相：</font>** 背后可能有一个**隐藏变量**（如“国家富裕程度”），富裕国家有钱消费更多巧克力，也有钱投入科研。
> * **冰淇淋销量与犯罪率：** 冰淇淋销量与暴力犯罪率呈**正相关**。
>     * **<font color="#E74C3C">错误结论：</font>** “吃冰淇淋导致暴力。”
>     * **<font color="#F39C12">真相：</font>** 隐藏变量是“天气”。天热时，冰淇淋销量增加，同时人也更烦躁，导致犯罪率上升。
> * **辛普森悖论 (Simpson's Paradox)：**
>     * **数据：** 当把所有数据点放在一起看时，X 和 Y 呈**<font color="#2ECC71">正相关</font>**。
>     * **<font color="#F39C12">真相：</font>** 当把数据按组群（如医院A、B、C）拆开看时，**<font color="#E74C3C">每一个</font>**单独的组群内部都呈**<font color="#E74C3C">负相关</font>**。
>     * **医院案例：** 汇总数据可能显示“医院规模越大，死亡率越高”。但事实是，大医院（三甲）收治的都是重症病人，死亡率自然高；而小医院（校医院）只看感冒，死亡率几乎为0。

> [!WARNING] 统计的局限性
> 唯一能告诉你所有信息的只有 PMF、PDF 和 CDF。所有的数字特征（均值、方差）都是对无限信息的有限描述，必然会丢失大量信息。

---

## 2. 方差 (Variance)

### 2.1 什么是方差？

* **期望 (Mean)** 告诉我们分布的“中心”在哪里。
* **方差 (Variance)** 告诉我们数据**<font color="#E67E22">偏离这个中心的“分散程度” (Spread)</font>**。
* **<font color="#2ECC71">方差越小</font>**，数据越**<font color="#2ECC71">集中</font>**在均值附近。
* **<font color="#E74C3C">方差越大</font>**，数据越**<font color="#E74C3C">分散</font>**，波动越大。

### 2.2 定义与计算公式

* **定义式：**
    方差是“偏离均值的距离的平方”的期望值。设 $\mu = E(X)$：
    **<font color="#F39C12">$$Var(X) = E[(X - \mu)^2]$$</font>**
    * **离散型：** $Var(X) = \sum (x - \mu)^2 f(x)$
    * **连续型：** $Var(X) = \int_{-\infty}^\infty (x - \mu)^2 f(x) \,dx$

* **<font color="#E74C3C">计算式 (Computational Formula)</font>：**
    在实际计算中，使用定义式非常麻烦。我们使用一个更简单的等价公式：
    **<font color="#F39C12">$$Var(X) = E(X^2) - [E(X)]^2$$</font>**
    (即：“平方的期望”减去“期望的平方”)

> [!ABSTRACT] 核心推导：计算公式
> 1.  $Var(X) = E[(X - \mu)^2]$  (根据定义, $\mu = E(X)$)
> 2.  $\qquad = E[X^2 - 2\mu X + \mu^2]$ (展开平方)
> 3.  $\qquad = E(X^2) - E(2\mu X) + E(\mu^2)$ (利用期望的线性性质)
> 4.  $\qquad = E(X^2) - 2\mu E(X) + \mu^2$ (把常数 $2\mu$ 和 $\mu^2$ 提出来)
> 5.  $\qquad = E(X^2) - 2\mu(\mu) + \mu^2$ (代入 $E(X) = \mu$)
> 6.  $\qquad = E(X^2) - 2\mu^2 + \mu^2$
> 7.  $\qquad = E(X^2) - \mu^2 = E(X^2) - [E(X)]^2$ (证毕)

---

## 3. 方差的核心性质

### 性质 1：非负性
* **<font color="#2ECC71">$$Var(X) \ge 0$$</font>**
* **原因：** $Var(X)$ 是 $(X - \mu)^2$ 的期望。平方项 $(X - \mu)^2$ 永远是非负的，非负项的期望（加权平均）也永远是非负的。

### 性质 2：常数的方差
* **<font color="#2ECC71">$$Var(X) = 0 \iff P(X=c) = 1$$</font>**
* **讲解：** 方差为 0，当且仅当这个“随机变量”根本不随机，它是一个恒定的常数 $c$。

### 性质 3：线性变换（最重要！）
* 设 $a$ 和 $b$ 是常数， $Y = aX + b$。
* **<font color="#E74C3C">$$Var(Y) = Var(aX + b) = a^2 Var(X)$$</font>**

> [!ABSTRACT] 核心推导：Var(aX + b)
> 1.  令 $Y = aX + b$。
> 2.  首先求 $Y$ 的期望：$\mu_Y = E(Y) = E(aX+b) = aE(X) + b = a\mu_X + b$。
> 3.  $Var(Y) = E[(Y - \mu_Y)^2]$ (根据定义)
> 4.  $\qquad = E[ (aX + b) - (a\mu_X + b) ]^2$ (代入 $Y$ 和 $\mu_Y$)
> 5.  $\qquad = E[ aX - a\mu_X ]^2$ (常数 $b$ 被减掉)
> 6.  $\qquad = E[ a^2 (X - \mu_X)^2 ]$ (提出公因数 $a$)
> 7.  $\qquad = a^2 E[(X - \mu_X)^2]$ (期望的线性性质，提出常数 $a^2$)
> 8.  $\qquad = a^2 Var(X)$ (证毕)

* **<font color="#F39C12">推论 (标准差)</font>：**
    * 标准差 (Standard Deviation) $\sigma = \sqrt{Var(X)}$
    * $\sigma_Y = \sqrt{Var(Y)} = \sqrt{a^2 Var(X)} = |a| \sqrt{Var(X)} = |a| \sigma_X$

### 性质 4：和的方差 (Variance of a Sum)

> [!WARNING] 期望 vs. 方差
> * **期望：** $E(X_1 + \dots + X_n) = E(X_1) + \dots + E(X_n)$ (**<font color="#2ECC71">永远成立</font>**，不需要任何条件)。
> * **方差：** $Var(X_1 + \dots + X_n) = Var(X_1) + \dots + Var(X_n)$
>     **<font color="#E74C3C">仅在 $X_1, \dots, X_n$ 相互独立 (Independent) 时才成立！</font>**

#### 协方差 (Covariance)

为什么独立性这么重要？我们来推导 $Var(X_1 + X_2)$：

> [!ABSTRACT] 核心推导：Var(X₁ + X₂)
> 1.  设 $\mu_1 = E(X_1), \mu_2 = E(X_2)$。
> 2.  $Var(X_1 + X_2) = E[ ((X_1 + X_2) - (\mu_1 + \mu_2))^2 ]$ (根据定义)
> 3.  $\qquad = E[ ((X_1 - \mu_1) + (X_2 - \mu_2))^2 ]$ (重新分组)
> 4.  $\qquad = E[ (X_1 - \mu_1)^2 + (X_2 - \mu_2)^2 + 2(X_1 - \mu_1)(X_2 - \mu_2) ]$ (展开平方)
> 5.  $\qquad = E[(X_1 - \mu_1)^2] + E[(X_2 - \mu_2)^2] + 2 E[(X_1 - \mu_1)(X_2 - \mu_2)]$ (期望的线性)
> 6.  $\qquad = Var(X_1) + Var(X_2) + \mathbf{2 \cdot Cov(X_1, X_2)}$

* 我们把 $E[(X_1 - \mu_1)(X_2 - \mu_2)]$ 这个交叉项称为 $X_1$ 和 $X_2$ 的**协方差 (Covariance)**。它衡量了两个变量的关系。
* **<font color="#2ECC71">当 $X_1, X_2$ 独立时</font>**：
    * $E[(X_1 - \mu_1)(X_2 - \mu_2)] = E[X_1 - \mu_1] \cdot E[X_2 - \mu_2]$ (独立性)
    * $\qquad = (E(X_1) - \mu_1) \cdot (E(X_2) - \mu_2)$
    * $\qquad = (\mu_1 - \mu_1) \cdot (\mu_2 - \mu_2) = 0 \cdot 0 = 0$
* **结论：** 只有当变量**<font color="#E74C3C">独立</font>**时，协方差项才为 0，和的方差才等于方差的和。

---

## 4. 常见分布的期望与方差

| 分布 | $E(X)$ (期望) | $E(X^2)$ | $Var(X) = E(X^2) - [E(X)]^2$ |
| :--- | :--- | :--- | :--- |
| **伯努利 Bernoulli(p)** | $p$ | $p$ | $p - p^2 = \mathbf{p(1-p)}$ |
| **二项 Binomial(n, p)** | $np$ | (复杂) | $\mathbf{np(1-p)}$ |
| **均匀 Uniform(a, b)** | $\frac{a+b}{2}$ | (可积) | $\mathbf{\frac{(b-a)^2}{12}}$ |
| **指数 Exponential(λ)** | $\frac{1}{\lambda}$ | $\frac{2}{\lambda^2}$ | $2/\lambda^2 - (1/\lambda)^2 = \mathbf{1/\lambda^2}$ |
| **正态 Normal(μ, σ²)** | $\mu$ | $\sigma^2 + \mu^2$ | $\mathbf{\sigma^2}$ |
| **柯西 Cauchy** | **<font color="#E74C3C">不存在</font>** | **<font color="#E74C3C">不存在</font>** | **<font color="#E74C3C">不存在</font>** |

### <font color="#1E8449">推导：二项分布的方差 (巧妙方法)</font>
* **方法1 (硬算)：** 通过 $E[X(X-1)]$ 计算 $E(X^2)$，过程极其复杂。
* **方法2 (IID求和)：**
    1.  我们知道一个二项随机变量 $X \sim Bin(n, p)$，可以看作是 $n$ 个**<font color="#F39C12">独立同分布 (IID)</font>** 的伯努利 $X_i \sim Bern(p)$ 变量的和：
        $X = X_1 + X_2 + \dots + X_n$
    2.  $Var(X) = Var(X_1 + X_2 + \dots + X_n)$
    3.  **<font color="#2ECC71">因为 $X_i$ 相互独立</font>**，我们可以使用“和的方差”性质：
        $Var(X) = Var(X_1) + Var(X_2) + \dots + Var(X_n)$
    4.  我们已经算出**<font color="#E67E22">伯努利的方差</font>** $Var(X_i) = p(1-p)$。
    5.  $Var(X) = p(1-p) + p(1-p) + \dots \text{(n次)} = \mathbf{np(1-p)}$。
    * **结论：** 永远把二项分布看作是 IID 伯努利分布的和，这是最简单的方法。

### <font color="#1E8449">推导：指数分布的方差</font>
* $f(x) = \lambda e^{-\lambda x}$
* $E(X) = 1/\lambda$ (上节课已证)
* $E(X^2) = \int_0^\infty x^2 (\lambda e^{-\lambda x}) \,dx = \lambda \int_0^\infty x^2 e^{-\lambda x} \,dx$
* *使用两次分部积分 (Integration by Parts)*：
    $\int x^2 e^{-\lambda x} \,dx = -\frac{x^2}{\lambda}e^{-\lambda x} + \int \frac{2x}{\lambda}e^{-\lambda x} \,dx$
    $\qquad = -\frac{x^2}{\lambda}e^{-\lambda x} - \frac{2x}{\lambda^2}e^{-\lambda x} + \int \frac{2}{\lambda^2}e^{-\lambda x} \,dx$
    $\qquad = -\frac{x^2}{\lambda}e^{-\lambda x} - \frac{2x}{\lambda^2}e^{-\lambda x} - \frac{2}{\lambda^3}e^{-\lambda x}$
* 代入 $0$ 和 $\infty$：
    $E(X^2) = \lambda \cdot [ (\text{在}\infty\text{处为}0) - (0 - 0 - \frac{2}{\lambda^3}) ] = \lambda \cdot (\frac{2}{\lambda^3}) = \frac{2}{\lambda^2}$
* **$Var(X) = E(X^2) - [E(X)]^2 = \frac{2}{\lambda^2} - \left(\frac{1}{\lambda}\right)^2 = \frac{1}{\lambda^2}$**

### <font color="#1E8449">推导：正态分布的方差</font>
* $X \sim N(\mu, \sigma^2)$，已知 $E(X) = \mu$。
* $Var(X) = E[(X - \mu)^2] = \int_{-\infty}^\infty (x - \mu)^2 \cdot \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \,dx$
* *标准代换：* $t = \frac{x-\mu}{\sigma}$，则 $x-\mu = \sigma t$，$dx = \sigma \,dt$
* $Var(X) = \int_{-\infty}^\infty (\sigma t)^2 \cdot \frac{1}{\sigma\sqrt{2\pi}} e^{-t^2/2} \cdot (\sigma \,dt)$
* $Var(X) = \int_{-\infty}^\infty \sigma^2 t^2 \cdot \frac{1}{\sqrt{2\pi}} e^{-t^2/2} \,dt$
* $Var(X) = \sigma^2 \int_{-\infty}^\infty t^2 \cdot \left( \frac{1}{\sqrt{2\pi}} e^{-t^2/2} \right) \,dt$
* *我们知道 $t$ 是标准正态 $Z \sim N(0, 1)$。括号中的是 $Z$ 的 PDF。*
* $Var(X) = \sigma^2 \cdot E[Z^2]$
* *对于 $Z \sim N(0, 1)$， $Var(Z) = 1$。根据计算公式 $Var(Z) = E(Z^2) - [E(Z)]^2$*
    $1 = E(Z^2) - [0]^2 \implies E(Z^2) = 1$
* $Var(X) = \sigma^2 \cdot (1) = \mathbf{\sigma^2}$ (证毕)

---

## 5. 正态分布的特殊可加性

正态分布有一个极强的特性：

1.  **<font color="#3498DB">线性变换不变性</font>：**
    * 如果 $X \sim N(\mu, \sigma^2)$
    * 则 $Y = aX + b \sim N(a\mu + b, a^2\sigma^2)$
    * *一个正态分布的线性函数**<font color="#2ECC71">仍然是</font>**正态分布。*

2.  **<font color="#3498DB">独立求和不变性</font>：**
    * 如果 $X_1 \sim N(\mu_1, \sigma_1^2)$ 和 $X_2 \sim N(\mu_2, \sigma_2^2)$ 且**<font color="#E74C3C">独立</font>**。
    * 则 $Y = X_1 + X_2 \sim N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$
    * *两个独立正态分布的和**<font color="#2ECC71">仍然是</font>**正态分布。*
    * *（注意：如果不独立，和的方差需要加协方差项，但如果它们是“二元正态分布”，和也仍然是正态的）*

---

## 6. 当方差不存在时：IQR

### 6.1 柯西分布 (Cauchy)
* $f(x) = \frac{1}{\pi(1+x^2)}$
* 我们在上节课证明了，它的期望 $E(X) = \int x f(x) dx$ **<font color="#E74C3C">不绝对收敛</font>** (发散)。
* 既然期望 $E(X)$ 都不存在，方差 $Var(X) = E[(X-\mu)^2]$ 自然也**<font color="#E74C3C">不存在</font>**。

### 6.2 四分位距 (Interquartile Range - IQR)

* **问题：** 对于柯西分布这种没有均值和方差的分布，我们如何描述它的“中心”和“分散程度”？
* **答案：** 使用**<font color="#F39C12">分位数 (Quantiles)</font>**。
* **中心：** 使用**<font color="#F39C12">中位数 (Median)</font>**，即 $Q_2 = F^{-1}(0.5)$。
* **分散程度：** 使用**<font color="#F39C12">四分位距 (IQR)</font>**。
    * $IQR = Q_3 - Q_1 = F^{-1}(0.75) - F^{-1}(0.25)$
    * 它描述了数据**<font color="#E67E22">中间 50%</font>** 的跨度。它不受极端值的影响，因此总能存在。

> [!EXAMPLE] 柯西分布的 IQR
> 1.  $F(x) = \int_{-\infty}^x \frac{1}{\pi(1+t^2)} \,dt = \frac{1}{\pi} [\arctan(t)]_{-\infty}^x = \frac{1}{\pi} (\arctan(x) - (-\frac{\pi}{2})) = \frac{\arctan(x)}{\pi} + \frac{1}{2}$
> 2.  **求 $Q_3$ ($F(x) = 0.75$)：**
>     $\frac{\arctan(x)}{\pi} + 0.5 = 0.75 \implies \arctan(x) = 0.25\pi \implies x = \tan(\pi/4) = 1$
> 3.  **求 $Q_1$ ($F(x) = 0.25$)：**
>     $\frac{\arctan(x)}{\pi} + 0.5 = 0.25 \implies \arctan(x) = -0.25\pi \implies x = \tan(-\pi/4) = -1$
> 4.  **$IQR = Q_3 - Q_1 = 1 - (-1) = 2$**。

---

## 7. 数字特征的局限性与矩 (Moments)

* 均值和方差是两个最有用的数字特征，但它们会丢失大量信息。
* **安斯库姆四重奏 (Anscombe's Quartet)：**
    * 这是一个著名的例子，展示了**<font color="#E74C3C">四组完全不同</font>**的数据集。
    * 它们各自的 $E(X)$, $E(Y)$, $Var(X)$, $Var(Y)$ 和相关系数**<font color="#E74C3C">完全相同</font>**。
    * 但它们的数据形态（一个是线性，一个是曲线，一个是离群点）截然不同。
* **结论：** 仅靠均值和方差不足以描述一个分布。

### 矩 (Moments)
* **思想：** 既然均值 $E(X)$ 和 $E(X^2)$ 提供了信息，那我们能不能用 $E(X^3)$, $E(X^4)$ 等来获取更多信息？
* **k 阶矩：** $E(X^k)$。
* 这就像用泰勒展开来逼近一个函数：
    * 1 阶（均值）提供了“线性”信息。
    * 2 阶（方差）提供了“二次/曲率”信息。
    * 3 阶（偏度 Skewness）提供了“不对称性”信息。
    * 4. 阶（峰度 Kurtosis）提供了“尾部肥胖”信息。
* **局限性：** 即使你知道了所有的矩 $E(X^k)$，在某些病态情况下（如对数正态分布），你仍然无法唯一确定原始分布。
* **<font color="#F39C12">最终结论：</font>** 唯一能告诉你所有信息的，只有 PMF / PDF / CDF。