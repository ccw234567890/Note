第 7 步：Web UI 部署

最后，我们看看项目是如何变成一个可以点击的网页应用的。

Code snippet


最后，请简单分析一下 `app.py` 文件。
1. 这个脚本是如何使用 Gradio 库来创建一个在线演示 (Online Demo) 的？
2. 它和 `chat.py` 在调用模型进行推理的核心逻辑上有什么相同和不同之处？


当你走完这 7 步，相信你对 LISA 项目的理解会达到一个全新的高度，那时候再思考如何去“优化”它，就会有非常清晰的方向了。如果在某个步骤中，Cursor 的回答你还是不理解，不要犹豫，继续追问它更细节的问题！祝你科研顺利！

---

好的，这是我们“代码精读课”的最后一站：项目的“橱窗”——`app.py`。

这个脚本的目标不是在黑漆漆的命令行里运行，而是创造一个**任何人都能通过浏览器访问和使用的图形化界面**。它使用了 Gradio 这个神奇的库来快速搭建 Web UI。

---

### 1. 使用 Gradio 创建在线演示

Gradio 是一个专门为机器学习模型设计的 UI 框架。它的核心理念是：**用最少的代码，把你的模型函数“包装”成一个交互式的网页应用**。

`app.py` 使用 Gradio 的过程可以概括为三步：

**第一步：定义“输入”和“输出”组件**

*   Gradio 提供了很多现成的 UI 组件，就像一个个乐高积木。`app.py` 会先定义好它需要哪些积木。
    ```python
    # app.py (简化示意)
    import gradio as gr

    with gr.Blocks() as demo:
        # 定义一个聊天机器人界面
        chatbot = gr.Chatbot(label='LISA')
        
        # 定义一个文本输入框
        msg = gr.Textbox(label="Prompt")
        
        # 定义一个图片上传框
        image = gr.Image(type="pil")
        
        # 定义一个提交按钮
        submit = gr.Button("Submit")
    ```
    这里，它定义了聊天窗口、文本框、图片上传框和按钮，这些就是用户将在浏览器里看到和操作的东西。

**第二步：定义核心处理函数**

*   脚本会定义一个核心函数（比如叫 `process_example` 或 `respond`），这个函数**接收**来自 UI 组件的输入，**处理**它们，然后**返回**要在 UI 组件上显示的结果。
    ```python
    # app.py (简化示意)
    
    def respond(prompt, chat_history, image):
        # 1. 接收来自 UI 的数据：
        #    prompt 是文本框里的文字
        #    chat_history 是聊天记录
        #    image 是上传的图片
        
        # 2. 调用模型进行推理...
        #    (这里的逻辑和 chat.py 非常相似)
        
        # 3. 返回要在 UI 上显示的结果：
        #    new_chat_history 是更新后的聊天记录
        #    result_image 是处理后带掩码的图片
        return "", new_chat_history, result_image
    ```

**第三步：“绑定”输入、输出和函数**

*   这是最关键的一步。Gradio 需要知道当用户**做什么操作**时，应该**调用哪个函数**，并且函数的**输入来自哪里**，**输出又该送到哪里**。
    ```python
    # app.py (简化示意)
    
    # 当 submit 按钮被点击 (click) 时:
    submit.click(
        fn=respond,           # 调用 `respond` 这个函数
        inputs=[msg, chatbot, image], # 函数的输入来自文本框、聊天记录和图片框
        outputs=[msg, chatbot, image] # 函数的输出去更新文本框、聊天记录和图片框
    )
    ```
    这行代码就像是“接线员”，它把 UI 按钮、处理函数和数据流动路径完美地连接在了一起。

**最后一步：启动服务**
*   脚本末尾会有一行 `demo.launch()`。运行这行代码，Gradio 就会在本地启动一个 Web 服务器。你会在命令行看到一个类似 `http://127.0.0.1:7860` 的地址，用浏览器打开它，就能看到你刚刚用代码定义的交互界面了。

---

### 2. 与 `chat.py` 的异同

`app.py` (图形界面) 和 `chat.py` (命令行) 在核心逻辑上其实是**“同父异母的兄弟”**。

#### **相同之处：核心推理引擎**

它们的心脏是**一模一样**的。

1.  **模型加载**: 它们都使用几乎相同的代码来加载 `LISAForCausalLM` 模型、Tokenizer 和视觉处理器。启动时传入的 `--version`, `--load_in_8bit` 等参数，作用也完全相同。

2.  **数据预处理**: 它们拿到用户输入的图片和文本后，执行的**预处理步骤是完全一致的**：图片被 `image_processor` 转换成张量，文本被 `tokenizer` 转换成 `input_ids`。

3.  **模型调用**: 它们都调用 `model.generate()` 这个核心函数来获取模型的回答和分割结果。

4.  **结果后处理**: 它们都对模型输出的掩码进行**二值化、尺寸恢复、并与原图叠加**来生成最终的可视化图片。

**可以这么说，`app.py` 在它的核心处理函数里，几乎是“复制粘贴”了 `chat.py` 的主要推理逻辑。**

#### **不同之处：交互的外壳**

它们最大的不同在于**“如何与用户打交道”**以及**“如何呈现结果”**。

| 特性 | `chat.py` (命令行) | `app.py` (Gradio Web UI) |
| :--- | :--- | :--- |
| **输入方式** | 通过命令行参数和 `input()` 函数接收文本。 | 通过网页上的**图片上传框**和**文本输入框**接收。 |
| **交互模式** | 一问一答的**纯文本**循环。 | **富媒体**的、事件驱动的交互（点击按钮）。 |
| **状态管理** | 通常需要自己手动管理多轮对话的历史。 | Gradio 的 `gr.Chatbot` 组件可以**自动维护聊天状态**。 |
| **输出呈现** | 在命令行打印出模型的文本回答。<br>将结果图片**默默地保存到本地文件夹**。 | 将文本回答更新到**网页的聊天窗口**中。<br>将结果图片直接**显示在网页的图片框**里，所见即所得。 |
| **目标用户** | 开发者、研究员，用于快速测试和调试。 | 任何人，用于直观的演示和体验。 |

### 一句话总结

`chat.py` 和 `app.py` 共用着**同一颗“推理大脑”**。

`chat.py` 给这颗大脑配上了一个**“命令行对讲机”**，简单直接。

而 `app.py` 则使用 Gradio，为这颗大脑精心打造了一个**漂亮的“驾驶舱”**，拥有仪表盘（图片显示）、方向盘（按钮）和麦克风（文本框），让普通用户也能轻松“驾驶”这个强大的模型。