# å­¦ä¹ ç¬”è®°ï¼šç¥ç»ç½‘ç»œæ ¸å¿ƒç»„ä»¶ ï¼ˆCCWç‰ˆ)

> [!NOTE] æ ¸å¿ƒçº²è¦
> è¿™ä»½ç¬”è®°å°†å¸¦æ‚¨å®Œæ•´åœ°äº†è§£æ„æˆç¥ç»ç½‘ç»œå¹¶ä½¿å…¶èƒ½å¤Ÿå­¦ä¹ çš„æ ¸å¿ƒç»„ä»¶ã€‚æˆ‘ä»¬å°†ä¾æ¬¡æ·±å…¥æ¢è®¨ï¼š
> 1.  **æ¿€æ´»å‡½æ•°**: èµ‹äºˆç½‘ç»œéçº¿æ€§å­¦ä¹ èƒ½åŠ›çš„â€œå¼€å…³â€ã€‚
> 2.  **æŸå¤±å‡½æ•°**: è¡¡é‡æ¨¡å‹é¢„æµ‹å¥½åçš„â€œæ ‡å°ºâ€ã€‚
> 3.  **è‡ªåŠ¨æ±‚å¯¼**: PyTorchä¸­å®ç°è‡ªåŠ¨ä¼˜åŒ–çš„â€œå¼•æ“â€ã€‚

---
## ç¬¬ä¸€éƒ¨åˆ†ï¼šç¥ç»ç½‘ç»œçš„â€œå¼€å…³â€ - æ¿€æ´»å‡½æ•° ğŸ§ 

> [!info] ä»€ä¹ˆæ˜¯æ¿€æ´»å‡½æ•°ï¼Ÿ
> ![[Pasted image 20250724232329.png]]
> åœ¨ç¥ç»å…ƒæ¥æ”¶æ‰€æœ‰è¾“å…¥å¹¶è¿›è¡Œ**åŠ æƒæ±‚å’Œ**åï¼Œå…¶ç»“æœä¼šç»è¿‡ä¸€ä¸ª**æ¿€æ´»å‡½æ•°** `f(Â·)` çš„å¤„ç†ï¼Œå¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºä¿¡å·ã€‚
> 
> **æ ¸å¿ƒä½œç”¨**: ==ä¸ºç½‘ç»œå¼•å…¥éçº¿æ€§==ã€‚æ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼Œæ— è®ºç½‘ç»œå¤šæ·±ï¼Œéƒ½åªæ˜¯ä¸€ä¸ªç®€å•çš„çº¿æ€§æ¨¡å‹ï¼Œæ— æ³•å­¦ä¹ å¤æ‚çš„ç°å®ä¸–ç•Œè§„å¾‹ã€‚

---
### æ¿€æ´»å‡½æ•°çš„æ¼”è¿›ä¹‹è·¯

#### 1. â€œè€ç¥–å®—â€ï¼šé˜¶è·ƒå‡½æ•° (Step Function)

> [!danger] è‡´å‘½ç¼ºé™·ï¼šæ— æ³•æ±‚å¯¼
> ![[Pasted image 20250724232405.png]]
> - **é€»è¾‘**: ç®€å•çš„â€œå¼€/å…³â€é€»è¾‘ï¼Œå¤§äºé˜ˆå€¼è¾“å‡º1ï¼Œå¦åˆ™è¾“å‡º0ã€‚
> - **ç¼ºé™·**: å‡½æ•°ä¸è¿ç»­ï¼Œå…¶å¯¼æ•°å‡ ä¹å¤„å¤„ä¸ºé›¶ã€‚è¿™æ„å‘³ç€æ¢¯åº¦æ— æ³•ä¼ æ’­ï¼Œæ¨¡å‹æ— æ³•é€šè¿‡æ¢¯åº¦ä¸‹é™è¿›è¡Œå­¦ä¹ ã€‚

#### 2. â€œç»å…¸ä¹‹é€‰â€ï¼šSigmoid å‡½æ•°

> [!example] Sigmoid: å¹³æ»‘çš„æ¦‚ç‡åŒ–å¼€å…³
> ![[Pasted image 20250724232432.png]]
> - **å…¬å¼**: $\sigma(x) = \frac{1}{1 + e^{-x}}$
> - **ç‰¹æ€§**:
>   - **å¹³æ»‘å¯å¯¼**ï¼šè§£å†³äº†é˜¶è·ƒå‡½æ•°çš„æœ€å¤§é—®é¢˜ã€‚
>   - **è¾“å‡ºèŒƒå›´ (0, 1)**ï¼šèƒ½å°†ä»»æ„è¾“å…¥â€œå‹ç¼©â€åˆ° (0, 1) ä¹‹é—´ï¼Œå¸¸ç”¨äºè¡¨ç¤ºæ¦‚ç‡æˆ–äºŒåˆ†ç±»ä»»åŠ¡çš„è¾“å‡ºã€‚
> - **å¯¼æ•°**: $\sigma' = \sigma(1-\sigma)$ï¼Œè®¡ç®—é«˜æ•ˆã€‚
> 
> > [!tip] ä»£ç ç¤ºä¾‹
> > ![[Pasted image 20250724232517.png]]

#### 3. â€œæ”¹è¿›ä¹‹é€‰â€ï¼šTanh (åŒæ›²æ­£åˆ‡) å‡½æ•°

> [!example] Tanh: é›¶ä¸­å¿ƒçš„Sigmoid
> ![[Pasted image 20250724232643.png]]
> - **å…¬å¼**: $\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$
> - **ç‰¹æ€§**:
>   - **è¾“å‡ºèŒƒå›´ (-1, 1)**ã€‚
>   - **==é›¶ä¸­å¿ƒ (Zero-centered)==**: è¾“å‡ºå‡å€¼ä¸º0ï¼Œè¿™ä¸€ç‰¹æ€§åœ¨å®è·µä¸­é€šå¸¸èƒ½è®©æ¨¡å‹**æ”¶æ•›å¾—æ›´å¿«**ï¼Œå› æ­¤åœ¨éšè—å±‚ä¸­è¡¨ç°å¸¸ä¼˜äºSigmoidã€‚
> - **å¯¼æ•°**: $\tanh'(x) = 1 - \tanh^2(x)$ã€‚
> 
> > [!tip] ä»£ç ç¤ºä¾‹
> >![[Pasted image 20250724232713.png]]

#### 4. â€œç°ä»£é»˜è®¤ä¹‹é€‰â€ï¼šReLU (ä¿®æ­£çº¿æ€§å•å…ƒ)

> [!success] ReLU: ç®€å•ã€é«˜æ•ˆã€ç¼“è§£æ¢¯åº¦æ¶ˆå¤±
> ![[Pasted image 20250724232754.png]]
> - **å…¬å¼**: $f(x) = \max(0, x)$
> - **æ ¸å¿ƒä¼˜åŠ¿**:
>   1.  **è®¡ç®—æå…¶é«˜æ•ˆ**ï¼šä»…éœ€ä¸€ä¸ªæ¯”è¾ƒæ“ä½œã€‚
>   2.  **==æœ‰æ•ˆç¼“è§£æ¢¯åº¦æ¶ˆå¤±==**ï¼šå½“è¾“å…¥ä¸ºæ­£æ•°æ—¶ï¼Œå…¶æ¢¯åº¦æ’ä¸º **1**ã€‚è¿™ä½¿å¾—æ¢¯åº¦èƒ½å¤Ÿé¡ºç•…åœ°åœ¨æ·±åº¦ç½‘ç»œä¸­ä¼ æ’­ï¼Œæå¤§åœ°åŠ é€Ÿäº†è®­ç»ƒã€‚
> - **å¯¼æ•°**:
> ![[Pasted image 20250724232826.png]]
> 
> > [!tip] ä»£ç ç¤ºä¾‹
> > ![[Pasted image 20250724232909.png]]

---
## ç¬¬äºŒéƒ¨åˆ†ï¼šè¡¡é‡è¯¯å·®çš„â€œæ ‡å°ºâ€ - æŸå¤±å‡½æ•° ğŸ“

> [!info] ä»€ä¹ˆæ˜¯æŸå¤±å‡½æ•°ï¼Ÿ
> **æŸå¤±å‡½æ•° (Loss Function)** æ˜¯ä¸€ä¸ªç”¨æ¥è®¡ç®—**æ¨¡å‹é¢„æµ‹å€¼**ä¸**çœŸå®æ ‡ç­¾**ä¹‹é—´å·®è·çš„å‡½æ•°ã€‚
> 
> **è®­ç»ƒç›®æ ‡**: ==é€šè¿‡è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œè®©æŸå¤±å‡½æ•°çš„å€¼å˜å¾—å°½å¯èƒ½å°ã€‚==

### æ·±å…¥ç†è§£ï¼šå‡æ–¹è¯¯å·® (Mean Squared Error, MSE)

> [!example] MSE: å›å½’ä»»åŠ¡çš„å¸¸ç”¨æ ‡å°º
>![[Pasted image 20250724233017.png]]
> - **æ ¸å¿ƒå…¬å¼**: $\text{loss} = \sum (\text{çœŸå®å€¼} - \text{é¢„æµ‹å€¼})^2 = \sum [y - f_\theta(x)]^2$
> - **ä½œç”¨**: ä¸»è¦ç”¨äº**å›å½’ä»»åŠ¡**ã€‚é€šè¿‡è®¡ç®—è¯¯å·®çš„å¹³æ–¹å’Œï¼Œæ¥è¡¡é‡æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

### æŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼šè¿æ¥è¯¯å·®ä¸ä¼˜åŒ–

> [!abstract] æ¢¯åº¦çš„æ¡¥æ¢ä½œç”¨
> ![[Pasted image 20250724233118.png]]
> - **å…¬å¼**: $\frac{\nabla \text{loss}}{\nabla \theta} = -2 \sum \underbrace{[y - f_\theta(x)]}_{\text{è¯¯å·®}} \cdot \underbrace{\frac{\nabla f_\theta(x)}{\nabla \theta}}_{\text{æ¨¡å‹è¾“å‡ºå¯¹å‚æ•°çš„æ¢¯åº¦}}$
> - **æ·±åˆ»å«ä¹‰**: è¿™ä¸ªå…¬å¼æ˜¯æ•´ä¸ªå­¦ä¹ è¿‡ç¨‹çš„åŠ¨åŠ›æºæ³‰ã€‚å®ƒå‘Šè¯‰æˆ‘ä»¬ï¼Œæœ€ç»ˆçš„**è¯¯å·®**ä¿¡å·ï¼Œæ˜¯å¦‚ä½•é€šè¿‡**é“¾å¼æ³•åˆ™**ï¼Œä¸€æ­¥æ­¥åœ°åå‘ä¼ æ’­ï¼Œå¹¶æŒ‡å¯¼ç½‘ç»œä¸­çš„**æ¯ä¸€ä¸ªå‚æ•°**åº”è¯¥å¦‚ä½•è¿›è¡Œå¾®è°ƒï¼Œä»è€Œè®©æ€»è¯¯å·®å‡å°ã€‚

---
## ç¬¬ä¸‰éƒ¨åˆ†ï¼šè‡ªåŠ¨åŒ–çš„â€œå¼•æ“â€ - PyTorch Autograd âš™ï¸

> [!info] ä»€ä¹ˆæ˜¯ Autogradï¼Ÿ
> æˆ‘ä»¬æ— éœ€æ‰‹åŠ¨è®¡ç®—ä¸Šé¢å¤æ‚çš„æ¢¯åº¦ã€‚PyTorch çš„ **`autograd`** å¼•æ“ä¼šé€šè¿‡æ„å»º**åŠ¨æ€è®¡ç®—å›¾**æ¥è‡ªåŠ¨å®Œæˆè¿™ä¸ªè¿‡ç¨‹ã€‚

### 1. é»„é‡‘æ³•åˆ™ï¼šå¼€å¯æ¢¯åº¦è¿½è¸ª (`requires_grad`)
> [!warning] å¿…é¡»å…ˆå¼€å¯è¿½è¸ªï¼ > è¦æƒ³è®© PyTorch è‡ªåŠ¨æ±‚å¯¼ï¼Œå¿…é¡»åœ¨è®¡ç®—å‘ç”Ÿ**ä¹‹å‰**ï¼Œå°†å‚æ•°å¼ é‡çš„ `.requires_grad` å±æ€§è®¾ç½®ä¸º `True`ã€‚ > `w.requires_grad_(True)`



### 2. è®¡ç®—æ¢¯åº¦çš„ä¸¤å¤§API

> [!tip] APIå¯¹æ¯”
> ![[Pasted image 20250724233253.png]]
> - **`loss.backward()` (æ¨è)**: æœ€å¸¸ç”¨çš„æ–¹æ³•ã€‚è®¡ç®—æ¢¯åº¦å¹¶å°†å…¶**å­˜å‚¨**åœ¨å‚æ•°çš„ `.grad` å±æ€§ä¸­ã€‚
> - **`torch.autograd.grad()`**: æ›´åº•å±‚çš„æ¥å£ï¼Œç›´æ¥å°†æ¢¯åº¦ä½œä¸ºç»“æœ**è¿”å›**ã€‚

> [!example] ä»£ç ä¸­çš„å¸¸è§é™·é˜±ä¸æ­£ç¡®æµç¨‹
> ![[Pasted image 20250724233314.png]]
> - **é”™è¯¯åŸå› **: åœ¨è®¡ç®—æŸå¤± `mse` æ—¶ï¼Œå‚æ•° `w` è¿˜æ²¡æœ‰å¼€å¯æ¢¯åº¦è¿½è¸ªã€‚
> - **æ­£ç¡®æµç¨‹**: ==å¿…é¡»å…ˆè®¾ç½® `w.requires_grad_(True)`ï¼Œç„¶åå†ç”¨è¿™ä¸ª `w` å»è®¡ç®—æŸå¤± `mse`==ï¼Œæœ€åæ‰èƒ½æˆåŠŸè°ƒç”¨ `mse.backward()` æˆ– `autograd.grad`ã€‚

---
## ç¬¬å››éƒ¨åˆ†ï¼šå¤šåˆ†ç±»â€œæ ‡å‡†ç­”æ¡ˆâ€ - Softmax å‡½æ•° ğŸ¯

> [!info] ä»€ä¹ˆæ˜¯ Softmaxï¼Ÿ
> ![[Pasted image 20250724233333.png]]
> **Softmax** èƒ½å°†ä¸€ä¸ªåŒ…å«ä»»æ„åˆ†æ•°çš„å‘é‡ï¼ˆlogitsï¼‰ï¼Œè½¬æ¢æˆä¸€ä¸ª**æ¦‚ç‡åˆ†å¸ƒ**ã€‚
> 
> **å…³é”®ç‰¹æ€§**:
> 1.  æ‰€æœ‰è¾“å‡ºå€¼éƒ½åœ¨ `[0, 1]` ä¹‹é—´ã€‚
> 2.  æ‰€æœ‰è¾“å‡ºå€¼çš„æ€»å’Œä¸º `1`ã€‚

### Softmax çš„æ•°å­¦ä¸ä»£ç å®è·µ

> [!abstract] Softmax çš„å¯¼æ•°
>![[Pasted image 20250724233413.png]]
> Softmax çš„å¯¼æ•°æ¯”è¾ƒå¤æ‚ï¼Œåˆ†ä¸º `i = j` å’Œ `i â‰  j` ä¸¤ç§æƒ…å†µã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸å°† **Softmax** å’Œ **äº¤å‰ç†µæŸå¤±** ç»“åˆä½¿ç”¨ï¼Œå®ƒä»¬çš„ç»„åˆæ¢¯åº¦å½¢å¼éå¸¸ç®€æ´ã€‚

> [!warning] PyTorchå®è·µä¸­çš„ `retain_graph`
> ![[Pasted image 20250724233503.png]]
> - **é»˜è®¤è¡Œä¸º**: è°ƒç”¨ `.backward()` æˆ– `autograd.grad()` åï¼Œè®¡ç®—å›¾ä¼šè¢«**ç«‹å³é‡Šæ”¾**ä»¥èŠ‚çœå†…å­˜ã€‚
> - **`retain_graph=True`**: å¦‚æœä½ éœ€è¦å¯¹åŒä¸€ä¸ªè®¡ç®—ç»“æœ**å¤šæ¬¡**æ‰§è¡Œæ¢¯åº¦è®¡ç®—ï¼Œå°±å¿…é¡»åœ¨è°ƒç”¨æ—¶ä¼ å…¥æ­¤å‚æ•°ï¼Œä»¥==å¼ºåˆ¶ä¿ç•™è®¡ç®—å›¾==ã€‚

---

# PyTorch æ ¸å¿ƒä»£ç è¯¦è§£ï¼šä»æ¿€æ´»å‡½æ•°åˆ°è‡ªåŠ¨æ±‚å¯¼

> [!NOTE] æ ¸å¿ƒçº²è¦
> è¿™ä»½ç¬”è®°å°†æ·±å…¥è§£æåœ¨ä¹‹å‰å­¦ä¹ ä¸­é‡åˆ°çš„å…³é”® PyTorch ä»£ç ç‰‡æ®µï¼Œå¸®åŠ©æ‚¨ä»â€œçŸ¥é“æ˜¯ä»€ä¹ˆâ€åˆ°â€œç²¾é€šæ€ä¹ˆç”¨â€ã€‚æˆ‘ä»¬å°†é€ä¸€å‰–æï¼š
> 1.  **å¸¸ç”¨æ¿€æ´»å‡½æ•°** (`sigmoid`, `tanh`, `relu`) çš„ä»£ç å®ç°ä¸ç‰¹æ€§ã€‚
> 2.  **æ ¸å¿ƒè®­ç»ƒæŒ‡ä»¤** `loss.backward()` çš„æ­£ç¡®å·¥ä½œæµç¨‹ä¸å¸¸è§é™·é˜±ã€‚
> 3.  **è®¡ç®—å›¾çš„ç”Ÿå‘½å‘¨æœŸ**ä»¥åŠ `retain_graph=True` çš„ç‰¹æ®Šåº”ç”¨ã€‚

---
## ç¬¬ä¸€éƒ¨åˆ†ï¼šæ¿€æ´»å‡½æ•°ä»£ç è¯¦è§£ ğŸ’¡

### 1. `torch.sigmoid` è¯¦è§£

> [!example] `torch.sigmoid`: é¥±å’Œçš„æ¦‚ç‡åŒ–å¼€å…³
> **æ ¸å¿ƒåŠŸèƒ½**: å°†ä»»æ„å®æ•°â€œå‹ç¼©â€åˆ° `(0, 1)` åŒºé—´ï¼Œå¸¸ç”¨äºè¡¨ç¤ºæ¦‚ç‡ã€‚
> 
> ```python
> # In [5]:
> a = torch.linspace(-100, 100, 10)
> # tensor([-100.00..., -77.77..., ..., 77.77..., 100.00...])
> 
> # In [7]:
> torch.sigmoid(a)
> # tensor([0.0000e+00, 1.6655e-34, ..., 9.9999e-01, 1.0000e+00])
> ```
> #### ä»£ç è§£æ
> - **è¾“å…¥**: `torch.linspace(-100, 100, 10)` åˆ›å»ºäº†ä¸€ä¸ªä»-100åˆ°100çš„ç­‰å·®æ•°åˆ—ï¼Œè¿™ä¸ªå¤§èŒƒå›´æ˜¯ä¸ºäº†å±•ç¤ºå…¶==é¥±å’Œæ•ˆåº”==ã€‚
> - **æ“ä½œ**: `torch.sigmoid(a)` å°† Sigmoid å‡½æ•° $\sigma(x) = \frac{1}{1 + e^{-x}}$ åº”ç”¨äº `a` ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ ã€‚
> - **è¾“å‡ºåˆ†æ**:
>   - æå¤§çš„è´Ÿæ•°ï¼ˆå¦‚ `-100`ï¼‰è¢«æ˜ å°„åˆ°**æ¥è¿‘ 0**ã€‚
>   - æå¤§çš„æ­£æ•°ï¼ˆå¦‚ `100`ï¼‰è¢«æ˜ å°„åˆ°**æ¥è¿‘ 1**ã€‚
>   - æ¥è¿‘ 0 çš„è¾“å…¥ä¼šè¢«æ˜ å°„åˆ° 0.5 é™„è¿‘ã€‚

### 2. `torch.tanh` è¯¦è§£

> [!example] `torch.tanh`: é›¶ä¸­å¿ƒçš„Så½¢å¼€å…³
> **æ ¸å¿ƒåŠŸèƒ½**: å°†ä»»æ„å®æ•°â€œå‹ç¼©â€åˆ° `(-1, 1)` åŒºé—´ï¼Œå› å…¶è¾“å‡º**é›¶ä¸­å¿ƒ**ï¼Œåœ¨éšè—å±‚ä¸­é€šå¸¸è¡¨ç°æ›´ä¼˜ã€‚
> ```python
> # In [9]:
> a = torch.linspace(-1, 1, 10)
> 
> # In [10]:
> torch.tanh(a)
> # tensor([-0.7616, -0.6514, ..., 0.6514,  0.7616])
> ```
> #### ä»£ç è§£æ
> - **è¾“å…¥**: `torch.linspace(-1, 1, 10)` è¿™ä¸ªèŒƒå›´ä¸»è¦å±•ç¤º Tanh åœ¨ä¸­å¿ƒåŒºåŸŸçš„è¡Œä¸ºã€‚
> - **æ“ä½œ**: å°† Tanh å‡½æ•°æŒ‰å…ƒç´ åº”ç”¨äºå¼ é‡ `a`ã€‚
> - **è¾“å‡ºåˆ†æ**: è¾“å‡ºç»“æœå…³äº 0 **å®Œç¾å¯¹ç§°**ï¼Œè¾“å…¥ä¸º 0 æ—¶è¾“å‡ºä¹Ÿä¸º 0ï¼Œè¿™æ­£æ˜¯å…¶â€œé›¶ä¸­å¿ƒâ€çš„ä½“ç°ã€‚

### 3. `torch.relu` / `F.relu` è¯¦è§£

> [!example] `torch.relu`: ç°ä»£ç½‘ç»œçš„é»˜è®¤ä¹‹é€‰
> **æ ¸å¿ƒåŠŸèƒ½**: ä¿®æ­£çº¿æ€§å•å…ƒã€‚==è´Ÿæ•°å½’é›¶ï¼Œæ­£æ•°ä¸å˜==ã€‚æå…¶é«˜æ•ˆï¼Œå¹¶èƒ½æœ‰æ•ˆç¼“è§£æ¢¯åº¦æ¶ˆå¤±ã€‚
> ```python
> from torch.nn import functional as F
> a = torch.linspace(-1, 1, 10)
> 
> # torch.relu(a) å’Œ F.relu(a) ç»“æœå®Œå…¨ç›¸åŒ
> # tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 
> #         0.1111, 0.3333, 0.5556, 0.7778, 1.0000])
> ```
> #### ä»£ç è§£æ
> - **`torch.relu` vs `F.relu`**:
>   - ä¸¤è€…åŠŸèƒ½å®Œå…¨ç­‰ä»·ã€‚`F.relu` æ˜¯ `torch.nn.functional` æ¨¡å—ä¸­çš„ä¸€ä¸ªçº¯å‡½æ•°ã€‚
>   - è¿˜æœ‰ä¸€ä¸ªé¢å‘å¯¹è±¡çš„ç‰ˆæœ¬ `torch.nn.ReLU()` (æ³¨æ„å¤§å†™)ï¼Œå®ƒæ˜¯ä¸€ä¸ªç±»ã€‚åœ¨ç”¨ `nn.Sequential` æ­å»ºç½‘ç»œæ—¶ä½¿ç”¨ç±»ï¼Œåœ¨è‡ªå®šä¹‰ `forward` å‡½æ•°æ—¶ï¼Œä½¿ç”¨ `F.relu` æ›´å¸¸è§ã€‚
> - **è¾“å‡ºåˆ†æ**: è¾“å…¥ `a` ä¸­çš„æ‰€æœ‰è´Ÿæ•°éƒ½è¢«â€œä¿®æ­£â€ä¸º0ï¼Œæ‰€æœ‰æ­£æ•°åˆ™ä¿æŒåŸæ ·ï¼Œå®Œç¾ä½“ç°äº† `max(0, x)` çš„é€»è¾‘ã€‚

---
## ç¬¬äºŒéƒ¨åˆ†ï¼šè‡ªåŠ¨æ±‚å¯¼ä»£ç è¯¦è§£ âš™ï¸

### 1. `loss.backward()` çš„æ­£ç¡®å·¥ä½œæµç¨‹

> [!tip] ä¸€ä¸ªå¸¸è§é”™è¯¯çš„æ•…äº‹ï¼šä¸‰å¹•å‰§ ğŸ“œ
> è¿™æ®µä»£ç å®Œç¾åœ°å±•ç¤ºäº†æ–°æ‰‹åœ¨ä½¿ç”¨ `autograd` æ—¶æœ€å®¹æ˜“çŠ¯çš„é”™è¯¯ï¼Œä»¥åŠæ­£ç¡®çš„å¤„ç†æµç¨‹ã€‚
> ![[Pasted image 20250726225532.png]]
> 
> > [!danger] ç¬¬ä¸€å¹•: ç¬¬ä¸€æ¬¡å¤±è´¥ (In [19] & [21])
> > **å‰§æƒ…**: è®¡ç®— `mse` åï¼Œå°è¯•æ±‚æ¢¯åº¦ã€‚
> > **å¤±è´¥åŸå› **: è®¡ç®— `mse` æ—¶ï¼Œ`w.requires_grad` ä¸º `False`ã€‚PyTorch æ²¡æœ‰â€œå½•åˆ¶â€è®¡ç®—è¿‡ç¨‹ã€‚
> > **æ¯”å–»**: ==æ²¡æŠ¥åè¯¾ç¨‹ï¼Œå´æƒ³åœ¨æœŸæœ«è¦æˆç»©å•ã€‚==
> 
> > [!danger] ç¬¬äºŒå¹•: ç¬¬äºŒæ¬¡å¤±è´¥ (In [22] & [23])
> > **å‰§æƒ…**: å°† `w` è®¾ç½®ä¸º `requires_grad=True` åï¼Œå¯¹**ä¹‹å‰è®¡ç®—çš„æ—§ `mse`** æ±‚æ¢¯åº¦ã€‚
> > **å¤±è´¥åŸå› **: `mse` è¯ç”Ÿäºä¸€ä¸ªæœªè¢«è¿½è¸ªçš„æ—§è®¡ç®—è¿‡ç¨‹ï¼Œä¸ç°åœ¨çš„ `w` æ˜¯â€œå¤±è”â€çš„ã€‚
> > **æ¯”å–»**: ==ç°åœ¨æŠ¥äº†åï¼Œå´æ‹¿ç€ç°åœ¨çš„å­¦ç”Ÿè¯å»è¦â€œä¸Šå­¦æœŸâ€çš„æˆç»©å•ã€‚==
> 
> > [!success] ç¬¬ä¸‰å¹•: æ­£ç¡®çš„æµç¨‹ (In [24] -> [28])
> > **å‰§æƒ…**: é‡æ–°è®¡ç®— `mse`ï¼Œè°ƒç”¨ `.backward()`ï¼ŒæˆåŠŸè·å–æ¢¯åº¦ã€‚
> > **æ­£ç¡®æ­¥éª¤**:
> > 1.  **å‡†å¤‡å‚æ•°**: ç¡®ä¿ `w.requires_grad` ä¸º `True`ã€‚
> > 2.  **æ„å»ºå›¾**: **ç„¶å**ç”¨è¿™ä¸ª `w` å»è®¡ç®— `mse`ï¼Œè®© PyTorch å®Œæ•´è®°å½•ã€‚
> > 3.  **åå‘ä¼ æ’­**: åœ¨ `mse` ä¸Šè°ƒç”¨ `.backward()`ã€‚
> > 4.  **è·å–ç»“æœ**: é€šè¿‡ `w.grad` æŸ¥çœ‹å­˜å‚¨çš„æ¢¯åº¦ã€‚

### 2. `F.softmax` ä¸ `retain_graph=True`
> [!warning] ç†è§£è®¡ç®—å›¾çš„â€œé˜…åå³ç„šâ€ç‰¹æ€§ ğŸ”¥ 
> > ![[Pasted image 20250726213011.png]]
> > > **æ ¸å¿ƒæ¦‚å¿µ**: åœ¨ PyTorch ä¸­ï¼Œä¸ºäº†èŠ‚çœå†…å­˜ï¼Œè®¡ç®—å›¾åœ¨é»˜è®¤æƒ…å†µä¸‹æ˜¯**â€œä¸€æ¬¡æ€§â€**çš„ã€‚å½“ä½ è°ƒç”¨ `.backward()` æˆ– `autograd.grad()` åï¼Œç”¨äºè®¡ç®—æ¢¯åº¦çš„å›¾ç»“æ„**ä¼šè¢«ç«‹å³é”€æ¯**ã€‚ 
> > > > - **`In [35]` çš„æ½œåœ¨é”™è¯¯**: å¦‚æœä½ è¿ç»­ä¸¤æ¬¡å¯¹ `p` è°ƒç”¨ `.backward()`ï¼Œç¬¬äºŒæ¬¡å°±ä¼šæŠ¥é”™ï¼Œå› ä¸ºè®¡ç®—å›¾åœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨åå·²è¢«é‡Šæ”¾ã€‚ 
> > > > - **æ¯”å–»**: ==è®¡ç®—å›¾å°±åƒä¸€å¼ â€œé˜…åå³ç„šâ€çš„å¯†æŠ¥ï¼Œçœ‹è¿‡ä¸€æ¬¡å°±æ²¡äº†ã€‚==
> > > > - [!tip] è§£å†³æ–¹æ¡ˆ: `retain_graph=True` 
> > > > - **ä½•æ—¶ä½¿ç”¨**: ä»…åœ¨ä½ éœ€è¦å¯¹**åŒä¸€ä¸ªè®¡ç®—å›¾**è¿›è¡Œ**å¤šæ¬¡**åå‘ä¼ æ’­æˆ–æ¢¯åº¦è®¡ç®—æ—¶ã€‚
> > > > - **`In [39]` çš„æ“ä½œ**: `torch.autograd.grad(..., retain_graph=True)` 
> > > > - è¿™è¡Œä»£ç è®¡ç®—äº†æ¢¯åº¦ï¼ŒåŒæ—¶æ˜ç¡®å‘Šè¯‰ PyTorchï¼šâ€œ==è¯·åœ¨è®¡ç®—åä¿ç•™è¿™å¼ è®¡ç®—å›¾ï¼Œæˆ‘ç¨åè¿˜æœ‰ç”¨ã€‚==â€ 
> > > > - **`In [40]` çš„æˆåŠŸ**: å› ä¸ºä¸Šä¸€æ­¥ä¿ç•™äº†å›¾ï¼Œæ‰€ä»¥å¯¹å›¾çš„ç¬¬äºŒæ¬¡æ¢¯åº¦è®¡ç®—ä¹Ÿèƒ½æˆåŠŸã€‚ 
> > > > - **åº”ç”¨åœºæ™¯**: è®¡ç®—é«˜é˜¶å¯¼æ•°ã€æŸäº›å¤æ‚çš„GANè®­ç»ƒç­–ç•¥ç­‰ã€‚

---

# PyTorch .requires_grad å±æ€§æ¢³ç† (å±‚çº§ç‰ˆ)

> [!NOTE]
> `.requires_grad` æ˜¯ PyTorch ä¸­ `torch.Tensor` çš„ä¸€ä¸ªæ ¸å¿ƒå±æ€§ï¼Œç”¨äºæ§åˆ¶è‡ªåŠ¨æ±‚å¯¼ã€‚

### 1. æ ¸å¿ƒå®šä¹‰
- **å±æ€§ç±»å‹**: å¸ƒå°”å€¼ (`True` or `False`)ã€‚
- **æ ¸å¿ƒåŠŸèƒ½**: ä½œä¸º `autograd` å¼•æ“çš„å¼€å…³ï¼Œå†³å®šæ˜¯å¦è¿½è¸ªå¯¹è¯¥å¼ é‡çš„æ“ä½œå†å²ã€‚
- **é»˜è®¤å€¼**: `False`ã€‚

### 2. ä¸»è¦ä½œç”¨
- **`å¼€å¯` (`True`)**:
    - **ç›®çš„**: ä¸ºäº†è®¡ç®—æ¢¯åº¦ã€‚
    - **åº”ç”¨**: ç¥ç»ç½‘ç»œä¸­æ‰€æœ‰**å¯å­¦ä¹ çš„å‚æ•°**ï¼ˆå¦‚ `nn.Linear` å±‚çš„ `weight` å’Œ `bias`ï¼‰ã€‚è¿™äº›å‚æ•°åœ¨è®­ç»ƒä¸­éœ€è¦æ ¹æ®æ¢¯åº¦è¿›è¡Œæ›´æ–°ã€‚
- **`å…³é—­` (`False`)**:
    - **ç›®çš„**: èŠ‚çœè®¡ç®—èµ„æºï¼ˆå†…å­˜å’ŒCPUï¼‰ã€‚
    - **åº”ç”¨**:
        - è¾“å…¥æ•°æ®å’Œç›®æ ‡æ ‡ç­¾ã€‚
        - æ¨¡å‹è¯„ä¼°ï¼ˆvalidation/testingï¼‰é˜¶æ®µã€‚
        - å†»ç»“éƒ¨åˆ†ç½‘ç»œå±‚è¿›è¡Œå¾®è°ƒï¼ˆfine-tuningï¼‰ã€‚

### 3. ä½¿ç”¨æ–¹æ³•ä¸è§„åˆ™
- **è®¾ç½®æ–¹æ³•**:
    1. `x = torch.tensor([1.], requires_grad=True)` (åˆ›å»ºæ—¶)
    2. `x.requires_grad_(True)` (In-place ä¿®æ”¹)
- **ä¼ æ’­è§„åˆ™**:
    - ä¸€ä¸ªæ“ä½œçš„è¾“å‡ºå¼ é‡ï¼Œå…¶ `requires_grad` ä¼šæ˜¯ `True`ï¼Œ**å½“ä¸”ä»…å½“**å…¶è¾“å…¥å¼ é‡ä¸­**è‡³å°‘æœ‰ä¸€ä¸ª**çš„ `requires_grad` ä¸º `True`ã€‚
    - `c = a + b`
        - è‹¥ `a.requires_grad=True`, `b.requires_grad=False` -> `c.requires_grad` ä¼šæ˜¯ `True`ã€‚
- **ä¸´æ—¶ç¦ç”¨æ¢¯åº¦**:
    - ä½¿ç”¨ `with torch.no_grad():` ä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚
    - åœ¨è¯¥ä»£ç å—å†…ï¼Œæ‰€æœ‰è®¡ç®—ç»“æœçš„ `requires_grad` éƒ½ä¼šè¢«å¼ºåˆ¶è®¾ä¸º `False`ã€‚

### 4. æ¢¯åº¦å­˜å‚¨
- å½“åœ¨ä¸€ä¸ªè®¡ç®—å›¾çš„æœ€ç»ˆè¾“å‡ºï¼ˆé€šå¸¸æ˜¯ `loss`ï¼‰ä¸Šè°ƒç”¨ `.backward()` åï¼Œæ‰€æœ‰ `requires_grad=True` çš„å¶å­å¼ é‡çš„æ¢¯åº¦ä¼š**ç´¯ç§¯**åˆ°å®ƒä»¬çš„ `.grad` å±æ€§ä¸­ã€‚

> [!EXAMPLE]
> ```python
> # å®Œæ•´çš„è®­ç»ƒæµç¨‹ç¤ºæ„
> x = torch.ones(2, requires_grad=True)
> y = x + 2
> z = y * y * 3
> out = z.mean()
> 
> # out æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œå¯¹å…¶åå‘ä¼ æ’­
> out.backward()
> 
> # è®¡ç®—å‡ºçš„æ¢¯åº¦å­˜å‚¨åœ¨ x.grad ä¸­
> print(x.grad) # tensor([9., 9.])
> ```

---
# æ·±å…¥ç†è§£ API ä¸ PyTorch æ ¸å¿ƒæ¢¯åº¦API

> [!abstract] å¯¼è¯»
> æœ¬ç¬”è®°å°†ä»ä¸€ä¸ªé€šä¿—æ˜“æ‡‚çš„æ ¸å¿ƒæ¦‚å¿µâ€”â€”**ä»€ä¹ˆæ˜¯API**â€”â€”å…¥æ‰‹ï¼Œç„¶åæ·±å…¥æ¢è®¨è¿™ä¸€æ¦‚å¿µåœ¨å…·ä½“æŠ€æœ¯ï¼ˆPyTorchï¼‰ä¸­æ˜¯å¦‚ä½•åº”ç”¨çš„ï¼Œç‰¹åˆ«æ˜¯PyTorchç”¨äº**è®¡ç®—æ¢¯åº¦**çš„ä¸¤å¤§æ ¸å¿ƒAPIï¼š`.backward()` å’Œ `autograd.grad()`ã€‚

---

# æ·±å…¥ç†è§£ API ä¸ PyTorch æ ¸å¿ƒæ¢¯åº¦API

> [!abstract] å¯¼è¯»
> æœ¬ç¬”è®°å°†ä»ä¸€ä¸ªé€šä¿—æ˜“æ‡‚çš„æ ¸å¿ƒæ¦‚å¿µâ€”â€”**ä»€ä¹ˆæ˜¯API**â€”â€”å…¥æ‰‹ï¼Œç„¶åæ·±å…¥æ¢è®¨è¿™ä¸€æ¦‚å¿µåœ¨å…·ä½“æŠ€æœ¯ï¼ˆPyTorchï¼‰ä¸­æ˜¯å¦‚ä½•åº”ç”¨çš„ï¼Œç‰¹åˆ«æ˜¯PyTorchç”¨äº**è®¡ç®—æ¢¯åº¦**çš„ä¸¤å¤§æ ¸å¿ƒAPIï¼š`.backward()` å’Œ `autograd.grad()`ã€‚

---

## Part 1ï¼šæ ¸å¿ƒæ¦‚å¿µï¼šä»€ä¹ˆæ˜¯ APIï¼Ÿ

> [!NOTE] æ ¸å¿ƒæ€æƒ³ï¼šAPI å°±åƒæ˜¯é¤å…çš„èœå•
> æƒ³è±¡ä¸€ä¸‹ä½ å»é¤å…åƒé¥­ï¼š
> - **ä½ ï¼ˆé¡¾å®¢ï¼‰**ï¼šæƒ³åƒé¥­ï¼Œä½†ä¸éœ€è¦çŸ¥é“å¨æˆ¿å¦‚ä½•è¿ä½œã€‚
> - **å¨æˆ¿ï¼ˆåç«¯ç³»ç»Ÿï¼‰**ï¼šæ‹¥æœ‰é£Ÿæå’Œå¨å¸ˆï¼Œè´Ÿè´£åˆ¶ä½œèœå“ã€‚
> 
> **èœå•ï¼ˆAPIï¼‰** å°±æ˜¯è¿æ¥ä½ å’Œå¨æˆ¿çš„æ¡¥æ¢ã€‚å®ƒæ¸…æ™°åœ°å‘Šè¯‰ä½ **èƒ½ç‚¹ä»€ä¹ˆ**ã€**éœ€è¦æä¾›ä»€ä¹ˆä¿¡æ¯**ï¼ˆå¦‚è¾£åº¦ï¼‰ã€ä»¥åŠ**ä¼šå¾—åˆ°ä»€ä¹ˆ**ã€‚ä½ åªéœ€æŒ‰èœå•è§„åˆ™ç‚¹èœï¼Œå¨æˆ¿å°±ä¼šç»™ä½ ä¸Šèœã€‚

API (Application Programming Interface - åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£) å°±æ˜¯ä¸€ä»½**æ¸…æ™°çš„è¯´æ˜ä¹¦æˆ–å¥‘çº¦**ï¼Œå®ƒå®šä¹‰äº†ä¸¤ä¸ªç‹¬ç«‹çš„è½¯ä»¶ç¨‹åºä¹‹é—´å¦‚ä½•æ²Ÿé€šå’Œäº¤äº’ï¼Œè€Œæ— éœ€å…³å¿ƒå¯¹æ–¹å†…éƒ¨çš„å¤æ‚å®ç°ã€‚

![API Analogy](https://i.imgur.com/u7X5x3B.png)

### > [!tip] ä¸ºä»€ä¹ˆ API å¦‚æ­¤é‡è¦ï¼Ÿ

- **æ•ˆç‡ (Efficiency)**: æ— éœ€â€œé‡å¤é€ è½®å­â€ã€‚æƒ³ç”¨åœ°å›¾ï¼Ÿç›´æ¥è°ƒç”¨é«˜å¾·åœ°å›¾APIã€‚
- **å®‰å…¨ (Security)**: æä¾›å®‰å…¨å±éšœã€‚APIåªæš´éœ²å¿…è¦çš„åŠŸèƒ½ï¼Œéšè—äº†åç«¯ç³»ç»Ÿçš„æ•æ„Ÿéƒ¨åˆ†ï¼ˆå¦‚æ•°æ®åº“ï¼‰ã€‚
- **ä¸“ä¸šåŒ– (Specialization)**: è®©ä¸åŒå›¢é˜Ÿèƒ½ä¸“æ³¨äºå„è‡ªé¢†åŸŸï¼Œé€šè¿‡APIåä½œæ„å»ºå¼ºå¤§ç”Ÿæ€ã€‚
- **æ ‡å‡†åŒ– (Standardization)**: å®šä¹‰äº†æ ‡å‡†äº¤äº’è§„åˆ™ï¼Œè®©ä¸åŒç³»ç»Ÿå¯ä»¥è½»æ¾é›†æˆã€‚

### > [!example] ç”Ÿæ´»ä¸­çš„ API ä¾‹å­
- **å¤©æ°”é¢„æŠ¥App**: ä½ çš„Appé€šè¿‡`å¤©æ°”API`å‘æ°”è±¡å±€æœåŠ¡å™¨è¯·æ±‚æ•°æ®ã€‚
- **â€œä½¿ç”¨å¾®ä¿¡ç™»å½•â€**: ç½‘ç«™è°ƒç”¨`å¾®ä¿¡API`æ¥å®‰å…¨åœ°éªŒè¯ä½ çš„èº«ä»½ï¼Œå…¨ç¨‹æ— éœ€æš´éœ²ä½ çš„å¯†ç ç»™ç½‘ç«™ã€‚
- **åœ¨çº¿æ”¯ä»˜**: è´­ç‰©ç½‘ç«™è°ƒç”¨`æ”¯ä»˜å®/å¾®ä¿¡æ”¯ä»˜API`æ¥åˆ›å»ºå®‰å…¨çš„æ”¯ä»˜è¯·æ±‚ã€‚
- **ç¨‹åºåº“API**: è¿™æ­£æ˜¯æˆ‘ä»¬æ¥ä¸‹æ¥è¦è®¨è®ºçš„ã€‚`PyTorch`è¿™ä¸ªåº“æœ¬èº«å°±æä¾›äº†ä¸€å¥—APIï¼ˆå‡½æ•°å’Œæ–¹æ³•ï¼‰ï¼Œè®©å¼€å‘è€…èƒ½æ–¹ä¾¿åœ°ä½¿ç”¨å®ƒçš„åŠŸèƒ½ã€‚

---

## Part 2ï¼šå…·ä½“å®ä¾‹ï¼šPyTorch çš„ä¸¤å¤§æ¢¯åº¦è®¡ç®— API

> [!INFO] æ‰¿ä¸Šå¯ä¸‹
> ç°åœ¨æˆ‘ä»¬ç†è§£äº†APIæ˜¯â€œé¢„å…ˆå®šä¹‰å¥½çš„åŠŸèƒ½èœå•â€ï¼Œé‚£ä¹ˆåœ¨PyTorchè¿™ä¸ªâ€œå¨æˆ¿â€é‡Œï¼Œç”¨äºâ€œè®¡ç®—æ¢¯åº¦â€è¿™é“â€œå¤§èœâ€çš„â€œèœå•é¡¹â€ä¸»è¦æœ‰ä¸¤ä¸ªã€‚

### API 1ï¼šéšå¼ç´¯ç§¯ `.backward()`

> [!note] æ ¸å¿ƒæ€æƒ³ï¼šå¯åŠ¨å¹¶å¿˜è®° (å‘½ä»¤å¼)
> ä»ä¸€ä¸ªä»£è¡¨æœ€ç»ˆç»“æœï¼ˆé€šå¸¸æ˜¯ `loss`ï¼‰çš„æ ‡é‡å¼€å§‹ï¼Œ**å‘½ä»¤å¼åœ°**å¯åŠ¨æ•´ä¸ªè®¡ç®—å›¾çš„åå‘ä¼ æ’­ã€‚`autograd` å¼•æ“ä¼šè´Ÿè´£è®¡ç®—æ‰€æœ‰ç›¸å…³å‚æ•°çš„æ¢¯åº¦ï¼Œå¹¶å°†å®ƒä»¬**è‡ªåŠ¨å¡«å……**åˆ°å„è‡ªçš„ `.grad` å±æ€§ä¸­ã€‚

#### > [!example] PyTorch æ ‡å‡†è®­ç»ƒä»£ç 
```python
import torch

# å®šä¹‰æ¨¡å‹å‚æ•°
w = torch.randn(1, requires_grad=True)

# æ¨¡æ‹Ÿä¸€æ¬¡è®¡ç®—
x = torch.tensor([2.0])
loss = (x * w - 7.0)**2 # å‡è®¾ç›®æ ‡æ˜¯ 7

# 1. æ¸…ç©ºæ—§æ¢¯åº¦ (éå¸¸é‡è¦ï¼)
if w.grad: w.grad.zero_()
    
# 2. æ ¸å¿ƒ API è°ƒç”¨ï¼šéšå¼è®¡ç®—å¹¶ç´¯ç§¯æ¢¯åº¦
loss.backward()

# 3. ç»“æœæŸ¥çœ‹ï¼šæ¢¯åº¦å·²è‡ªåŠ¨å¡«å……åˆ° .grad å±æ€§
print(f"w çš„æ¢¯åº¦: {w.grad}")
```
#### > [!tldr] ä¼˜ç¼ºç‚¹æ€»ç»“

- **ä¼˜ç‚¹**: âœ… ç®€æ´ç›´è§‚ï¼Œå®Œç¾å¥‘åˆæ ‡å‡†è®­ç»ƒæµç¨‹ã€‚
    
- **ç¼ºç‚¹**: âš ï¸ æœ‰å‰¯ä½œç”¨ï¼ˆä¼šä¿®æ”¹`.grad`ï¼‰ï¼Œçµæ´»æ€§è¾ƒä½ã€‚
    

### API 2ï¼šæ˜¾å¼è¿”å›Â `autograd.grad()`

> [!note] æ ¸å¿ƒæ€æƒ³ï¼šå‡½æ•°å¼è°ƒç”¨ åƒè°ƒç”¨ä¸€ä¸ªæ™®é€šå‡½æ•° `gradient = f(outputs, inputs)` ä¸€æ ·ï¼Œ**æ˜¾å¼åœ°**ä¼ å…¥ä½ æƒ³è¦çš„â€œè¾“å‡ºâ€å’Œâ€œè¾“å…¥â€ï¼Œå‡½æ•°ä¼šç›´æ¥**è¿”å›**ä¸€ä¸ªåŒ…å«æ¢¯åº¦çš„å…¨æ–°å¼ é‡ï¼Œä¸ä¿®æ”¹ä»»ä½•åŸæœ‰çŠ¶æ€ã€‚

#### > [!example] PyTorch é«˜çº§åº”ç”¨ä»£ç 
```pyton
import torch

w = torch.randn(1, requires_grad=True)
x = torch.tensor([2.0])
loss = (x * w - 7.0)**2

# æ ¸å¿ƒ API è°ƒç”¨ï¼šæ˜¾å¼è®¡ç®—æ¢¯åº¦
# å®ƒè¿”å›ä¸€ä¸ªæ–°çš„å…ƒç»„ï¼Œä¸ä¿®æ”¹ w.grad
grad_tuple = torch.autograd.grad(outputs=loss, inputs=(w,))

print(f"è¿”å›çš„ w æ¢¯åº¦: {grad_tuple[0]}")
print(f"w çš„ .grad å±æ€§: {w.grad}") # .grad å±æ€§ä¿æŒä¸å˜
```
#### > [!tldr] ä¼˜ç¼ºç‚¹æ€»ç»“

- **ä¼˜ç‚¹**: âœ… çµæ´»æ€§æé«˜ï¼Œæ— å‰¯ä½œç”¨ï¼Œé€‚åˆå®ç°å¤æ‚ç®—æ³•ã€‚
    
- **ç¼ºç‚¹**: âš ï¸ ç”¨æ³•ç¨å¤æ‚ï¼Œåœ¨ç®€å•è®­ç»ƒä¸­ä¸å¦‚`.backward()`ç›´æ¥ã€‚
    

---

### > [!SUMMARY] æœ€ç»ˆå¯¹æ¯”

|ç‰¹æ€§|`.backward()`Â (éšå¼ç´¯ç§¯)|`autograd.grad()`Â (æ˜¾å¼è¿”å›)|
|---|---|---|
|**å·¥ä½œæ¨¡å¼**|**å‘½ä»¤å¼**ï¼šå¯åŠ¨æ•´ä¸ªå›¾çš„åå‘ä¼ æ’­|**å‡½æ•°å¼**ï¼šè¾“å…¥ç›®æ ‡å’Œå˜é‡ï¼Œè¾“å‡ºæ¢¯åº¦|
|**æ¢¯åº¦å»å‘**|è‡ªåŠ¨**ç´¯ç§¯**åˆ°å‚æ•°çš„Â `.grad`Â å±æ€§|ä½œä¸ºå‡½æ•°çš„**è¿”å›å€¼**ç›´æ¥è·å¾—|
|**æ ¸å¿ƒç”¨é€”**|**æ ‡å‡†ç¥ç»ç½‘ç»œè®­ç»ƒå¾ªç¯**|**é«˜çº§ç®—æ³•**ä¸**æ¢¯åº¦åˆ†æ**|
|**çŠ¶æ€ä¿®æ”¹**|**æœ‰å‰¯ä½œç”¨**Â (In-place)|**æ— å‰¯ä½œç”¨**Â (Out-of-place)|
|**é€‚åˆåœºæ™¯**|`model -> loss -> loss.backward()`|`grads = grad(loss, params)`Â åè¿›è¡Œè‡ªå®šä¹‰æ“ä½œ|
