# 学习笔记：反向传播 - 从手动推导到PyTorch实战

> [!NOTE] 核心纲要
> 我们已经知道需要用**梯度**来更新模型参数。但是，这个梯度究竟是如何从最终的“误差”一路计算回网络起点的呢？这个过程就是大名鼎鼎的**反向传播 (Backpropagation)**。
> 
> 本篇笔记将以最基础的**单个神经元**为例，完整地走一遍这个流程：
> 1.  **定义模型**：理解数据如何**前向传播**。
> 2.  **理论推导**：**手动计算**梯度，理解反向传播的原理。
> 3.  **代码实战**：看 PyTorch 如何用一行代码**自动完成**这个复杂过程。

---
## 第一部分：模型定义 - 单个神经元的前向传播 ➡️

> [!info] 一个神经元的工作流程
> ![[Pasted image 20250725000535.png]]
> **前向传播 (Forward Propagation)** 是指数据从输入层开始，一步步流向输出层的过程。
> 
> 1.  **输入 (Input)**
>     - 一组输入特征，表示为向量 $x^0 = (x^0_0, x^0_1, \dots, x^0_n)$。
> 
> 2.  **线性加权和 (Linear Combination)**
>     - 将输入与对应的权重 `w` 进行点积运算（暂时忽略偏置`b`）。
>      ![[Pasted image 20250725000615.png]]
>       $$ x^1_0 = \sum_{i=0}^{n} w^1_{i0} x^0_i $$
> 
> 3.  **激活函数 (Activation)**
>     - 将加权和的结果传入 Sigmoid 函数 `σ`，得到神经元的最终输出 `O`。
>       $$ O^1_0 = \sigma(x^1_0) $$
> 
> 4.  **计算损失 (Loss)**
>     - 将输出 `O` 与真实目标 `t` 比较，计算均方误差 `E`。
>       $$ E = \frac{1}{2}(O^1_0 - t)^2 $$

---
## 第二部分：理论核心 - 手动反向传播详解 🧠

> [!abstract] 目标：计算梯度 $\frac{\partial E}{\partial w^1_{j0}}$
> ![[Pasted image 20250725000705.png]]
> 我们的目标是找出最终误差 `E` 相对于网络中任意一个权重 $w^1_{j0}$ 的梯度。为此，我们必须使用**链式法则**，将 `E` 对 `w` 的影响链条拆解开来。
> 
> $$ \frac{\partial E}{\partial w^1_{j0}} = \underbrace{\frac{\partial E}{\partial O^1_0}}_{\text{第一环}} \cdot \underbrace{\frac{\partial O^1_0}{\partial x^1_0}}_{\text{第二环}} \cdot \underbrace{\frac{\partial x^1_0}{\partial w^1_{j0}}}_{\text{第三环}} $$
> 
> #### 分步拆解
> 
> 1.  **第一环: 损失对输出的梯度**
>     - $E = \frac{1}{2}(O^1_0 - t)^2 \implies \frac{\partial E}{\partial O^1_0} = (O^1_0 - t)$
>     - **含义**: 当前的输出值与真实值之间的误差。
> 
> 2.  **第二环: 输出对激活前的值的梯度**
>     - $O^1_0 = \sigma(x^1_0) \implies \frac{\partial O^1_0}{\partial x^1_0} = O^1_0(1 - O^1_0)$
>     - **含义**: Sigmoid 激活函数本身的梯度。
> 
> 3.  **第三环: 激活前的值对权重的梯度**
>     - $x^1_0 = \sum_i w^1_{i0} x^0_i \implies \frac{\partial x^1_0}{\partial w^1_{j0}} = x^0_j$
>     - **含义**: 与该权重 $w^1_{j0}$ 相连接的那个输入 $x^0_j$。
> 
> ---
> > [!success] 最终梯度公式
> > 将三环相乘，我们得到了最终的梯度更新公式：
> >
> > $$ \frac{\partial E}{\partial w^1_{j0}} = (O^1_0 - t) \cdot O^1_0(1 - O^1_0) \cdot x^0_j $$
> > **这个公式优美地告诉我们，对一个权重的调整量，取决于 ==整体误差==、==激活函数的梯度== 和 ==对应的输入信号== 这三者的乘积。**

---
## 第三部分：PyTorch 实战 - 自动化的高效实现 🚀

> [!example] 代码实现：理论的完美映射
> 手动推导帮助我们理解原理，而 PyTorch 的 `autograd` 则将我们从繁琐的计算中解放。下面的代码实现了与手动推导完全相同的过程。
> ![[Pasted image 20250725000851.png]]
> 
> #### 代码逐行解析
> - **`In [41]`, `[48]`**: 创建输入 `x` 和权重 `w`。最关键的一步是为 `w` 设置 `requires_grad=True`，开启梯度追踪。
> - **`In [49]`**: `o = torch.sigmoid(x @ w.t())`
>   - 这一行代码就完成了**前向传播**中的“线性加权和”与“激活”两步，得到了最终输出 `o`。
> - **`In [51]`**: `loss = F.mse_loss(...)`
>   - 计算模型输出 `o` 和目标值 `1` 之间的**损失**。
> - **`In [53]`**: `loss.backward()`
>   - **==魔法发生的地方！==** PyTorch 自动执行了我们第二部分中所有的链式法则推导，计算出 `loss` 相对于所有 `requires_grad=True` 的张量的梯度。
> - **`In [54]`**: `w.grad`
>   - 我们直接访问 `w` 的 `.grad` 属性，就能看到 PyTorch 为我们自动算好的梯度向量。这个向量的每一个值，都对应着我们辛辛苦苦手动推导出来的 $\frac{\partial E}{\partial w^1_{j0}}$。

> [!summary] 总结
> - **反向传播** 是一个利用**链式法则**，从最终损失开始，逐层向后计算梯度，从而“传播”误差信号的过程。
> - **手动推导**能帮助我们建立深刻的直觉，理解模型内部的工作机制。
> - **PyTorch Autograd** 将这个过程完全自动化，让我们能专注于设计更强大的网络架构，而不必陷入繁琐的数学计算中。==理解前者，能让我们更好地使用后者。==

---
# 为什么反向传播的目标是计算误差E对权重w的梯度？

> [!abstract] 一句话核心答案
> 因为梯度 $\frac{\partial E}{\partial w}$ 是连接“最终的、宏观的误差”与“每一个微观的、可调节的参数”之间的**唯一桥梁**。它提供了一份量化的、可执行的**“优化说明书”**，指导网络如何最高效地学习。

---

## > [!NOTE] 一、核心比喻：一个庞大的交响乐团

想象你是一位指挥家，正在指挥一个由**成千上万名乐手**组成的交响乐团。

- **乐手 (Musician)**: 对应神经网络中的每一个**权重 (weight, w)**。
- **演奏出的乐章 (Music Piece)**: 对应神经网络的**最终输出 (Prediction)**。
- **听众的反馈 “太难听了！”**: 对应模型的**最终误差 (Error, E)**。

你的**唯一目标**是：通过调整每个乐手的演奏方式，让乐章变得优美动听，即**让最终误差 E 最小化**。面对成千上万名乐手，你如何知道该调整谁、以及如何调整？

> [!TIP] “超级听力”算法：反向传播
> **反向传播**，就是你作为指挥家，发明的一种“超级听力”算法。当你听到最终那个刺耳的误差 `E` 时，这个算法能让你瞬间定位到**每一个乐手 `w`**，并得到关于他的精确**“调试报告”**。
>
> **这份“调试报告”，就是梯度 $\frac{\partial E}{\partial w}$。**

---

## > [!summary] 二、梯度 $\frac{\partial E}{\partial w}$ 提供的精确“调试报告”

这份报告包含两部分关键信息：**正负号**和**绝对值大小**。

### > [!check] 1. 梯度的正负号：指明了“调整方向”

- **如果梯度是 `正数`**：
    - **报告解读**：“乐手 `w`，你当前的声音如果再**大**一点（增大`w`），最终的乐章就会**更难听**（误差`E`会增大）。”
    - **指挥策略**：为了让乐章变好听，我应该让你声音**小**一点（**减小**`w`）。

- **如果梯度是 `负数`**：
    - **报告解读**：“乐手 `w`，你当前的声音如果再**大**一点（增大`w`），最终的乐章就会**更好听**一点（误差`E`会减小）。”
    - **指挥策略**：为了让乐章变好听，我应该让你声音**大**一点（**增大**`w`）。

> **结论一：梯度的正负号，完美地解决了“应该增大还是减小权重”的问题。**

### > [!check] 2. 梯度的绝对值大小：确定了“责任大小”

- **如果梯度`绝对值很大`**：
    - **报告解读**：“乐手 `w`，你现在是个‘关键人物’！你稍微改变一点演奏方式，都会对最终的乐章产生**巨大影响**。你对现在的糟糕演奏**负有主要责任**。”
    - **指挥策略**：我应该优先、并且幅度较大地调整你。

- **如果梯度`绝对值很小`**：
    - **报告解读**：“乐手 `w`，你现在影响不大。不管你怎么改变演奏，对最终乐章的好坏都**几乎没影响**。”
    - **指挥策略**：我暂时不用太管你，或者稍微调整一下你就行。

> **结论二：梯度的大小，完美地解决了“应该重点调整哪个权重”的问题。**

---

## > [!formula] 三、最终目的：科学地更新权重

有了这份包含“方向”和“大小”的精确报告后，我们就可以使用**梯度下降法（Gradient Descent）**来科学地更新每一个权重了。

$$ w_{\text{新}} = w_{\text{旧}} - \eta \cdot \frac{\partial E}{\partial w} $$

- $w_{\text{新}}$：乐手调整后的新状态。
- $w_{\text{旧}}$：乐手当前的状态。
- $\frac{\partial E}{\partial w}$：我们刚刚得到的“调试报告”（梯度）。
- $\eta$ (**学习率**): 指挥家的“调整力度”。它是一个很小的正数，用来控制每次调整的步子大小，防止调整过猛。

> [!INFO] 公式中的减号 (-)
> 注意公式里的**减号**，它完美地执行了我们的指挥策略：
> - 当梯度为正时（意味着增大w会增大误差），我们用`w - (正数)`，即减小`w`。
> - 当梯度为负时（意味着增大w会减小误差），我们用`w - (负数)`，即增大`w`。

---

## > [!tldr] 结论

**反向传播的目标之所以是找出最终误差 `E` 相对于网络中任意一个权重 `w` 的梯度，是因为：**

**梯度 $\frac{\partial E}{\partial w}$ 是连接“最终的、宏观的误差”与“每一个微观的、可调节的参数”之间的唯一桥梁。它提供了一份量化的、可执行的“优化说明书”，指导着整个网络如何从一个糟糕的状态，一步步、系统性地、最高效地向一个更好的状态进行“学习”和“进化”。**

**没有梯度，所谓的“学习”就成了毫无方向的随机乱猜。**