# 🧠 神经网络核心知识点笔记

> [!abstract] 学习路径总览
> 这份笔记将按照一个完整的项目流程来组织，带你走过从定义问题到最终应用的每一步：
> **问题定义 -> 模型构建 -> 模型训练 -> 模型应用**

---

## 1. 🎯 问题定义：识别手写数字 (MNIST)
(**Modified National Institute of Standards and Technology database**)
> [!note] 我们的起点和目标
> (源自: `DL is NOT a Toy.jpg`)

- **🎯 目标**: 我们的任务是训练一个模型，让它能够识别图片中的手写数字 (0 到 9)。
- **📚 数据集 (Dataset)**: 使用著名的 **MNIST** 数据集。
    - **内容**: 每个数字 (0-9) 都有约7000张手写体图片。
    - **图片规格**: 每张图片都是一个 `28x28` 像素的灰度图。
    - **数据划分**: 数据集被分为两部分：
        - **训练集 (Training set)**: **60,000** 张图片，用于训练模型。
        - **测试集 (Test set)**: **10,000** 张图片，用于在模型训练完成后评估其性能。

![[Pasted image 20250723221551.png]]

---

## 2. ⚙️ 模型构建：从线性函数到三层神经网络
> [!info] 搭建我们的“大脑”
> (源自: `NO deep learning, just function mapping.jpg`, `Non-linear Factor.jpg`)
>
> 我们的模型本质上是一个“函数映射”，它接收一个输入（图片），经过一系列计算，输出一个结果（分类）。

### a. 输入数据展平 (Input Flattening)

电脑无法直接理解 `28x28` 的二维图片，所以我们首先要将其**“展平”(Flatten)**成一个一维长向量。
- **计算**: $28 \times 28 = 784$
- **输入向量 $X$**: `X` 是一个包含784个元素的一维向量，代表了一张图片的所有像素值。
    - 维度: `[1, 784]`

### b. 核心构建块：线性层 + 激活函数

神经网络由多个“层”堆叠而成，每一层的核心是两个部分：

1.  **线性变换 (Linear Transformation)**:
    - **公式**: $y = Wx + b$
    - `W` (**权重 Weights**): 一个矩阵，可以被看作是特征的“重要性”或“连接强度”。
    - `b` (**偏置 Biases**): 一个向量，用于微调输出，增加模型的灵活性。

2.  **非线性激活 (Non-linear Activation)**:
> [!tip] 为什么需要非线性？
> 这是深度学习的**关键**！如果没有非线性激活函数，无论你堆叠多少层线性网络，其效果都等同于一个单层的线性网络，因此无法学习复杂的模式。

    - 常用函数:
        - ReLU (Rectified Linear Unit): 公式为 $ReLU(z) = max(0, z)$。它非常简单高效：小于0的值变为0，大于0的值保持不变。
        - Sigmoid: 将数值压缩到 `(0, 1)` 区间，常用于表示概率（图中也画出了它的S形曲线）。

![[Pasted image 20250723221645.png]]

### c. 构建一个三层神经网络

我们将三个这样的“层”连接起来，形成一个完整的前向传播路径：

- **第一层 (Hidden Layer 1)**:
    - `H1 = relu(X @ W1 + b1)`
    - `X` (输入): `[1, 784]`
    - `W1` (权重): `[784, d1]` (d1是自定义的神经元数量)
    - `b1` (偏置): `[d1]`
    - `H1` (输出): `[1, d1]`

- **第二层 (Hidden Layer 2)**:
    - `H2 = relu(H1 @ W2 + b2)`
    - `H1` (输入): `[1, d1]`
    - `W2` (权重): `[d1, d2]` (d2是自定义的神经元数量)
    - `b2` (偏置): `[d2]`
    - `H2` (输出): `[1, d2]`

- **第三层 (Output Layer)**:
    - `H3 = H2 @ W3 + b3`  *(注意：输出层通常在计算损失前不加ReLU)*
    - `H2` (输入): `[1, d2]`
    - `W3` (权重): `[d2, 10]` (输出维度必须是10，因为有10个类别0-9)
    - `b3` (偏置): `[10]`
    - `H3` or `pred` (最终预测): `[1, 10]`

![[Pasted image 20250723221806.png]]

---

## 3. 📉 训练模型：如何让模型学习
> [!warning] 让模型从错误中进步
> (源自: `Loss?.jpg`, `Gradient Descent.jpg`)
>
> 模型建好了，但里面的 `W` 和 `b` 都是随机的。我们需要一个方法来衡量模型的好坏，并指导它去优化这些参数。

### a. 损失函数 (Loss Function): 衡量“错得有多离谱”

- **目标 (Y)**: 我们需要一个标准答案来和模型的预测作比较。这个标准答案 `Y` 使用 **One-Hot 编码**。
> [!example] 什么是 One-Hot 编码?
> 一种将类别标签转换为向量的方法。向量的长度等于类别总数，只有对应类别的位置为1，其余为0。
> ```
> 标签 1 => [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]
> 标签 3 => [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
> ```

- **计算损失**: 比较模型的预测 `pred` (一个`[1, 10]`的向量，如 `[0.1, 0.8, ...]`) 和真实标签 `Y` (一个One-Hot向量)。
    - **方法**: **欧氏距离** 或 **均方误差 (MSE)**
    - **公式**: $$Loss = \sum (pred - Y)^2$$
![[Pasted image 20250723221938.png]]

### b. 优化器 (Optimizer): 如何调整参数以减少损失

- **🎯 目标**: **最小化损失函数 (minimize objective)**。
- **⚙️ 方法**: **梯度下降 (Gradient Descent)**。
    - **核心思想**: 计算损失函数对于每一个参数 (`W1, b1, W2, b2, ...`) 的**梯度**（即导数）。梯度指明了能使损失函数增长最快的方向。
    - **更新规则**: 我们沿着梯度的**相反方向**去微调参数，这样就能让损失函数逐步降低。这个过程就像“盲人下山”，一步步走到山谷（损失最低点）。
- **🛠️ 需要优化的参数**: `[W1, W2, W3]` 和 `[b1, b2, b3]`。

![[Pasted image 20250723222005.png]]

---

## 4. 🚀 应用模型：进行预测 (Inference)
> [!success] 用训练好的模型大显身手
> (源自: `Inference.jpg`, `In a nutshell.png`)
>
> 当模型训练完成后（即 `W` 和 `b` 的值已经优化好），我们就可以用它来预测新的、从未见过的图片了。

1.  **前向传播 (Forward Pass)**:
    - 将新图片 `X` 输入到训练好的网络中。
    - 执行完整的计算:
    $$pred = relu(relu(XW_1+b_1)W_2 + b_2)W_3 + b_3$$
    - 得到一个 `[1, 10]` 的预测向量 `pred`，如 `[0.1, 0.8, 0.01, 0, 0.02, ...]`。向量中的每个值可以被看作是模型认为图片属于对应类别的**“置信度分数”**。

2.  **获取最终结果 (Argmax)**:
    - 我们只关心置信度最高的那个类别。
    - **`argmax(pred)`**: 这个函数会返回预测向量 `pred` 中最大值的**索引 (index)**。
    - **示例**:
        - `pred = [0.1, 0.8, 0.01, ...]`
        - 最大值是 `0.8`，它的索引位置是 `1`。
        - 因此，最终预测的**标签就是 `1`**。

![[Pasted image 20250723222042.png]]![[Pasted image 20250723222057.png]]

---
# 🎯 Argmax之后：一个预测结果的四大核心用途

> [!faq] 核心问题
> `argmax` 函数帮我们找到了置信度最高的类别，得到了一个预测标签（比如 `1`）。那么，这个看似简单的判断结果，究竟有什么用呢？

这个判断是连接**抽象数学模型**和**现实世界应用**的桥梁，其价值体现在以下四个层面：

---

> [!success] ### 1. 最直接的用途：分类与决策 (Classification & Decision)
> 这是它的核心使命。`argmax` 的结果就是模型对问题的最终回答。
> 
> - **垃圾邮件过滤**: `argmax` 输出 `1`（垃圾邮件）或 `0`（正常邮件）。这个结果直接决定了这封邮件是进入你的**收件箱**还是**垃圾箱**。
> - **人脸识别门禁**: `argmax` 输出 `135`（代表员工小张的ID）。这个结果直接决定了门是**“打开”**还是**“保持关闭”**。
> - **自动驾驶识别交通标志**: `argmax` 输出 `0`（停止标志）或 `1`（限速50）。这个结果直接决定了汽车下一步是**“刹车”**还是**“调整速度”**。
> 
> **简单说，这个判断就是机器的“眼睛”，它看到了、识别了，并给出了一个明确的结论。**

---

> [!info] ### 2. 至关重要的用途：评估模型性能 (Performance Evaluation)
> 光有结论还不够，我们怎么知道这个结论有多可靠？`argmax` 的结果是衡量模型好坏的基石。在开发阶段，我们会用**测试数据**来“考验”模型。
> 
> - **过程**:
>   1.  拿一张**真实标签是“1”**的图片给模型。
>   2.  模型进行计算，`argmax` 输出的预测标签是 `1`。
>   3.  我们一比较：**预测(1) == 真实(1)**。这是一次**正确**的预测！
>   4.  再拿一张**真实标签是“8”**的图片给模型。
>   5.  模型计算后，`argmax` 输出的预测标签是 `3`。
>   6.  我们一比较：**预测(3) != 真实(8)**。这是一次**错误**的预测。
> 
> - **用途**:
>   通过对成千上万张测试图片重复这个过程，我们可以计算出模型的**准确率 (Accuracy)**。比如，模型在10,000次测试中答对了9,900次，那它的准确率就是 **99%**。这个指标，是决定这个模型能否上线的关键依据。
> 
> **没有 `argmax` 给出的明确预测，我们就无法量化模型的性能。**

---

> [!example] ### 3. 最具潜力的用途：触发自动化系统 (Triggering Automation)
> 在复杂的系统中，模型的判断往往不是终点，而是一个**自动化流程的起点**。
> 
> - **工业质检**: 生产线上的摄像头拍下产品照片，模型进行判断。
>   - `argmax` 输出 `0` (合格) -> 产品继续前进。
>   - `argmax` 输出 `1` (有瑕疵) -> **触发**一个信号，让机械臂将这个产品从产线上移除。
> 
> - **内容审核**: 社交平台用模型分析用户评论。
>   - `argmax` 输出 `0` (正常) -> 评论正常显示。
>   - `argmax` 输出 `1` (违规) -> **触发**系统自动隐藏该评论，并将其加入人工审核队列。
> 
> **在这里，模型的判断成了一个“开关”，用来驱动现实世界中的其他设备或软件执行特定任务。**

---

> [!example] ### 4. 最常见的用途：与用户进行交互 (User Interaction)
> 很多时候，模型的判断结果是直接呈现给用户，为用户提供服务的。
> 
> - **购物App“以图搜图”**: 你上传一张椅子的照片。
>   - 模型进行分析，`argmax` 判断出这张图片属于“北欧风单人沙发”这个类别。
>   - **用途**: App 根据这个判断结果，立即为你展示所有“北欧风单人沙发”的**商品列表**。
> 
> - **手机相册自动分类**: 你的手机在后台默默地分析你的照片。
>   - `argmax` 对每张照片进行判断，打上“美食”、“风景”、“聚会”、“文档”等标签。
>   - **用途**: 当你打开相册搜索“美食”时，所有被模型这样判断过的照片都会被**筛选出来**，方便你查找。

---

> [!summary] 总结
> `argmax` 判断完后的那个看似简单的“标签”，其用途是：
> 1.  **回答问题**：给出最直接的分类结果。
> 2.  **衡量好坏**：作为评估模型准确率的依据。
> 3.  **驱动行为**：作为自动化流程的触发器。
> 4.  **服务人类**：作为与用户交互、提供信息的基础。