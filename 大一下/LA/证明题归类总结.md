### 证明题分类与解答

#### 1. 关于特征向量和线性独立性

**题目来源：**
* **2022年试卷 Q7**：Given that $\lambda_{1}$ and $\lambda_{2}$ are distinct eigenvalues of matrix A, u and v are eigenvectors of A corresponding to $\lambda_{1}$ and $\lambda_{2}$ respectively, prove that $u+v$ is not an eigenvector of A. 
* **2024年试卷 Q7**：Suppose that $\lambda_{1}$ and $\lambda_{2}$ are distinct eigenvalues of matrix A. Further suppose that, u and v are eigenvectors of A corresponding to $\lambda_{1}$ and $\lambda_{2}$ respectively. Therefore, prove that $u+v$ is not an eigenvector of A. 
* **2022年试卷 Q8**：A is an $n\times n$ matrix n, $\alpha\in R^{n}$. If $A^{m-1}\alpha\ne0$, $A^{m}\alpha=0$ prove a, Aa, $A^{2}\alpha,\cdot\cdot\cdot,A^{m-1}\alpha$ are linear independent. 
* **2023年试卷 Q8**：Let $v_{1}$ $v_{2}$ $v_{3}$ be linearly dependent, and $v_{2}$ $v_{3}$, $v_{4}$ linearly independent. Show that $v_{1}$ must a linear combination of $v_{2}$ and $v_{3}$. 
* **2024年试卷 Q8**：Let $\{\alpha_{1},\alpha_{2},\cdot\cdot\cdot,\alpha_{s}\}$ be a basis of null space of A. The vector ẞ is not a solution to the system $AX=0$, namely $A\beta\ne0$ Prove that $\{\beta,\beta+\alpha_{1},\beta+\alpha_{2},\cdot\cdot\cdot,\beta+\alpha_{s}\}$ is linearly independent. 

**解答与思路总结：**

**(1.1) Q7 (2022 & 2024): 证明 $u+v$ 不是特征向量**

* **题目**：设 $\lambda_1$ 和 $\lambda_2$ 是矩阵 A 的不同特征值，u 和 v 分别是对应于 $\lambda_1$ 和 $\lambda_2$ 的特征向量，证明 $u+v$ 不是 A 的特征向量。 
* **精简解答**：
    假设 $u+v$ 是 A 的特征向量，对应特征值 $\lambda$。那么 $A(u+v) = \lambda(u+v)$。
    由于 $Au = \lambda_1 u$ 和 $Av = \lambda_2 v$，则 $A(u+v) = \lambda_1 u + \lambda_2 v$。
    因此，$\lambda_1 u + \lambda_2 v = \lambda u + \lambda v$，即 $(\lambda_1 - \lambda)u + (\lambda_2 - \lambda)v = 0$。
    已知不同特征值对应的特征向量是线性无关的，所以 $u$ 和 $v$ 线性无关。
    因此，系数必须为零：$\lambda_1 - \lambda = 0 \Rightarrow \lambda = \lambda_1$ 且 $\lambda_2 - \lambda = 0 \Rightarrow \lambda = \lambda_2$。
    这推出 $\lambda_1 = \lambda_2$，与题目条件“$\lambda_1$ 和 $\lambda_2$ 是不同特征值”矛盾。 
    故假设不成立，$u+v$ 不是 A 的特征向量。
* **思路与总结**：
    * **思路**：采用反证法。假设结论不成立（即 $u+v$ 是特征向量），然后利用特征向量的定义和“不同特征值对应的特征向量线性无关”这一重要性质，推导出与题目条件矛盾的结果。
    * **总结**：这是线性代数中关于特征值和特征向量关系的经典证明。关键点在于利用线性无关性，将线性组合的系数强制为零，从而揭示矛盾。

**(1.2) Q8 (2022): 证明 $\{\alpha, A\alpha, \dots, A^{m-1}\alpha\}$ 线性独立**

* **题目**：A 是一个 $n \times n$ 矩阵，$\alpha \in R^n$。如果 $A^{m-1}\alpha \neq 0$，$A^m\alpha = 0$，证明 $\alpha, A\alpha, A^2\alpha, \dots, A^{m-1}\alpha$ 线性独立。 
* **精简解答**：
    假设存在标量 $c_0, c_1, \dots, c_{m-1}$ 不全为零，使得 $c_0\alpha + c_1A\alpha + \dots + c_{m-1}A^{m-1}\alpha = 0$。
    对该式两边左乘 $A^{m-1}$：
    $c_0A^{m-1}\alpha + c_1A^m\alpha + \dots + c_{m-1}A^{2m-2}\alpha = 0$。
    由于 $A^m\alpha = 0$，所以对于任何 $k \ge m$ 都有 $A^k\alpha = 0$。因此，除第一项外，所有项都为零。
    $c_0A^{m-1}\alpha = 0$。
    因为 $A^{m-1}\alpha \neq 0$，所以 $c_0 = 0$。 
    将 $c_0=0$ 代回原式，并重复上述过程：对 $c_1A\alpha + \dots + c_{m-1}A^{m-1}\alpha = 0$ 两边左乘 $A^{m-2}$。
    这将依次推导出 $c_1=0, c_2=0, \dots, c_{m-1}=0$。
    因此，所有系数都必须为零，与最初假设矛盾。故向量集线性独立。 
* **思路与总结**：
    * **思路**：采用反证法。假设向量集线性相关，则存在非零系数的线性组合为零。通过巧妙地左乘矩阵 $A$ 的适当次幂，利用 $A^m\alpha = 0$ 和 $A^{m-1}\alpha \neq 0$ 的条件，逐个强制系数为零，最终推导出所有系数都为零的矛盾。
    * **总结**：这是证明Krylov子空间基线性独立性的标准方法，也是理解最小多项式概念的基础。关键是利用矩阵幂对向量的作用效果和非零/零向量的性质。

**(1.3) Q8 (2023): 证明 $v_1$ 是 $v_2, v_3$ 的线性组合**

* **题目**：设 $v_1, v_2, v_3$ 线性相关，且 $v_2, v_3, v_4$ 线性独立。证明 $v_1$ 必须是 $v_2$ 和 $v_3$ 的线性组合。 
* **精简解答**：
    因为 $v_1, v_2, v_3$ 线性相关，所以存在不全为零的标量 $c_1, c_2, c_3$ 使得 $c_1v_1 + c_2v_2 + c_3v_3 = 0$。
    我们需要证明 $c_1 \neq 0$。
    假设 $c_1 = 0$。那么 $c_2v_2 + c_3v_3 = 0$。
    由于 $v_2, v_3, v_4$ 线性独立，所以其子集 $v_2, v_3$ 也线性独立。
    因此，由 $c_2v_2 + c_3v_3 = 0$ 且 $v_2, v_3$ 线性独立可推出 $c_2 = 0$ 且 $c_3 = 0$。
    这与最初的假设“$c_1, c_2, c_3$ 不全为零”相矛盾。
    所以，$c_1$ 必须不为零 ($c_1 \neq 0$)。
    既然 $c_1 \neq 0$，我们可以将 $v_1$ 表示为：
    $c_1v_1 = -c_2v_2 - c_3v_3$
    $v_1 = (-\frac{c_2}{c_1})v_2 + (-\frac{c_3}{c_1})v_3$
    这表明 $v_1$ 是 $v_2$ 和 $v_3$ 的线性组合。
* **思路与总结**：
    * **思路**：利用线性相关和线性独立的定义。从线性相关性出发，写出线性组合为零的方程。通过反证法证明关键系数 ($c_1$) 不为零，然后进行移项和系数化简，即可得到所需结论。
    * **总结**：这揭示了在存在线性相关关系时，若部分向量线性独立，则另一部分向量可被表示为线性组合。这是理解向量空间基和维数的重要基础。

**(1.4) Q8 (2024): 证明 $\{\beta,\beta+\alpha_{1},\beta+\alpha_{2},\cdot\cdot\cdot,\beta+\alpha_{s}\}$ 线性独立**

* **题目**：设 $\{\alpha_{1},\alpha_{2},\cdot\cdot\cdot,\alpha_{s}\}$ 是A的零空间的一组基。向量 $\beta$ 不是系统 $AX=0$ 的解，即 $A\beta\ne0$。证明 $\{\beta,\beta+\alpha_{1},\beta+\alpha_{2},\cdot\cdot\cdot,\beta+\alpha_{s}\}$ 线性独立。 
* **精简解答**：
    假设存在标量 $c_0, c_1, \dots, c_s$ 不全为零，使得 $c_0\beta + c_1(\beta+\alpha_1) + \dots + c_s(\beta+\alpha_s) = 0$。
    展开并重组：
    $(c_0+c_1+\dots+c_s)\beta + c_1\alpha_1 + \dots + c_s\alpha_s = 0$。 (1)
    令 $C = c_0+c_1+\dots+c_s$。
    $C\beta + c_1\alpha_1 + \dots + c_s\alpha_s = 0$。 
    对 (1) 式两边左乘矩阵 A：
    $A(C\beta + c_1\alpha_1 + \dots + c_s\alpha_s) = A(0)$
    $CA\beta + c_1A\alpha_1 + \dots + c_sA\alpha_s = 0$。
    由于 $\alpha_1, \dots, \alpha_s$ 是零空间的一组基，所以 $A\alpha_i = 0$ 对于所有 $i=1, \dots, s$。
    因此，$CA\beta = 0$。
    已知 $A\beta \neq 0$ (因为 $\beta$ 不是 $AX=0$ 的解)。 
    所以，为了使 $CA\beta = 0$ 成立，必然有 $C = 0$。
    将 $C=0$ 代回方程 (1)：
    $c_1\alpha_1 + \dots + c_s\alpha_s = 0$。
    由于 $\{\alpha_1, \dots, \alpha_s\}$ 是A的零空间的一组基，基向量是线性独立的。
    因此，所有系数 $c_1, \dots, c_s$ 都必须为零。
    最后，将 $c_1=\dots=c_s=0$ 和 $C=0$ 代回 $C = c_0+c_1+\dots+c_s$，得到 $0 = c_0 + 0 + \dots + 0 \Rightarrow c_0=0$。
    所以，所有系数 $c_0, c_1, \dots, c_s$ 都为零。这与最初的假设矛盾。
    故向量集 $\{\beta,\beta+\alpha_{1},\beta+\alpha_{2},\cdot\cdot\cdot,\beta+\alpha_{s}\}$ 线性独立。 
* **思路与总结**：
    * **思路**：利用线性独立性的定义，假设线性相关并构造线性组合为零的方程。关键步骤是巧妙地左乘矩阵A，利用零空间基的性质和$\beta$不在零空间中的条件，逐步推导出所有系数为零。
    * **总结**：这证明了零空间外的向量与零空间基向量组合后仍能保持线性独立性，这对于理解向量空间的分解和线性变换的性质有帮助。

#### 2. 关于实对称矩阵的性质

**题目来源：**
* **2021年试卷 Q4(b)**：If A is a real symmetric matrix, and $A^{2}=0,$ prove that $A=0$. 

**解答与思路总结：**

**(2.1) Q4(b) (2021): 证明实对称矩阵 $A^2=0 \Rightarrow A=0$**

* **题目**：如果 A 是一个实对称矩阵，并且 $A^2=0$，证明 $A=0$。 
* **精简解答**：
    **方法一：利用特征值**
    由于 A 是实对称矩阵，它可正交对角化。这意味着存在正交矩阵 $P$ 和对角矩阵 $D$ 使得 $A=PDP^T$。D 的对角线元素是 A 的实数特征值。
    由 $A^2=0$ 可得 $(PDP^T)(PDP^T) = 0 \Rightarrow PD^2P^T = 0$ (因为 $P^TP=I$)。
    由于 $P$ 可逆，左乘 $P^T$ 右乘 $P$ 得到 $D^2=0$。
    如果 $D = \text{diag}(\lambda_1, \dots, \lambda_n)$，则 $D^2 = \text{diag}(\lambda_1^2, \dots, \lambda_n^2)$。
    $D^2=0$ 意味着 $\lambda_i^2 = 0$ 对于所有 $i$，所以所有特征值 $\lambda_i = 0$。
    因此，$D=0$，进而 $A=P(0)P^T=0$。
    **方法二：利用范数**
    对于任意向量 $x$，考虑 $\|Ax\|^2 = (Ax)^T(Ax)$。
    由于 A 是实对称矩阵，有 $A^T=A$。
    所以，$\|Ax\|^2 = x^T A^T A x = x^T A A x = x^T A^2 x$。
    已知 $A^2=0$，所以 $\|Ax\|^2 = x^T (0) x = 0$。
    因此，$Ax=0$ 对于所有向量 $x$ 都成立。这意味着 $A=0$。 
* **思路与总结**：
    * **思路**：
        * **方法一**：利用实对称矩阵可正交对角化这一核心性质，将矩阵的平方为零的问题转化为对角矩阵的平方为零的问题，从而推导出所有特征值为零，进而矩阵为零。
        * **方法二**：利用内积的性质和实对称矩阵的 $A^T=A$ 性质，将 $\|Ax\|^2$ 转化为涉及 $A^2$ 的形式，直接推导出 $Ax=0$。
    * **总结**：这是实对称矩阵的一个重要性质，强调了其正定性（或半正定性）的内在联系。方法二通常更简洁和优雅。