
# 梯度下降算法 (Gradient Descent)

> [!note] 核心比喻：蒙着眼睛下山 🦯
> 
> - **你的目标：** 找到山谷的最低点。
>     
> - **你的能力：** 只能通过脚感受当前地面的**坡度**（梯度），并判断哪个方向是**最陡的下坡路**。
>     
> - **你的动作：** 朝着最陡的下坡方向，小心翼翼地迈出一小步，并重复这个过程。
>     

**标签:** #MachineLearning #Algorithm #Optimization #DeepLearning

---

## 🎯 核心目标

> [!question] 我们要解决什么问题？
> 
> 如何找到一组最佳的模型参数（例如神经网络中的权重和偏差），使得模型的**“错误”或“损失” (Loss) 最小化**？

---

## ⚙️ 核心三要素

梯度下降的每一步都由这三个关键部分决定。

> [!info] 1. 损失函数 (Loss Function) 📉
> 
> - **定义：** 一个衡量模型“做得有多差”的数学函数。损失值越大，模型预测越不准。
>     
> - **目标：** 调整模型参数，找到让这个函数值最小的点。
>     
> - **图例：** 在你的图片中，`loss = x² * sin(x)` 就是一个损失函数，那条蓝色的U型曲线就是它的图像。右侧的等高线图则是一个二维损失函数的俯视图，中心点就是最小值。
>     

> [!tip] 2. 梯度 (Gradient) 🧭
> 
> - **定义：** 损失函数在某一点上对各个参数的导数。
>     
> - **直观理解：** 梯度是一个向量，它指向函数值**上升最快**的方向（“上山”最快的方向）。
>     
> - **关键用法：** 我们不“上山”，而是要“下山”。因此，我们沿着梯度的**反方向** `-∇f(x)` 前进，这就是下降最快的方向。
>     
> - **图例：** 你图片中手写的 `y' = ...` 就是求梯度的过程。左侧图中的小红箭头就代表了“下山”的负梯度方向。
>     

> [!important] 3. 学习率 (Learning Rate / Step Size) 🚶‍♂️
> 
> - **定义：** 决定了我们每次沿着“下山”方向**迈出的步子有多大**。它是一个需要我们手动设置的超参数。
>     
> - **影响：**
>     
>     - **学习率太小 (Too Small):** 就像你图片左侧的图 (`step = 0.005`)，虽然方向对，但步子太小，下山速度很慢。
>         
>     - **学习率太大 (Too Large):** 就像你图片中间的图 (`step = 0.05`)，步子太大，容易一步跨过最低点，在山谷两侧来回“震荡”，甚至可能离目标越来越远。
>         

> [!example] 核心更新公式
> 
> 梯度下降的每一步都遵循这个简单的规则：
> 
> 新位置 = 当前位置 - 学习率 × 梯度
> 
> Code snippet
> 
> ```
> x_{new} = x_{current} - \eta \cdot \nabla f(x)
> ```
> 
> _这里的 `η` (eta) 就是学习率。_

---

## 🗺️ 算法流程总结

> [!todo] 梯度下降的四个步骤
> 
> 1. **随机初始化：** 在“山”上随机选一个点作为出发点。
>     
> 2. **计算梯度：** 计算当前位置的梯度，找到“下山”最快的方向。
>     
> 3. **更新参数：** 沿着负梯度方向，迈出由“学习率”决定的一小步，到达新位置。
>     
> 4. **循环迭代：** 重复第2步和第3步，直到到达山谷底部（梯度接近于0），或达到预设的迭代次数。
>     

---

## ✨ 进阶：梯度下降的变体 (Optimizers)

> [!abstract] 为什么有这么多不同颜色的线？
> 
> 你图片右上角的图展示了标准梯度下降（sgd）的多种改进版，被称为优化器 (Optimizers)。
> 
> 它们都是为了解决标准梯度下降可能遇到的问题（如下山慢、路线曲折、卡在某个平坦区域等）。例如：
> 
> - **Momentum (动量法):** 模拟物理世界的惯性，让“下山”的小球冲过平坦区域，加速收敛。
>     
> - **Adagrad / RMSprop / Adam:** 能够智能地为不同参数调整学习率，让下降过程更平稳高效。
>     
> 
> 这些不同颜色的轨迹，就代表了不同“下山策略”的智能小球，最终都汇聚到了最低点 ★。

![[屏幕截图 2025-07-23 194913.png]]