# 深度学习知识体系大纲 (从零到实践)

> [!abstract] 学习路线图总览
> 本大纲旨在为深度学习初学者提供一个系统、清晰的学习路径。我们将从最基础的数学和编程知识开始，逐步深入到机器学习、深度学习核心概念，再到主流网络架构和前沿应用。每个模块都包含核心知识点和学习目标。

---

## > [!NOTE] 模块一：基石 —— 数学与编程基础

> [!todo] 学习目标：打下坚实的地基，理解模型背后的语言。

- **1. 线性代数 (Linear Algebra)**
    - `向量 (Vectors)`: 数据的基本表示。
    - `矩阵 (Matrices)`: 权重、数据集的组织形式。
    - `矩阵乘法`: 神经网络中信息传递的核心运算。
    - `张量 (Tensors)`: 多维数据容器，深度学习框架的基本单位。
- **2. 微积分 (Calculus)**
    - `导数 (Derivatives)`: 理解变化率。
    - `链式法则 (Chain Rule)`: **反向传播算法的数学灵魂**。
    - `偏导数 (Partial Derivatives)`: 理解单个参数对总误差的影响。
    - `梯度 (Gradients)`: 多变量函数变化最快的方向，**优化的核心**。
- **3. 概率与统计 (Probability & Statistics)**
    - `概率分布`: 理解数据和模型输出的特性。
    - `均值、方差`: 描述数据的基本统计量。
    - `最大似然估计`: 理解损失函数设计的思想来源之一。
- **4. Python 编程与核心库**
    - `Python 基础语法`: 必备的编程语言。
    - `NumPy`: 高效的数值计算库，处理矩阵和张量的利器。
    - `Pandas`: 数据分析和预处理库。
    - `Matplotlib / Seaborn`: 数据可视化库，用于观察结果和调试。

---

## > [!NOTE] 模块二：入门 —— 经典机器学习

> [!todo] 学习目标：理解“学习”的基本范式，为深度学习铺路。

- **1. 机器学习核心概念**
    - `监督学习 vs. 无监督学习 vs. 强化学习`
    - `特征 (Features) vs. 标签 (Labels)`
    - `训练集、验证集、测试集`
- **2. 经典模型**
    - `线性回归 (Linear Regression)`: 理解如何拟合一条线。
    - `逻辑回归 (Logistic Regression)`: 从回归到分类的第一步，理解Sigmoid函数。
- **3. 训练中的核心问题**
    - `损失函数 (Loss Function)`: 如何量化模型的“错误”。
    - `梯度下降 (Gradient Descent)`: 如何根据“错误”来优化模型。
    - `过拟合 (Overfitting) 与 欠拟合 (Underfitting)`: 模型训练最常见的问题。
    - `正则化 (Regularization - L1, L2)`: 防止过拟合的常用技术。

---

## > [!NOTE] 模块三：核心 —— 深度神经网络基础

> [!todo] 学习目标：真正踏入深度学习的大门，理解神经网络的工作原理。

- **1. 从神经元到神经网络**
    - `人工神经元模型`: 加权和 -> 激活函数。
    - `多层感知机 (MLP)`: 如何将神经元堆叠成“层”和“网络”。
- **2. 关键组件**
    - `激活函数 (Activation Functions)`:
        - `Sigmoid`: 用于二分类。
        - `ReLU`: 现代网络最常用的激活函数。
        - `Softmax`: 用于多分类，将输出转为概率。
    - `损失函数 (Loss Functions)`:
        - `均方误差 (MSE)`: 用于回归问题。
        - `交叉熵 (Cross-Entropy)`: 用于分类问题。
- **3. 训练的“黑魔法”**
    - `反向传播 (Backpropagation)`: **神经网络学习的灵魂算法**，高效计算梯度。
    - `优化器 (Optimizers)`: 梯度下降的变种，如 `SGD`, `Adam`，让“下山”更聪明、更快。
    - `学习率 (Learning Rate)`: 控制学习步伐大小的关键超参数。

---

## > [!NOTE] 模块四：进阶 —— 主流网络架构

> [!todo] 学习目标：掌握处理不同类型数据（图像、序列）的“专家”网络。

- **1. 卷积神经网络 (Convolutional Neural Networks - CNNs)**
    - `应用领域`: **图像识别**、物体检测、图像分割。
    - `核心概念`: `卷积层 (Convolution)`, `池化层 (Pooling)`, `感受野 (Receptive Field)`。
    - `经典模型`: `LeNet`, `AlexNet`, `VGG`, `ResNet`。
- **2. 循环神经网络 (Recurrent Neural Networks - RNNs)**
    - `应用领域`: **序列数据处理**，如自然语言处理、时间序列预测。
    - `核心概念`: `循环结构`, `记忆`, `梯度消失/爆炸`问题。
- **3. 长短期记忆网络 (Long Short-Term Memory - LSTM) & GRU**
    - `目的`: RNN的改进版，通过`门控机制`解决长期依赖和梯度问题。
- **4. Transformer 与 注意力机制 (Attention Mechanism)**
    - `应用领域`: **现代NLP的基石**，也逐渐应用于CV等领域。
    - `核心概念`: `自注意力 (Self-Attention)`, `位置编码`, `多头注意力`。
    - `经典模型`: `BERT`, `GPT` 系列。

---

## > [!NOTE] 模块五：前沿与实践

> [!todo] 学习目标：将理论应用于实践，并了解当前最热门的研究方向。

- **1. 深度学习框架实践**
    - `PyTorch` (推荐，更灵活) 或 `TensorFlow/Keras`。
    - `搭建、训练、评估`一个完整的模型。
- **2. 生成式AI (Generative AI)**
    - `生成对抗网络 (GANs)`: 生成以假乱真的图像。
    - `变分自编码器 (VAEs)`: 另一种生成模型。
    - `扩散模型 (Diffusion Models)`: 当前最火的图像生成技术 (Midjourney, Stable Diffusion)。
- **3. 强化学习 (Reinforcement Learning - RL)**
    - `基本概念`: `Agent`, `Environment`, `Reward`, `Policy`。
    - `经典算法`: `Q-Learning`, `DQN`。
- **4. 模型部署与应用 (MLOps)**
    - `模型压缩与优化`: `ONNX`, `TensorRT`。
    - `部署工具`: `Docker`, `Flask/FastAPI`, `云服务 (AWS, GCP, Azure)`。

---

## > [!summary] 持续学习与进阶路径

- **阅读论文**: 从经典论文开始，逐步跟进 `arXiv` 上的最新研究。
- **参加竞赛**: `Kaggle` 等平台是检验和提升实战能力的最佳场所。
- **复现代码**: 尝试复现顶级会议论文的代码，深入理解细节。
- **关注社区**: 关注顶会 (NeurIPS, ICML, CVPR, ICLR)、顶尖研究者和实验室的动态。
- **构建项目**: 将所学知识应用于解决一个你感兴趣的实际问题，打造个人作品集。