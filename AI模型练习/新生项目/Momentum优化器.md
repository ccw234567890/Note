# 解析：“Momentum优化器”的矩阵变换模拟

**标签**: #DeepLearning #Optimizer #Momentum #LinearAlgebra #FineTuning

> [!quote] 您的原始分析
> 这行代码把“**带动量的 SGD**”注入训练循环：它记录并利用历史梯度方向（动量），按调度表控制步长（学习率），并附加 L2 正则（权重衰减），在每个 step 自动更新 **仅限分类头的参数**，从而实现高效、稳定的微调。
> ... (完整分析)

---

## 1. 我们的目标

我们将模拟在**训练步骤 `t`** 中，`Momentum` 优化器是如何根据**当前计算出的梯度 `g_t`**，并结合**历史速度 `v_{t-1}`**，来更新**权重矩阵 `W`** 的具体过程。

## 2. 登场角色与初始状态 (第 t-1 步)

我们继续使用上一篇笔记 [[解析：“分类头” (Head Net) 的矩阵变换模拟]] 中的极简设定。

#### A. 上一步的权重矩阵 $W_{t-1}$
这是 `head_net` 在本次更新**前**的“大脑状态”。
$$
W_{t-1} = \begin{bmatrix}
10 & 2 \\
10 & 1 \\
-8 & 9 \\
1  & 10
\end{bmatrix}
$$

#### B. 上一步的速度向量 $v_{t-1}$
这是动量优化器的“记忆”或“惯性”，它累积了之前的梯度方向。我们假设它是一个较小的值。
$$
v_{t-1} = \begin{bmatrix}
0.1 & -0.1 \\
0.1 & -0.2 \\
-0.2 & 0.1 \\
0.0 & 0.2
\end{bmatrix}
$$

#### C. 超参数 (Hyperparameters)
- **学习率 (lr_t)**: 假设在第 `t` 步，动态学习率的值为 `0.1`。
- **动量系数 (μ)**: `0.9`
- **权重衰减 (weight_decay, λ)**: `0.005`

---

## 3. 第 t 步的计算

假设在第 `t` 步，模型看到了一张**猫**的图片，但错误地给了“狗”一个较高的分数，导致产生了损失。经过反向传播，计算出了如下的**梯度矩阵 $g_t$**。

#### 当前梯度矩阵 $g_t$
梯度指向了能使损失**增加**最快的方向。因此，为了**减小**损失，我们需要沿着**负梯度**方向更新权重。
- **解读**:
    - “猫”列的梯度是**负数**，意味着我们应该**增加**这些权重（因为 `w - lr*g`，减去一个负数等于增加）。
    - “狗”列的梯度是**正数**，意味着我们应该**减小**这些权重。
$$
g_t = \begin{bmatrix}
-0.5 & 0.4 \\
-0.6 & 0.3 \\
0.2 & 0.5 \\
-0.4 & 0.2
\end{bmatrix}
$$

---

## 4. 模拟开始：Momentum 更新步骤

我们将遵循 MindSpore 内部的更新逻辑：
$$ v_t = \mu \cdot v_{t-1} + g_t + \lambda \cdot W_{t-1} $$
$$ W_t = W_{t-1} - \text{lr}_t \cdot v_t $$

### 第 4.1 步: 计算各项分量

**a) 动量项 (历史速度的延续)**:
$$ \mu \cdot v_{t-1} = 0.9 \times \begin{bmatrix} 0.1 & -0.1 \\ 0.1 & -0.2 \\ -0.2 & 0.1 \\ 0.0 & 0.2 \end{bmatrix} = \begin{bmatrix} 0.09 & -0.09 \\ 0.09 & -0.18 \\ -0.18 & 0.09 \\ 0.0 & 0.18 \end{bmatrix} $$

**b) 权重衰减项 (L2 正则化)**:
$$ \lambda \cdot W_{t-1} = 0.005 \times \begin{bmatrix} 10 & 2 \\ 10 & 1 \\ -8 & 9 \\ 1 & 10 \end{bmatrix} = \begin{bmatrix} 0.05 & 0.01 \\ 0.05 & 0.005 \\ -0.04 & 0.045 \\ 0.005 & 0.05 \end{bmatrix} $$

### 第 4.2 步: 更新速度向量 $v_t$

将**动量项**、**当前梯度 $g_t$** 和**权重衰减项**相加。

$$ v_t = \begin{bmatrix} 0.09 & -0.09 \\ 0.09 & -0.18 \\ -0.18 & 0.09 \\ 0.0 & 0.18 \end{bmatrix} + \begin{bmatrix} -0.5 & 0.4 \\ -0.6 & 0.3 \\ 0.2 & 0.5 \\ -0.4 & 0.2 \end{bmatrix} + \begin{bmatrix} 0.05 & 0.01 \\ 0.05 & 0.005 \\ -0.04 & 0.045 \\ 0.005 & 0.05 \end{bmatrix} $$

$$ v_t = \begin{bmatrix} -0.36 & 0.32 \\ -0.46 & 0.125 \\ -0.02 & 0.635 \\ -0.395 & 0.43 \end{bmatrix} $$
*解读：这是综合了“历史惯性”、“当前任务指引”和“保持精简”三方力量后，最终决定的“移动方向和速度”。*

### 第 4.3 步: 更新权重矩阵 $W_t$

用旧的权重，减去由“学习率”缩放后的“速度”。

$$ W_t = W_{t-1} - \text{lr}_t \cdot v_t $$
$$ W_t = \begin{bmatrix} 10 & 2 \\ 10 & 1 \\ -8 & 9 \\ 1 & 10 \end{bmatrix} - 0.1 \times \begin{bmatrix} -0.36 & 0.32 \\ -0.46 & 0.125 \\ -0.02 & 0.635 \\ -0.395 & 0.43 \end{bmatrix} $$
$$ W_t = \begin{bmatrix} 10 & 2 \\ 10 & 1 \\ -8 & 9 \\ 1 & 10 \end{bmatrix} - \begin{bmatrix} -0.036 & 0.032 \\ -0.046 & 0.0125 \\ -0.002 & 0.0635 \\ -0.0395 & 0.043 \end{bmatrix} $$

$$ W_t = \begin{bmatrix} 10.036 & 1.968 \\ 10.046 & 0.9875 \\ -7.998 & 8.9365 \\ 1.0395 & 9.957 \end{bmatrix} $$

---
## 5. 结果分析

比较更新前 $W_{t-1}$ 和更新后 $W_t$ 的权重：
- **“猫”列 (第1列)**: 权重普遍**增加**了 (10 -> 10.036, 10 -> 10.046 等)。这与梯度 $g_t$ 的负值信号一致，模型正在加强“毛茸茸”、“有胡须”等特征对判断“是猫”的贡献。
- **“狗”列 (第2列)**: 权重普遍**减小**了 (2 -> 1.968, 9 -> 8.9365 等)。这与梯度 $g_t$ 的正值信号一致，模型正在削弱这些特征对判断“是狗”的贡献，以修正这次的错误。

**动量 (Momentum)** 的作用体现在 $v_t$ 的计算中，它让更新方向不仅仅由当前梯度 $g_t$ 决定，还部分地延续了之前的趋势 $v_{t-1}$，使得更新更平滑、更稳定。

**权重衰减 (Weight Decay)** 的作用体现在 $v_t$ 计算的第三项，它给所有权重施加了一个微小的“拉力”，使其朝零靠近，防止权重变得过大而导致过拟合。

这个矩阵变换的模拟过程，就是 `Momentum` 优化器在一个训练步骤中，为实现高效、稳定微调所执行的精确计算。