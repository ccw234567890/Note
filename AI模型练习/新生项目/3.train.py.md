下面按照 `train.py` 的行号顺序进行逐行（或成段）讲解，帮助你彻底理解脚本逻辑。所有行号对应文件中的实际代码。

```1:14:code/train.py
# 版权与 Apache-2.0 许可声明
```
1–14  版权头与许可证说明，无运行逻辑，但表明代码遵循 Apache-2.0 协议。

```15:15:code/train.py
"""Train mobilenetV2 on ImageNet."""
```
15  文件 docstring，一句话说明：用 MobileNetV2 训练（原本面向 ImageNet，但本项目已改为宠物数据集）。

```17:23:code/train.py
import time
...
from mindspore.common import set_seed
```
17–23  导入标准库 `time` 与 MindSpore 中训练所需模块，并设定随机种子函数 `set_seed`（保证结果可复现）。

```24:30:code/train.py
from src.dataset import extract_features
...
from src.models import CrossEntropyWithLabelSmooth, define_net, load_ckpt, get_networks, train
```
24–30  导入本项目自定义工具函数与模型搭建、训练流程等关键 API。  
• `extract_features`：用 backbone 一次性提取特征。  
• `set_config`、`train_parse_args`：解析/封装配置。  
• `context_device_init`：MindSpore 运行环境 & 设备。  
• `predict_from_net` 等：推理或模型导出。  
• `define_net`、`load_ckpt`、`train`：核心模型和训练循环。

```31:31:code/train.py
set_seed(1)
```
31  固定随机数种子，确保多次跑结果一致（1 可改其他值）。

```33:35:code/train.py
if __name__ == '__main__':
    args_opt = train_parse_args()
    config = set_config(args_opt)
```
33–35  脚本入口：  
1) 解析命令行参数，生成 `args_opt`（如 `--epoch_size`、`--dataset_path` 等）。  
2) 调用 `set_config` 把参数整理成 `config` 对象，后续统一读取。

```36:37:code/train.py
start = time.time()
```
36  记录训练起始时间，用于统计总耗时。

```38:40:code/train.py
# set context and device init
context_device_init(config)
```
38–40  按配置初始化 MindSpore 上下文（图模式 / PyNative、Ascend/GPU/CPU 设备、并行模式等）。

```41:43:code/train.py
# define network
backbone_net, head_net, net = define_net(config, activation="Softmax")
```
41–43  调用 `define_net`：  
• `backbone_net`：`MobileNetV2Backbone`，只到倒数第二个卷积层。  
• `head_net`：`MobileNetV2Head`，一个全连接层输出 `num_classes`。  
• `net`：把二者拼在一起；同时把最后激活函数设为 `Softmax` 方便推理可视化。

```44:46:code/train.py
# load parameters into backbone net from pre_training checkpoint
load_ckpt(backbone_net, args_opt.pretrain_ckpt, trainable=False)
```
44–46  (可选) 加载预训练权重到 backbone。`trainable=False` 意味着冻结参数，以便只训练头部。

```47:50:code/train.py
# show test img and predict label pre training
test_list = get_samples_from_eval_dataset(args_opt.dataset_path)
predict_from_net(net, test_list, config, show_title="pre training")
```
47–50  在正式训练前，用若干验证集图片做一次推理并可视化，作为“baseline”对照。

```51:53:code/train.py
# catch backbone features
data, step_size = extract_features(backbone_net, args_opt.dataset_path, config)
```
51–53  使用已加载权重的 backbone 对整个数据集抽取特征：  
• 返回值 `data` 为 `(train_features, train_labels, eval_features, eval_labels)` 的元组，后面手写循环直接拿特征进行分类头训练，大幅加速。  
• `step_size` 是训练集样本数。

```55:60:code/train.py
# define loss
if config.label_smooth > 0:
    loss = CrossEntropyWithLabelSmooth(...)
else:
    loss = SoftmaxCrossEntropyWithLogits(...)
```
55–60  根据配置决定是否启用 label-smoothing，创建交叉熵损失函数对象。

```61:68:code/train.py
# get learning rate
lr = Tensor(get_lr(
    global_step=0,
    lr_init=config.lr_init,
    lr_end=config.lr_end,
    lr_max=config.lr_max,
    warmup_epochs=config.warmup_epochs,
    total_epochs=config.epoch_size,
    steps_per_epoch=step_size))
```
61–68  调用 `get_lr` 生成整个训练期间（epoch_size × steps_per_epoch）的一维学习率数组，并封装成 MindSpore `Tensor` 供优化器读取。支持 warm-up、cosine 等策略。

```70:72:code/train.py
# get optimizer
opt = Momentum(filter(lambda x: x.requires_grad, head_net.get_parameters()),
               lr, config.momentum, config.weight_decay)
```
70–72  只把 head 网络中 `requires_grad=True` 的参数送进 `Momentum` 优化器，学习率 tensor、动量与权重衰减从 `config` 中读取。

```74:75:code/train.py
# define train and eval networks and start training
train_net, eval_net = get_networks(head_net, loss, opt)
train(train_net, eval_net, net, data, config)
```
74–75 
1) `get_networks()`：  
   • `WithLossCell(head_net, loss)` 计算前向+loss。  
   • `TrainOneStepCell(..., opt)` 自动求梯度 & 更新。  
   • 生成 `Model(net)` 作为评估网络。  
2) `train()`：进入 `src/models.py` 里的自定义训练循环：  
   • 每 epoch 随机打乱样本索引；  
   • 前向-后向更新头部；  
   • 计算训练 / 验证准确率；  
   • 维护 `best_acc` → 提前终止 & 保存最佳 ckpt (`ckpt_0/mobilenetv2_best.ckpt`)。

```76:76:code/train.py
print("train total cost {:5.4f} s".format(time.time() - start))
```
76  训练完成后打印总耗时。

```78:81:code/train.py
# show test img and predict label after training
predict_from_net(net, test_list, config, show_title="after training")
# export mindir file after training
export_mindir(net, "mobilenetv2")
```
78–81 
1) 用同一批测样再次推理，可视化训练后效果；  
2) 调用 `export_mindir` 导出 MindIR 文件 (`mobilenetv2.mindir`) 便于后续推理部署。

---

至此，`train.py` 的执行流程完整解析完毕。总结关键思想：  
• 利用预训练 backbone + 离线特征抽取 → 只 fine-tune 轻量级分类头，缩短训练时间。  
• 手写训练循环可轻松加入早停、最佳模型保存等逻辑。  
• 训练前后都有可视化推理对比，方便直观验证效果。