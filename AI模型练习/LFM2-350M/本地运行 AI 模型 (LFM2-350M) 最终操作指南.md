# æœ¬åœ°è¿è¡Œ AI æ¨¡å‹ (LFM2-350M) æœ€ç»ˆæ“ä½œæŒ‡å—

---

### **é˜¶æ®µã€‡ï¼šä¸€æ¬¡æ€§ç¯å¢ƒå‡†å¤‡ (åœ¨ Windows ä¸Š)**
è¿™äº›æ­¥éª¤åœ¨æ–°ç”µè„‘ä¸Šåªéœ€æ‰§è¡Œä¸€æ¬¡ã€‚

1.  **å®‰è£… WSL (Windows Subsystem for Linux)**
    * ä»¥ **ç®¡ç†å‘˜èº«ä»½** æ‰“å¼€ **Windows PowerShell**ã€‚
    * è¿è¡Œå‘½ä»¤ï¼š`wsl --install`
    * æ ¹æ®æç¤º**é‡å¯ç”µè„‘**ã€‚é‡å¯åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å®‰è£… Ubuntuï¼Œå¹¶è¦æ±‚æ‚¨è®¾ç½®ä¸€ä¸ª **Linux ç”¨æˆ·åå’Œå¯†ç **ã€‚

2.  **å®‰è£… Docker Desktop**
    * åœ¨ Windows æµè§ˆå™¨ä¸­è®¿é—®å®˜ç½‘ï¼š`https://www.docker.com/products/docker-desktop/`
    * ä¸‹è½½å¹¶å®‰è£… **Windows ç‰ˆæœ¬** (`Download for Windows - AMD64`)ã€‚
    * å®‰è£…å®Œæˆåï¼Œå¯åŠ¨ Docker Desktopã€‚

3.  **é…ç½® Docker ä¸ WSL çš„é›†æˆ**
    * å³é”®ç‚¹å‡»ä»»åŠ¡æ çš„ Docker å›¾æ ‡ ğŸ³ï¼Œé€‰æ‹© **"Settings" (è®¾ç½®)**ã€‚
    * è¿›å…¥ **"Resources" -> "WSL Integration"**ã€‚
    * ç¡®ä¿ "Ubuntu" æ—è¾¹çš„**å¼€å…³æ˜¯å¼€å¯çŠ¶æ€**ã€‚
    * ç‚¹å‡» **"Apply & Restart"** ä¿å­˜è®¾ç½®ã€‚

---

### **é˜¶æ®µä¸€ï¼šé¡¹ç›®è®¾ç½®ä¸æ¨¡å‹ä¸‹è½½**

1.  **åˆ›å»ºé¡¹ç›®æ–‡ä»¶å¤¹**
    * ä» Windows å¼€å§‹èœå•æ‰“å¼€ **Ubuntu** ç»ˆç«¯ã€‚
    * åœ¨ Ubuntu ç»ˆç«¯ä¸­ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
        ```bash
        mkdir LFM2-Project
        cd LFM2-Project
        ```

2.  **æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶ (æœ€ç¨³å¦¥çš„æ–¹æ³•)**
    * åœ¨ **Windows æµè§ˆå™¨**ä¸­è®¿é—®æ¨¡å‹é¡µé¢ï¼š`https://huggingface.co/LiquidAI/LFM2-350M`
    * ç‚¹å‡» **"Files and versions"** æ ‡ç­¾é¡µã€‚
    * ç‚¹å‡»é¡µé¢å³ä¸Šè§’ç´«è‰²çš„ **"Use this model"** æŒ‰é’®æ—è¾¹çš„**ä¸‹æ‹‰å°ç®­å¤´ `â–¾`**ï¼Œåœ¨èœå•ä¸­é€‰æ‹© **"Download repository"**ï¼Œå°†æ¨¡å‹ä¸‹è½½ä¸ºä¸€ä¸ª ZIP å‹ç¼©åŒ…ã€‚
    * åœ¨ Windows ä¸­è§£å‹è¿™ä¸ª ZIP æ–‡ä»¶ï¼Œå¾—åˆ°ä¸€ä¸ªåä¸º `LFM2-350M` çš„æ–‡ä»¶å¤¹ã€‚

3.  **å°†æ¨¡å‹æ–‡ä»¶æ”¾å…¥ WSL**
    * åœ¨ **Ubuntu ç»ˆç«¯**ä¸­ï¼Œä¸ºæ¨¡å‹æ–‡ä»¶åˆ›å»ºä¸€ä¸ªä½ç½®ï¼š
        ```bash
        # ç¡®ä¿ä½ è¿˜åœ¨ LFM2-Project æ–‡ä»¶å¤¹å†…
        mkdir LFM2-350M
        ```
    * æ‰“å¼€ **Windows æ–‡ä»¶èµ„æºç®¡ç†å™¨**ï¼Œåœ¨åœ°å€æ è¾“å…¥ `\\wsl$` å¹¶å›è½¦ã€‚
    * ä¾æ¬¡è¿›å…¥ `Ubuntu` -> `home` -> `[ä½ çš„Linuxç”¨æˆ·å]` -> `LFM2-Project` -> `LFM2-350M`ã€‚
    * å°†æ‚¨åœ¨ Windows ä¸­è§£å‹å¥½çš„æ–‡ä»¶å¤¹é‡Œçš„**æ‰€æœ‰æ–‡ä»¶**ï¼Œ**å¤åˆ¶å¹¶ç²˜è´´**åˆ°è¿™ä¸ªä½ç½®ã€‚

---

### **é˜¶æ®µäºŒï¼šæ„å»º Docker è¿è¡Œç¯å¢ƒ**
**æ³¨æ„**ï¼šä»è¿™ä¸€æ­¥å¼€å§‹ï¼Œæˆ‘ä»¬ä¸»è¦åœ¨ **Windows PowerShell** ä¸­æ“ä½œã€‚

1.  **åˆ›å»º Dockerfile**
    * æ‰“å¼€ **Windows PowerShell**ï¼Œå¹¶è¿›å…¥é¡¹ç›®ç›®å½•ï¼š
        ```powershell
        cd \\wsl$\Ubuntu\home\[ä½ çš„Linuxç”¨æˆ·å]\LFM2-Project
        ```
    * è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œåˆ›å»ºå¹¶ç¼–è¾‘ `Dockerfile`ï¼š
        ```powershell
        wsl nano Dockerfile
        ```
    * åœ¨æ‰“å¼€çš„ç¼–è¾‘å™¨ä¸­ï¼Œç²˜è´´ä»¥ä¸‹**æœ€ç»ˆç‰ˆ**å†…å®¹ï¼š
        ```dockerfile
        # ä½¿ç”¨ä¸€ä¸ªå®˜æ–¹çš„ Python 3.10 é•œåƒä½œä¸ºåŸºç¡€
        FROM python:3.10-slim

        # è®¾ç½®å·¥ä½œç›®å½•
        WORKDIR /app

        # å®‰è£… PyTorch, Transformers, å’Œ Accelerate åº“
        RUN pip install torch transformers accelerate

        # å°†æˆ‘ä»¬å‡†å¤‡å¥½çš„æ¨¡å‹æ–‡ä»¶å¤¹å¤åˆ¶åˆ°å®¹å™¨ä¸­
        COPY ./LFM2-350M /app/LFM2-350M

        # è®¾ç½®é»˜è®¤å‘½ä»¤ï¼Œè®©å®¹å™¨ä¿æŒè¿è¡Œ
        CMD ["tail", "-f", "/dev/null"]
        ```
    * æŒ‰ `Ctrl + O` ä¿å­˜ï¼ŒæŒ‰ `Enter` ç¡®è®¤ï¼ŒæŒ‰ `Ctrl + X` é€€å‡ºã€‚

2.  **æ„å»º Docker é•œåƒ**
    * åœ¨ PowerShell ä¸­ï¼Œè¿è¡Œæ„å»ºå‘½ä»¤ï¼ˆæ³¨æ„æœ€åçš„ `.`ï¼‰ï¼š
        ```powershell
        docker build -t lfm2-runner .
        ```
    * è¿™ä¸ªè¿‡ç¨‹ç¬¬ä¸€æ¬¡ä¼šæ¯”è¾ƒè€—æ—¶ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚

---

### **é˜¶æ®µä¸‰ï¼šè¿è¡Œæ¨¡å‹**

1.  **åˆ›å»º Python è„šæœ¬**
    * ä»åœ¨ PowerShell çš„é¡¹ç›®ç›®å½•ä¸­ï¼Œåˆ›å»ºå¹¶ç¼–è¾‘è„šæœ¬æ–‡ä»¶ï¼š
        ```powershell
        wsl nano run_model.py
        ```
    * åœ¨æ‰“å¼€çš„ç¼–è¾‘å™¨ä¸­ï¼Œç²˜è´´ä»¥ä¸‹**æœ€ç»ˆç‰ˆ** Python ä»£ç ï¼š
        ```python
        import torch
        from transformers import AutoTokenizer, AutoModelForCausalLM

        # è¿™æ˜¯æ¨¡å‹åœ¨å®¹å™¨å†…éƒ¨çš„è·¯å¾„
        model_path = "/app/LFM2-350M"
        print("--- æ­£åœ¨ä»å®¹å™¨å†…åŠ è½½æ¨¡å‹ ---")

        # åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForCausalLM.from_pretrained(
            model_path,
            dtype=torch.float32, # ä½¿ç”¨ dtype æ›¿ä»£å·²å¼ƒç”¨çš„ torch_dtype
            device_map="auto"
        )
        print("--- æ¨¡å‹åŠ è½½æˆåŠŸï¼ ---")

        # åœ¨è¿™é‡Œä¿®æ”¹ä½ æƒ³é—®çš„é—®é¢˜ï¼
        prompt = "In a world where AI is king, "
        inputs = tokenizer(prompt, return_tensors="pt").to("cpu")

        print(f"\nè¾“å…¥æç¤º: {prompt}")
        print("--- æ­£åœ¨ç”Ÿæˆæ–‡æœ¬... ---")

        # ç”Ÿæˆæ–‡æœ¬
        outputs = model.generate(**inputs, max_new_tokens=50, pad_token_id=tokenizer.eos_token_id)
        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

        print("\n--- æ¨¡å‹ç”Ÿæˆç»“æœ ---")
        print(generated_text)
        print("--------------------")
        ```
    * æŒ‰ `Ctrl + O` ä¿å­˜ï¼Œ`Enter` ç¡®è®¤ï¼Œ`Ctrl + X` é€€å‡ºã€‚

2.  **å¯åŠ¨ã€å¤åˆ¶ã€è¿›å…¥å¹¶è¿è¡Œ**
    * åœ¨ PowerShell ä¸­ï¼Œä¾æ¬¡æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
        ```powershell
        # 1. å¯åŠ¨å®¹å™¨ (åœ¨åå°è¿è¡Œ)
        docker run -it -d --name my-lfm2-container lfm2-runner

        # 2. å°†è„šæœ¬å¤åˆ¶åˆ°å®¹å™¨ä¸­
        docker cp run_model.py my-lfm2-container:/app/

        # 3. è¿›å…¥å®¹å™¨çš„å‘½ä»¤è¡Œ
        docker exec -it my-lfm2-container /bin/bash
        ```
    * è¿›å…¥å®¹å™¨åï¼ˆæç¤ºç¬¦ä¼šå˜ä¸º `root@...#`ï¼‰ï¼Œè¿è¡Œè„šæœ¬ï¼š
        ```bash
        python run_model.py
        ```
    * è‡³æ­¤ï¼Œæ‚¨åº”è¯¥èƒ½çœ‹åˆ°æ¨¡å‹çš„è¾“å‡ºäº†ã€‚

---

### **é˜¶æ®µå››ï¼šæ—¥å¸¸ä½¿ç”¨ä¸ç®¡ç†**

* **ä¿®æ”¹é—®é¢˜**ï¼šåªéœ€åœ¨ PowerShell ä¸­ç”¨ `wsl nano run_model.py` ä¿®æ”¹ `prompt` å†…å®¹ï¼Œä¿å­˜åï¼Œé‡æ–°æ‰§è¡Œ**é˜¶æ®µä¸‰**çš„ç¬¬ `2` æ­¥ï¼ˆ`docker cp` å’Œ `docker exec`ï¼‰å³å¯ã€‚
* **ç®¡ç†å®¹å™¨** (åœ¨ PowerShell ä¸­è¿è¡Œ)ï¼š
    * åœæ­¢å®¹å™¨ï¼š `docker stop my-lfm2-container`
    * å†æ¬¡å¯åŠ¨ï¼š `docker start my-lfm2-container`
    * å½»åº•åˆ é™¤ï¼š `docker rm my-lfm2-container`