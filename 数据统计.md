> [!NOTE] Title: PyTorch学习笔记：统计、范数与比较
> ---

> [!TIP] ## 1. 核心统计运算 (`mean`, `sum`, `min`, `max`, `prod`)
> 基础的聚合操作，用于分析张量的整体特性。
>
> ```python
> # 创建一个2x4的浮点型张量
> a = torch.arange(8).view(2,4).float()
> # tensor([[0., 1., 2., 3.],
> #         [4., 5., 6., 7.]])
> ```
>
> > [!abstract] ### 全局操作
> > 不指定维度时，对整个张量进行运算。
> > ```python
> > a.mean()    # tensor(3.5000)
> > a.sum()     # tensor(28.)
> > a.min()     # tensor(0.)
> > a.max()     # tensor(7.)
> > a.prod()    # tensor(0.) # 乘积，因为有0，所以结果是0
> > ```
>
> > [!abstract] ### argmin & argmax
> > 返回展平后张量中最小/最大值的**索引**。
> > ```python
> > # a被展平为 [0, 1, 2, 3, 4, 5, 6, 7]
> > a.argmin()  # tensor(0)  (0.是最小值，在第0个位置)
> > a.argmax()  # tensor(7)  (7.是最大值，在第7个位置)
> > ```

> [!TIP] ## 2. 范数 (Norm)
> 范数衡量向量或矩阵的大小，常用于正则化和梯度裁剪(clipping)。
>
> > [!INFO] ### 数学定义
> > - **向量L2范数**: $||x||_2 = \sqrt{\sum_{i=1}^{n} x_i^2}$ (所有元素平方和的平方根)
> > - **矩阵Frobenius范数**: $||A||_F = \sqrt{\sum_{i=1}^{m} \sum_{j=1}^{n} a_{ij}^2}$ (形式同向量L2范数)
> > - **L1范数**: $\sum |x_i|$ (所有元素绝对值之和)
>
> > [!abstract] ### PyTorch中的`torch.norm()`
> > `torch.norm(input, p, dim)`
> > - `p`: 范数类型 (1, 2, 'fro', etc.)。默认是'fro'，等价于L2范数。
> > - `dim`: 计算范数的维度。
> >
> > ```python
> > b = torch.ones(2, 4)
> > # tensor([[1., 1., 1., 1.],
> > #         [1., 1., 1., 1.]])
> > 
> > # L2范数 (所有元素的平方和再开根号)
> > b.norm(2)  # tensor(2.8284) -> sqrt(8*1^2)
> >
> > # 沿着维度1(行)计算L1范数
> > b.norm(1, dim=1) # tensor([4., 4.]) -> 每行的绝对值和
> >
> > # 沿着维度0(列)计算L2范数
> > b.norm(2, dim=0) # tensor([1.4142, 1.4142, 1.4142, 1.4142]) -> 每列的L2范数, sqrt(1^2+1^2)
> > ```

> [!TIP] ## 3. 维度参数 (`dim`, `keepdim`)
> `dim` 指定操作的轴，`keepdim` 决定是否保留该维度。
> > [!INFO] ### `dim`
> > `dim=0` 通常是列操作（纵向），`dim=1` 是行操作（横向）。
> >
> > [!INFO] ### `keepdim=True`
> > 在计算后保持原始维度，对于广播(Broadcasting)运算非常有用。
> >
> > ```python
> > a = torch.randn(4, 10)
> > 
> > # 不保留维度
> > res_vals = a.max(dim=1) 
> > # res_vals.shape -> torch.Size([4])
> > 
> > # 保留维度
> > res_vals_kept = a.max(dim=1, keepdim=True)
> > # res_vals_kept.shape -> torch.Size([4, 1])
> > ```

> [!TIP] ## 4. Top-k 或 k-th 值 (`topk`, `kthvalue`)
> 用于查找最大/最小的k个元素或第k小的元素。
>
> ```python
> a = torch.randn(4, 10)
> ```
> > [!abstract] ### `topk`
> > 寻找最大或最小的k个值。
> > ```python
> > # 寻找每行最大的3个元素
> > values, indices = a.topk(3, dim=1)
> > 
> > # 寻找每行最小的3个元素
> > values_small, indices_small = a.topk(3, dim=1, largest=False)
> > ```
>
> > [!abstract] ### `kthvalue`
> > 寻找第k小的值。
> > ```python
> > # 寻找每行第3小的元素 (k从1开始)
> > values, indices = a.kthvalue(3, dim=1)
> > ```

> [!TIP] ## 5. 比较运算 (`compare`)
> 对张量进行逐元素比较。
>
> > [!abstract] ### 逐元素比较 (`==`, `torch.eq`)
> > 返回一个与原张量形状相同的布尔张量。
> > ```python
> > a = torch.tensor([[1, 2], [3, 4]])
> > b = torch.tensor([[1, 0], [3, 5]])
> > 
> > # 使用运算符
> > a == b 
> > # tensor([[ True, False],
> > #         [ True, False]])
> >
> > # 使用函数
> > torch.eq(a, b)
> > # tensor([[ True, False],
> > #         [ True, False]])
> > ```
> >
> > [!abstract] ### 整体比较 (`torch.equal`)
> > 判断两个张量的**形状和值是否都完全相等**，返回一个单一的布尔值。
> > ```python
> > torch.equal(a, a)  # True
> > torch.equal(a, b)  # False
> > ```