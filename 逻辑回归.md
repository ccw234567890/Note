# 🩺 Logistic Regression：名为“回归”的分类器

`#MachineLearning` `#Classification` `#LogisticRegression` `#Sigmoid`

> [!abstract] 核心用途
> 逻辑回归是一个**名为“回归”的分类器**。它的核心任务是预测一个事件发生的 **概率**，这个事件只有 **两种可能的结果**（例如 “是/否”、“恶性/良性”）。它回答的不是“是多少？”，而是“有多大的可能性是‘是’？”。

---

## 矛盾的命名：为何叫“回归”？

> [!question] 困惑点
> 尽管名字中含有“回归”(Regression)，但逻辑回归在本质上是一个解决 **分类 (Classification)** 问题的强大算法。这个历史遗留的命名常常是初学者的第一个困惑点。

> [!note] 两者区别
> - **线性回归 (Linear Regression)**: 输出一个 **连续值**，用于预测具体数值，例如房价、气温。
> - **逻辑回归 (Logistic Regression)**: 输出一个 **(0, 1) 区间内的概率**，用于判断输入属于哪个类别，例如“是/否”、“真/假”。

---

## 从回归到分类的桥梁：Sigmoid函数

> [!info] 实现思路
> 逻辑回归巧妙地沿用了 **线性回归的内核**，并通过一个关键的“激活函数”——**Sigmoid函数**，完成了从预测数值到预测概率的完美转换。

### Step 1: 线性加权求和 (医生收集信息并进行初步评估)

> [!example] 医生诊断流程
> 1.  **收集指标 (输入 x)**: 肿瘤大小、病人年龄、细胞形状等。
> 2.  **经验判断 (权重 w)**: 根据经验，为每个指标赋予一个重要性权重。
> 3.  **得出“风险指数” (输出 z)**: 将所有信息加权求和，得到一个综合的、无边界的风险分数 `z`。

和线性回归完全相同，首先计算输入的加权和：
$$ z = w \cdot x + b $$
这个输出 `z` 是一个无界的连续实数（例如 `25.8` 或 `-18.2`），它本身并不代表概率。

### Step 2: Sigmoid函数映射 (医生将“风险指数”转换成标准化的“诊断报告”)

> [!success] Sigmoid函数：神奇的“概率校准器”
> 为了将无边界的风险指数 `z` 转换成病人能看懂的、在 `(0, 1)` 区间内的概率值，我们把它“挤压”进 Sigmoid 函数中。

$$ \sigma(z) = \frac{1}{1 + e^{-z}} $$

![Sigmoid Function](https://i.imgur.com/gT3fT8Y.png)

#### Sigmoid函数的特性：
-   **输出范围 (0, 1)**: 可以将任意实数 `z` 映射到 `(0, 1)` 区间内，完美符合概率的定义。
-   **概率化解读**:
    -   当 `z` 很大（风险极高）时，输出 **接近 1** (例如 99.8%)。
    -   当 `z` 很小（风险极低）时，输出 **接近 0** (例如 0.1%)。
    -   当 `z` 等于 `0`（风险中性）时，输出 **正好是 0.5** (50%)。

> [!tip] 最终结论
> 通过这两步，逻辑回归就完成了它的使命：接收一系列输入数据，最终输出一个有分寸的、可解释的概率值，告诉我们输入样本属于正类别 (Class 1) 的可能性有多大。