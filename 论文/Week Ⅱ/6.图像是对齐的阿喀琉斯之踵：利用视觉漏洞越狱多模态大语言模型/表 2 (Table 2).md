![](https://cc-407-1376569927.cos.ap-guangzhou.myqcloud.com/cc-407-1376569927/images-obsidian/202509241948828.png)

好的，这张**表2 (Table 2)** 是展示 **HADES 攻击方法最终效果**的“成绩单”。如果说表1是诊断问题，那么表2就是展示“治疗方案”（在这里是攻击方案）有多么强大。它详细量化了 HADES 的每一步是如何层层加码，最终实现高效“越狱”的。

### **一、 表格的目标**

这张表格的核心目标是：

1.  **验证 HADES 攻击的有效性：** 证明 HADES 确实能显著提高对各种主流 MLLM 的攻击成功率。
2.  **剖析 HADES 各组件的贡献：** 通过逐级展示攻击效果，清晰地说明 HADES 的每一步（隐藏、放大、再放大）分别贡献了多少“攻击力”。
3.  **横向对比不同模型的脆弱性：** 看看哪个模型在面对 HADES 攻击时最脆弱，哪个模型的防御能力最强。

### **二、 表格结构解析**

与表1类似，我们先来拆解表格的结构：

*   **Metric (衡量指标):** 同样是**攻击成功率 (Attack Success Rate, ASR)**。数字越高，代表攻击越成功，模型越不安全。
*   **Model (模型):** 列出了被攻击的五个目标模型。
*   **Setting (评估设置):** 这部分是理解本表格的关键，它完美对应了 HADES 攻击流程的几个阶段。
    *   **Typ image (基线):** 这是 HADES 攻击的**第一步**。输入包括：原始有害文本指令 + 一张只包含有害关键词的**文字图片** (`i_typ`)。这可以看作是最基础的“图文分离”攻击。
    *   **+T2I pointer (第二步前半):** “T2I pointer” 指的是 "Text-to-image pointer"，即把文本中的有害词换成“图中物体”的操作。所以这个设置的输入是：**被修改后的无害化文本 (`t'`)** + 文字图片 (`i_typ`)。这是 HADES **第一步的完整体现**。
    *   **+Opt image (第二步后半):** 在上一步的基础上，加入了经过 LLM 迭代优化生成的**有害图片 (`i_opt`)**。这是 HADES **第二步的完整体现**。
    *   **+Adv image (第三步):** 在上一步的基础上，又加入了通过梯度更新生成的**对抗性噪声图片 (`i_adv`)**。这是 **HADES 的完全体**，火力全开的最终形态。*（注意：由于闭源模型无法获取梯度，所以 Gemini 和 GPT-4V 没有这一行数据）*
*   **Average(%) (平均成功率):** 同样是最重要的一列，是各模型在不同攻击设置下的平均 ASR。括号里的 `+` 和 `-` 数字，代表该设置下的 ASR **相对于 `Typ image` 基线的变化**。

### **三、 从表格数据中得出的核心结论**

#### **结论一：HADES 攻击整体上极其有效**

请直接看每个模型最后一行（或 `+Opt image` 行）的 `Average(%)` 数据：

*   **LLaVA-1.5:** 完整 HADES 攻击的 ASR 高达 **90.26%**。这意味着10次攻击里有9次都能成功，其防御系统几乎被完全摧毁。
*   **LLaVA-1.5L** 和 **LLaVA:** ASR 也分别达到了 **88.93%** 和 **82.53%**。
*   **Gemini Pro:** 即使是强大的闭源模型，在面对 HADES 第二步攻击后，ASR 也飙升至 **71.60%**，说明其防御也存在巨大漏洞。
*   **GPT-4V:** 在所有模型中表现最为稳健，但其 ASR 也从基线的 1.73% 提升到了 **15.07%**，说明它也并非无懈可击。

**解读:** 数据雄辩地证明，HADES 是一种非常强大的攻击方法，对当前主流的开源和闭源 MLLM 都构成了实质性的威胁。

#### **结论二：HADES 的每一步都有效增强了攻击**

我们可以通过观察 ASR 的逐级变化来看这一点，以 LLaVA-1.5 为例：

1.  **Typ image (基线):** 65.60%
2.  **+T2I pointer:** 降至 58.13% (`-7.47`)。这是一个有趣的现象，作者在论文中解释说，对于 LLaVA 这种 OCR 能力较弱的模型，将文本中的关键词移除反而让它更难理解指令，导致 ASR 下降。但对于 OCR 能力强的 Gemini 和 GPT-4V，这一步的 ASR 是**上升**的，证明了“隐藏”策略对强模型有效。
3.  **+Opt image:** 飙升至 78.53% (`+12.93`)。这说明，加入那张经过 AI 优化的有害图片，极大地增强了攻击效果。它不仅提供了强烈的视觉有害信号，还帮助 LLaVA 模型更好地理解了指令的真实意图，弥补了上一步的不足。
4.  **+Adv image:** 最终达到 **90.26%** (`+24.66`)。这表明，最后的对抗性噪声是“压死骆驼的最后一根稻草”，它贡献了巨大的攻击力，让成功率趋近完美。

**解读:** 表格清晰地展示了 HADES 是一个设计精良的组合攻击。它的每一步，尤其是**生成有害图片 (`Opt image`)** 和**叠加对抗噪声 (`Adv image`)**，都对最终的攻击成功率有显著的正面贡献。

#### **结论三：不同模型对攻击的抵抗力差异巨大**

*   **开源模型 (LLaVA 系列):** 普遍非常脆弱，在完整攻击下基本不堪一击。
*   **闭源模型 (Gemini Pro, GPT-4V):** 防御能力明显更强。
    *   **Gemini Pro** 表现出较大的脆弱性，ASR 达到了 71.60%。
    *   **GPT-4V** 表现出最强的鲁棒性，是唯一能将 ASR 控制在 20% 以下的模型，但依然受到了影响。

**解读:** 这可能反映了闭源模型在安全对齐方面投入了更多的研发资源和更先进的技术。然而，HADES 依然能撼动它们，说明这种基于“视觉漏洞”的攻击思路是正确的，并且对所有模型都有效。

### **总结**

**表2** 是这篇论文最有力的“战果展示”。它不仅证明了 HADES 是一个可以实际操作且效果拔群的攻击工具，还通过逐级递进的数据，让我们深刻理解了这种复杂攻击的内在机制，即通过**隐藏、放大、再放大**的策略，层层递进，最终彻底瓦解 MLLM 的安全防线。