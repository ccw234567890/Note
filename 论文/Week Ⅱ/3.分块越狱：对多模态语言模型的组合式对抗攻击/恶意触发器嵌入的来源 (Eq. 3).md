![image.png](https://cc-407-1376569927.cos.ap-guangzhou.myqcloud.com/cc-407-1376569927/images-obsidian/202509251651318.png)
# 深度解析：恶意触发器嵌入的来源 (Source of Malicious Trigger Embeddings)

> **核心目标**：在组合式越狱攻击中，最关键的第一步，是在模型的“联合嵌入空间” (Joint Embedding Space) 中，为我们的恶意意图（例如“炸弹”）确定一个精确的数学坐标。这个坐标就是 **恶意触发器嵌入** (Malicious Trigger Embedding)，在论文中我们将其表示为 `H_harm`。攻击的后续步骤，都是为了让一张看似无害的图片，其嵌入 `H_adv` 无限逼近这个目标 `H_harm`。

论文利用了 **CLIP (Contrastive Language-Image Pre-Training)** 模型强大的图文编码能力来生成这个目标嵌入。CLIP 包含一个文本编码器 `E_t(·)` 和一个图像编码器 `E_v(·)`，它们可以将任何文本或图像转换到同一个嵌入空间中。

以下是论文提出的四种生成 `H_harm` 的方法，从最直接到最有效，层层递进。

---

## 1. 文本触发器 (Textual Trigger)

*   **核心思想**: 最直接的想法是，直接使用恶意词汇的文本含义作为我们的目标。
*   **适用场景**: 当我们想让对抗性图像在模型眼中等同于某个特定的词或短语时。

### 数学公式推导

$$
H_{\text{harm}} = E_t(x_{\text{harm}})
$$

*   **步骤分解**:
    1.  **定义恶意输入 `x_harm`**:
        *   `x_harm` 在这里是一个文本字符串 (string)。
        *   例如：`x_harm = "Grenade, bomb"`

    2.  **通过文本编码器 `E_t(·)`**:
        *   我们将这个字符串 `x_harm` 输入到 CLIP 的文本编码器 `E_t` 中。
        *   `E_t` 会将这段文字的语义信息，转换成一个高维度的数学向量。

    3.  **获得目标嵌入 `H_harm`**:
        *   `E_t(x_harm)` 的输出就是我们最终的目标嵌入向量 `H_harm`。这个向量在嵌入空间中，就代表了“手榴弹、炸弹”的语义。

*   **效果分析**: 虽然这个方法最直观，但实验证明它的**攻击成功率最低**。原因是 CLIP 的文本和图像嵌入之间存在“模态鸿沟” (Modality Gap)，用一张图像去精确模仿一个纯文本的嵌入，难度很大，效率很低。

---

## 2. OCR 文本触发器 (OCR Textual Trigger)

*   **核心思想**: 既然直接用文本嵌入效果不好，那我们能否让模型“看”到这些文字？即，将文字渲染成图片，然后利用更强大的图像编码器来生成嵌入。
*   **适用场景**: 当恶意概念是纯文本或指令时（例如“非法活动”），这种方法比第一种更有效。

### 数学公式推导

$$
H_{\text{harm}} = E_v(\text{Render}(x_{\text{harm}}))
$$

*   **步骤分解**:
    1.  **定义恶意输入 `x_harm`**:
        *   `x_harm` 依然是一个文本字符串。
        *   例如：`x_harm = "Grenade Bomb"`

    2.  **渲染成图 `Render(·)`**:
        *   `Render(·)` 是一个函数，代表将输入的文本字符串，转换成一张图片。
        *   例如，它会生成一张白底黑字、写着 "Grenade Bomb" 的 `.jpg` 或 `.png` 图像。

    3.  **通过图像编码器 `E_v(·)`**:
        *   我们将这张刚刚生成的**文字图片** `Render(x_harm)` 输入到 CLIP 的图像编码器 `E_v` 中。
        *   `E_v` 会分析这张图片的内容（通过光学字符识别 OCR 的能力），并将其转换成一个嵌入向量。

    4.  **获得目标嵌入 `H_harm`**:
        *   `E_v(...)` 的输出就是我们的目标嵌入 `H_harm`。

*   **效果分析**: 这种方法的效果**显著优于**纯文本触发器。因为它绕过了“模态鸿沟”，完全在视觉域内进行操作，更符合对抗性图像的生成路径。

---

## 3. 视觉触发器 (Visual Trigger)

*   **核心思想**: 与其让模型“看”文字，不如直接让它看恶意物体本身。这是最符合人类直觉的方式。
*   **适用场景**: 当恶意概念是一个具体的、可以被图像表示的物体时（如武器、毒品等）。

### 数学公式推导

$$
H_{\text{harm}} = E_v(x_{\text{harm}})
$$

*   **步骤分解**:
    1.  **定义恶意输入 `x_harm`**:
        *   **关键变化**：`x_harm` 在这里**不再是文本**，而是一张包含恶意物体的**真实图像**。
        *   例如：`x_harm` 是一张包含手榴弹和炸弹的照片。

    2.  **通过图像编码器 `E_v(·)`**:
        *   我们将这张真实照片 `x_harm` 直接输入到 CLIP 的图像编码器 `E_v` 中。
        *   `E_v` 会识别图片中的物体，并将其转换成一个代表其视觉内容的嵌入向量。

    3.  **获得目标嵌入 `H_harm`**:
        *   `E_v(x_harm)` 的输出就是我们的目标嵌入 `H_harm`。

*   **效果分析**: 这是一个**非常有效**的方法。因为它直接利用了模型最强大的能力——识别和理解真实世界图像。

---

## 4. 组合触发器 (Combined OCR Textual-Visual Trigger)

*   **核心思想**: “集大成者”。将视觉线索（真实物体）和文本线索（物体名称）结合在同一张图片里，为模型提供最强烈、最明确的信号。
*   **适用场景**: 追求最高攻击成功率和鲁棒性的首选方法。

### 数学公式推导
$$
H_{\text{harm}} = E_v(\text{Overlay}(x_{\text{harm}}^{\text{visual}}, \text{Render}(x_{\text{harm}}^{\text{text}})))
$$

*   **步骤分解**:
    1.  **定义两个恶意输入**:
        *   `x_{harm}^{\text{visual}}`: 包含恶意物体的真实图像（同方法3）。
        *   `x_{harm}^{\text{text}}`: 描述该物体的文本字符串（同方法1和2）。

    2.  **渲染文本 `Render(·)`**:
        *   首先，将文本 `x_{harm}^{\text{text}}` 渲染成一张文字图片。

    3.  **叠加图像 `Overlay(A, B)`**:
        *   `Overlay(A, B)` 是一个函数，代表将图片 B（文字图片）叠加到图片 A（物体图片）之上。
        *   最终得到一张既有手榴弹，上面又写着 "Grenade Bomb" 字样的组合图片。

    4.  **通过图像编码器 `E_v(·)`**:
        *   将这张信息量最丰富的**组合图片**输入到图像编码器 `E_v` 中。

    5.  **获得目标嵌入 `H_harm`**:
        *   `E_v(...)` 的输出就是我们的最终目标嵌入 `H_harm`。

*   **效果分析**: 这是论文中**效果最好、最鲁棒的触发器**。因为它通过单一的视觉通道，同时提供了物体的视觉特征和文本标签，给予了模型一个几乎不可能误解的超强信号。

---

### 总结与对比

| 触发器类型 (Trigger Type)           | 输入 `x_harm` 的类型     | 使用的编码器 | 核心思想                                | 效果 (Attack Success Rate) |
| ----------------------------------- | -------------------------- | ------------ | --------------------------------------- | -------------------------- |
| **1. 文本 (Textual)**               | 文本字符串                 | `E_t` (文本) | 直接使用词语的语义                      | **最低** (几乎为0)         |
| **2. OCR 文本 (OCR Textual)**       | 文本字符串 (渲染成图)      | `E_v` (图像) | 让模型“看”到文字                        | **较高**                   |
| **3. 视觉 (Visual)**                | 真实物体图片               | `E_v` (图像) | 让模型“看”到物体本身                    | **高**                     |
| **4. 组合 (Combined)**              | 真实图片 + 文本字符串 (叠加) | `E_v` (图像) | 提供视觉和文本双重线索，信息最强        | **最高**                   |

这个设计精巧的四步法，揭示了攻击者可以如何利用多模态模型内部的表示机制，来为恶意内容创建一个强大且精确的“数字指纹”，为后续的对抗性攻击铺平了道路。