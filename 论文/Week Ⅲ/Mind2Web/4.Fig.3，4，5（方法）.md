![](https://cc-407-1376569927.cos.ap-guangzhou.myqcloud.com/cc-407-1376569927/images-obsidian/202510051154853.png)

好，这页其实把 **MIND2WEB 的基线方法 MINDACT** 拆成了三个图：  
**Figure 3（整体流程）→ Figure 4（候选生成 Ranker 的模板细节）→ Figure 5（动作预测 LLM 的两种出题方式）**。我按“从左到右，从上到下”的顺序讲清每个方块、箭头与它们的动机。

---

# Figure 3｜MINDACT 的整体流水线

**输入**（左下黄框）

- **Task Description**：自然语言任务（如“找到最近的…并看评论”）。
    
- **Previous Actions**：已经执行的历史步骤（为后续决策提供上下文）。
    
- **HTML Document**：当前页面的完整 HTML/DOM。
    

**阶段 A：候选生成（Ranking LM）**

1. 把页面里**每一个可交互元素**（按钮、输入框、链接、下拉等）做成“**候选元素**”列表。
    
2. 用一个**小模型 Ranker**（图中“Ranking LM”）给每个候选元素打分，输出在 [0,1] 的相关性分数（右侧细长竖条 “Score”）。
    
3. 取 **Top-k**（通常数十个）候选作为“**高召回的短名单**”。
    
4. 同时为每个入选候选抽取一个**HTML Snippet**（元素本身 + 适量上下文）——这一步的目的是把原来动辄上万 token 的整页 HTML，压缩成若干**与任务强相关的小片段**。
    

**阶段 B：动作预测（Prediction LLM）**

- 把“**Top-k 候选 + 对应 HTML 片段**”喂给一个**更大的生成模型**（图中的 Prediction LLM）。
    
- 该模型输出一步动作的两部分：
    
    1. **Target Element**（到底点/填/选哪个元素）；
        
    2. **Operation**（做什么操作；若是 TYPE/SELECT 还需给出**值**）。
        
- 执行这一步后，页面可能变化；于是抓取新的 HTML + 追加到历史，再回到阶段 A，**循环**到任务结束。
    

**设计动机**

- 用**小 Ranker 先“粗筛”**，把**召回率**做高、成本做低；
    
- 再用**大 LLM 精排/决策**，把**精度**做高；
    
- 这样把“长而脏的 HTML + 开放动作空间”拆成“**检索**（谁相关）+ **决策**（做什么）”，比直接把整页塞进大模型要稳得多、便宜得多。
    

---

# Figure 4｜候选生成模块（Ranking LM）的模板

右上角这块展示 Ranker 的**输入格式**与思路：

**两段文本化模板**

1. **Candidate Representation（候选表示）**
    
    - 用自然语言把该候选元素编码出来：
        
        - `ancestors:` 其**祖先路径**（如 `/html/div/dialog/ul …`），
            
        - `location:` 所在区域/版块的提示（如“search results”），
            
        - `target:` 元素本身（如 `button id=… span "Boston"`），
            
        - 也会包含**邻近文本**（例如 `span NY, USA`）。
            
    - 目的：让模型“知道它在 DOM 的哪里、长什么样、附近写了啥”。
        
2. **Task Query（任务查询）**
    
    - 把**任务描述**与**历史动作**拼成“查询串”：
        
        - `Task:` 接原始目标（如“在波士顿…18号…一位客人…”）；
            
        - `Previous Actions:` 把已做过的动作“语言化”（如 `[combobox] Reservation type -> SELECT: Pickup` 等）。
            
    - 目的：给 Ranker **任务上下文**，便于“当前步”去匹配“哪个候选最相关”。
        

**打分方式**

- 把两段模板拼成 Ranker 的输入（可用交叉编码器样式），输出 0–1 的**相关分**；
    
- 以此对**同一页面的所有候选**排序，取 Top-k 进入下一阶段。
    

**为什么要这样写模板？**

- **祖先路径/邻域文本**把“网页的结构偏置”喂给 Ranker；
    
- **历史动作**让 Ranker 具备“**步骤感**”（知道上一部做了啥，下一步该找谁），提高跨页长链路的相关性召回。
    

---

# Figure 5｜动作预测（Prediction LLM）的两种出题法

这张（下方大图）展示了给大模型喂“**HTML 片段** + **任务/历史**”后，如何让它产出“**选哪个元素** + **做什么操作**”。有两条路线：

### 1）Direct Generation（直接生成）

- 让模型**自由生成**一个结构化回答：
    
    ```
    Element: <select id=1 …> “Size; Select a Size”
    Action: SELECT
    Value: Queen
    ```
    
- 好处：表达力强、灵活；
    
- 坏处：**容易幻觉或指代不清**（元素不在片段里、或生成的定位不可执行）。
    

### 2）Multichoice（多选题）

- 把候选片段里的**若干元素**列成“选项清单”（每个选项是文本化后的元素串），**再加一个 “None of the above”**。
    
- 出题：
    
    - “**选哪一个元素**最合适？”（单选题）；
        
    - “**动作是什么**（Click/Type/Select）以及**值**是什么？”（可附带小生成）。
        
- 如果有很多候选，论文会**分组出题**、多轮淘汰：每轮在一小组里选，再把胜出的选项汇总成新一组，直至只剩一个。
    
- 好处：**受限输出**能显著减少幻觉，效果通常**强于直接生成**；
    
- 代价：多轮出题会**多几次调用**，但仍比把整页 HTML 喂大模型便宜。
    

---

## 小结（把三图串起来）

1. **Ranker 先筛**：把“整页成千上万个节点”→“几十个高召回候选 + 简短 HTML 片段”。
    
2. **LLM 再判**：在这些片段上，采用“**多选题**（优先）或**直接生成**”选定**目标元素**并给出**操作/参数**。
    
3. **闭环执行**：执行 → 页面变 → 新 HTML 与历史再喂 Ranker → 下一步，直到任务完成。
    

这三张图合在一起，就是 MINDACT 的“检索-决策”双阶段范式；它的优势在于：**把超长、嘈杂、开放的网页交互问题，拆成了可控的、高召回 + 高精度 的两步走**。如果你想，我可以把这套流程画成一张 **Mermaid 流程图（中英双注）** 或给出一段**伪代码**，便于你放进笔记或直接改造成实验脚本。